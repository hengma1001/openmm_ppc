/* -------------------------------------------------------------------------- *
 *                                   OpenMM                                   *
 * -------------------------------------------------------------------------- *
 * This is part of the OpenMM molecular simulation toolkit originating from   *
 * Simbios, the NIH National Center for Physics-Based Simulation of           *
 * Biological Structures at Stanford, funded under the NIH Roadmap for        *
 * Medical Research, grant U54 GM072970. See https://simtk.org.               *
 *                                                                            *
 * Portions copyright (c) 2012 Stanford University and the Authors.           *
 * Authors: Peter Eastman                                                     *
 * Contributors:                                                              *
 *                                                                            *
 * This program is free software: you can redistribute it and/or modify       *
 * it under the terms of the GNU Lesser General Public License as published   *
 * by the Free Software Foundation, either version 3 of the License, or       *
 * (at your option) any later version.                                        *
 *                                                                            *
 * This program is distributed in the hope that it will be useful,            *
 * but WITHOUT ANY WARRANTY; without even the implied warranty of             *
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the              *
 * GNU Lesser General Public License for more details.                        *
 *                                                                            *
 * You should have received a copy of the GNU Lesser General Public License   *
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.      *
 * -------------------------------------------------------------------------- */

#include "CudaKernelSources.h"

using namespace OpenMM;
using namespace std;

const string CudaKernelSources::andersenThermostat = "/**\n"
" * Apply the Andersen thermostat to adjust particle velocities.\n"
" */\n"
"\n"
"extern \"C\" __global__ void applyAndersenThermostat(int numAtoms, float collisionFrequency, float kT, mixed4* velm, const mixed4* __restrict__ stepSize, const float4* __restrict__ random,\n"
"        unsigned int randomIndex, const int* __restrict__ atomGroups) {\n"
"    float collisionProbability = 1.0f-expf(-(float) (collisionFrequency*stepSize[0].y));\n"
"    float randomRange = erff(collisionProbability/sqrtf(2.0f));\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed4 velocity = velm[index];\n"
"        float4 selectRand = random[randomIndex+atomGroups[index]];\n"
"        float4 velRand = random[randomIndex+index];\n"
"        real scale = (selectRand.w > -randomRange && selectRand.w < randomRange ? 0 : 1);\n"
"        real add = (1-scale)*SQRT(kT*velocity.w);\n"
"        velocity.x = scale*velocity.x + add*velRand.x;\n"
"        velocity.y = scale*velocity.y + add*velRand.y;\n"
"        velocity.z = scale*velocity.z + add*velRand.z;\n"
"        velm[index] = velocity;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::angleForce = "real3 v0 = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"real3 v1 = make_real3(pos2.x-pos3.x, pos2.y-pos3.y, pos2.z-pos3.z);\n"
"#if APPLY_PERIODIC\n"
"APPLY_PERIODIC_TO_DELTA(v0)\n"
"APPLY_PERIODIC_TO_DELTA(v1)\n"
"#endif\n"
"real3 cp = cross(v0, v1);\n"
"real rp = cp.x*cp.x + cp.y*cp.y + cp.z*cp.z;\n"
"rp = max(SQRT(rp), (real) 1.0e-06f);\n"
"real r21 = v0.x*v0.x + v0.y*v0.y + v0.z*v0.z;\n"
"real r23 = v1.x*v1.x + v1.y*v1.y + v1.z*v1.z;\n"
"real dot = v0.x*v1.x + v0.y*v1.y + v0.z*v1.z;\n"
"real cosine = min(max(dot*RSQRT(r21*r23), (real) -1), (real) 1);\n"
"real theta = ACOS(cosine);\n"
"COMPUTE_FORCE\n"
"real3 force1 = cross(v0, cp)*(dEdAngle/(r21*rp));\n"
"real3 force3 = cross(cp, v1)*(dEdAngle/(r23*rp));\n"
"real3 force2 = -force1-force3;\n"
"";
const string CudaKernelSources::bondForce = "real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#if APPLY_PERIODIC\n"
"APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"real r = SQRT(delta.x*delta.x + delta.y*delta.y + delta.z*delta.z);\n"
"COMPUTE_FORCE\n"
"dEdR = (r > 0) ? (dEdR / r) : 0;\n"
"delta *= dEdR;\n"
"real3 force1 = delta;\n"
"real3 force2 = -delta;\n"
"";
const string CudaKernelSources::brownian = "/**\n"
" * Perform the first step of Brownian integration.\n"
" */\n"
"\n"
"extern \"C\" __global__ void integrateBrownianPart1(int numAtoms, int paddedNumAtoms, mixed tauDeltaT, mixed noiseAmplitude, const long long* __restrict__ force,\n"
"        mixed4* __restrict__ posDelta, const mixed4* __restrict__ velm, const float4* __restrict__ random, unsigned int randomIndex) {\n"
"    randomIndex += blockIdx.x*blockDim.x+threadIdx.x;\n"
"    const mixed fscale = tauDeltaT/(mixed) 0x100000000;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed invMass = velm[index].w;\n"
"        if (invMass != 0) {\n"
"            posDelta[index].x = fscale*invMass*force[index] + noiseAmplitude*SQRT(invMass)*random[randomIndex].x;\n"
"            posDelta[index].y = fscale*invMass*force[index+paddedNumAtoms] + noiseAmplitude*SQRT(invMass)*random[randomIndex].y;\n"
"            posDelta[index].z = fscale*invMass*force[index+paddedNumAtoms*2] + noiseAmplitude*SQRT(invMass)*random[randomIndex].z;\n"
"        }\n"
"        randomIndex += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Perform the second step of Brownian integration.\n"
" */\n"
"\n"
"extern \"C\" __global__ void integrateBrownianPart2(int numAtoms, mixed deltaT, real4* posq, real4* __restrict__ posqCorrection, mixed4* velm, const mixed4* __restrict__ posDelta) {\n"
"    const mixed oneOverDeltaT = RECIP(deltaT);\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        if (velm[index].w != 0) {\n"
"            mixed4 delta = posDelta[index];\n"
"            velm[index].x = oneOverDeltaT*delta.x;\n"
"            velm[index].y = oneOverDeltaT*delta.y;\n"
"            velm[index].z = oneOverDeltaT*delta.z;\n"
"#ifdef USE_MIXED_PRECISION\n"
"            real4 pos1 = posq[index];\n"
"            real4 pos2 = posqCorrection[index];\n"
"            mixed4 pos = make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"            real4 pos = posq[index];\n"
"#endif\n"
"            pos.x += delta.x;\n"
"            pos.y += delta.y;\n"
"            pos.z += delta.z;\n"
"#ifdef USE_MIXED_PRECISION\n"
"            posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"            posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"            posq[index] = pos;\n"
"#endif\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::cmapTorsionForce = "const real PI = (real) 3.14159265358979323846;\n"
"\n"
"// Compute the first angle.\n"
"\n"
"real3 v0a = make_real3(pos1.x-pos2.x, pos1.y-pos2.y, pos1.z-pos2.z);\n"
"real3 v1a = make_real3(pos3.x-pos2.x, pos3.y-pos2.y, pos3.z-pos2.z);\n"
"real3 v2a = make_real3(pos3.x-pos4.x, pos3.y-pos4.y, pos3.z-pos4.z);\n"
"#if APPLY_PERIODIC\n"
"APPLY_PERIODIC_TO_DELTA(v0a)\n"
"APPLY_PERIODIC_TO_DELTA(v1a)\n"
"APPLY_PERIODIC_TO_DELTA(v2a)\n"
"#endif\n"
"real3 cp0a = cross(v0a, v1a);\n"
"real3 cp1a = cross(v1a, v2a);\n"
"real cosangle = dot(normalize(cp0a), normalize(cp1a));\n"
"real angleA;\n"
"if (cosangle > 0.99f || cosangle < -0.99f) {\n"
"    // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"    real3 cross_prod = cross(cp0a, cp1a);\n"
"    real scale = dot(cp0a, cp0a)*dot(cp1a, cp1a);\n"
"    angleA = ASIN(SQRT(dot(cross_prod, cross_prod)/scale));\n"
"    if (cosangle < 0.0f)\n"
"        angleA = PI-angleA;\n"
"}\n"
"else\n"
"   angleA = ACOS(cosangle);\n"
"angleA = (dot(v0a, cp1a) >= 0 ? angleA : -angleA);\n"
"angleA = fmod(angleA+2.0f*PI, 2.0f*PI);\n"
"\n"
"// Compute the second angle.\n"
"\n"
"real3 v0b = make_real3(pos5.x-pos6.x, pos5.y-pos6.y, pos5.z-pos6.z);\n"
"real3 v1b = make_real3(pos7.x-pos6.x, pos7.y-pos6.y, pos7.z-pos6.z);\n"
"real3 v2b = make_real3(pos7.x-pos8.x, pos7.y-pos8.y, pos7.z-pos8.z);\n"
"#if APPLY_PERIODIC\n"
"APPLY_PERIODIC_TO_DELTA(v0b)\n"
"APPLY_PERIODIC_TO_DELTA(v1b)\n"
"APPLY_PERIODIC_TO_DELTA(v2b)\n"
"#endif\n"
"real3 cp0b = cross(v0b, v1b);\n"
"real3 cp1b = cross(v1b, v2b);\n"
"cosangle = dot(normalize(cp0b), normalize(cp1b));\n"
"real angleB;\n"
"if (cosangle > 0.99f || cosangle < -0.99f) {\n"
"    // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"    real3 cross_prod = cross(cp0b, cp1b);\n"
"    real scale = dot(cp0b, cp0b)*dot(cp1b, cp1b);\n"
"    angleB = ASIN(SQRT(dot(cross_prod, cross_prod)/scale));\n"
"    if (cosangle < 0.0f)\n"
"        angleB = PI-angleB;\n"
"}\n"
"else\n"
"   angleB = ACOS(cosangle);\n"
"angleB = (dot(v0b, cp1b) >= 0 ? angleB : -angleB);\n"
"angleB = fmod(angleB+2.0f*PI, 2.0f*PI);\n"
"\n"
"// Identify which patch this is in.\n"
"\n"
"int2 pos = MAP_POS[MAPS[index]];\n"
"int size = pos.y;\n"
"real delta = 2*PI/size;\n"
"int s = (int) (angleA/delta);\n"
"int t = (int) (angleB/delta);\n"
"float4 c[4];\n"
"int coeffIndex = pos.x+4*(s+size*t);\n"
"c[0] = COEFF[coeffIndex];\n"
"c[1] = COEFF[coeffIndex+1];\n"
"c[2] = COEFF[coeffIndex+2];\n"
"c[3] = COEFF[coeffIndex+3];\n"
"real da = angleA/delta-s;\n"
"real db = angleB/delta-t;\n"
"\n"
"// Evaluate the spline to determine the energy and gradients.\n"
"\n"
"real torsionEnergy = 0.0f;\n"
"real dEdA = 0.0f;\n"
"real dEdB = 0.0f;\n"
"torsionEnergy = da*torsionEnergy + ((c[3].w*db + c[3].z)*db + c[3].y)*db + c[3].x;\n"
"dEdA = db*dEdA + (3.0f*c[3].w*da + 2.0f*c[2].w)*da + c[1].w;\n"
"dEdB = da*dEdB + (3.0f*c[3].w*db + 2.0f*c[3].z)*db + c[3].y;\n"
"torsionEnergy = da*torsionEnergy + ((c[2].w*db + c[2].z)*db + c[2].y)*db + c[2].x;\n"
"dEdA = db*dEdA + (3.0f*c[3].z*da + 2.0f*c[2].z)*da + c[1].z;\n"
"dEdB = da*dEdB + (3.0f*c[2].w*db + 2.0f*c[2].z)*db + c[2].y;\n"
"torsionEnergy = da*torsionEnergy + ((c[1].w*db + c[1].z)*db + c[1].y)*db + c[1].x;\n"
"dEdA = db*dEdA + (3.0f*c[3].y*da + 2.0f*c[2].y)*da + c[1].y;\n"
"dEdB = da*dEdB + (3.0f*c[1].w*db + 2.0f*c[1].z)*db + c[1].y;\n"
"torsionEnergy = da*torsionEnergy + ((c[0].w*db + c[0].z)*db + c[0].y)*db + c[0].x;\n"
"dEdA = db*dEdA + (3.0f*c[3].x*da + 2.0f*c[2].x)*da + c[1].x;\n"
"dEdB = da*dEdB + (3.0f*c[0].w*db + 2.0f*c[0].z)*db + c[0].y;\n"
"dEdA /= delta;\n"
"dEdB /= delta;\n"
"energy += torsionEnergy;\n"
"\n"
"// Apply the force to the first torsion.\n"
"\n"
"real normCross1 = dot(cp0a, cp0a);\n"
"real normSqrBC = dot(v1a, v1a);\n"
"real normBC = SQRT(normSqrBC);\n"
"real normCross2 = dot(cp1a, cp1a);\n"
"real dp = RECIP(normSqrBC);\n"
"real4 ff = make_real4((-dEdA*normBC)/normCross1, dot(v0a, v1a)*dp, dot(v2a, v1a)*dp, (dEdA*normBC)/normCross2);\n"
"real3 force1 = ff.x*cp0a;\n"
"real3 force4 = ff.w*cp1a;\n"
"real3 d = ff.y*force1 - ff.z*force4;\n"
"real3 force2 = d-force1;\n"
"real3 force3 = -d-force4;\n"
"\n"
"// Apply the force to the second torsion.\n"
"\n"
"normCross1 = dot(cp0b, cp0b);\n"
"normSqrBC = dot(v1b, v1b);\n"
"normBC = SQRT(normSqrBC);\n"
"normCross2 = dot(cp1b, cp1b);\n"
"dp = RECIP(normSqrBC);\n"
"ff = make_real4((-dEdB*normBC)/normCross1, dot(v0b, v1b)*dp, dot(v2b, v1b)*dp, (dEdB*normBC)/normCross2);\n"
"real3 force5 = ff.x*cp0b;\n"
"real3 force8 = ff.w*cp1b;\n"
"d = ff.y*force5 - ff.z*force8;\n"
"real3 force6 = d-force5;\n"
"real3 force7 = -d-force8;\n"
"";
const string CudaKernelSources::constraints = "extern \"C\" __global__ void applyPositionDeltas(int numAtoms, real4* __restrict__ posq, real4* __restrict__ posqCorrection, mixed4* __restrict__ posDelta) {\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"        real4 pos1 = posq[index];\n"
"        real4 pos2 = posqCorrection[index];\n"
"        mixed4 pos = make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"        mixed4 pos = posq[index];\n"
"#endif\n"
"        pos.x += posDelta[index].x;\n"
"        pos.y += posDelta[index].y;\n"
"        pos.z += posDelta[index].z;\n"
"#ifdef USE_MIXED_PRECISION\n"
"        posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"        posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"        posq[index] = pos;\n"
"#endif\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::coulombLennardJones = "{\n"
"#if USE_EWALD\n"
"    bool needCorrection = hasExclusions && isExcluded && atom1 != atom2 && atom1 < NUM_ATOMS && atom2 < NUM_ATOMS;\n"
"    unsigned int includeInteraction = ((!isExcluded && r2 < CUTOFF_SQUARED) || needCorrection);\n"
"    const real alphaR = EWALD_ALPHA*r;\n"
"    const real expAlphaRSqr = EXP(-alphaR*alphaR);\n"
"#if HAS_COULOMB\n"
"    const real prefactor = 138.935456f*CHARGE1*CHARGE2*invR;\n"
"#else\n"
"    const real prefactor = 0.0f;\n"
"#endif\n"
"\n"
"#ifdef USE_DOUBLE_PRECISION\n"
"    const real erfcAlphaR = erfc(alphaR);\n"
"#else\n"
"    // This approximation for erfc is from Abramowitz and Stegun (1964) p. 299.  They cite the following as\n"
"    // the original source: C. Hastings, Jr., Approximations for Digital Computers (1955).  It has a maximum\n"
"    // error of 1.5e-7.\n"
"\n"
"    const real t = RECIP(1.0f+0.3275911f*alphaR);\n"
"    const real erfcAlphaR = (0.254829592f+(-0.284496736f+(1.421413741f+(-1.453152027f+1.061405429f*t)*t)*t)*t)*t*expAlphaRSqr;\n"
"#endif\n"
"    real tempForce = 0.0f;\n"
"#if HAS_LENNARD_JONES\n"
"    // The multiplicative term to correct for the multiplicative terms that are always\n"
"    // present in reciprocal space.  The real terms have an additive contribution\n"
"    // added in, but for excluded terms the multiplicative term is just subtracted.\n"
"    // These factors are needed in both clauses of the needCorrection statement, so\n"
"    // I declare them up here.\n"
"    #if DO_LJPME\n"
"        const real dispersionAlphaR = EWALD_DISPERSION_ALPHA*r;\n"
"        const real dar2 = dispersionAlphaR*dispersionAlphaR;\n"
"        const real dar4 = dar2*dar2;\n"
"        const real dar6 = dar4*dar2;\n"
"        const real invR2 = invR*invR;\n"
"        const real expDar2 = EXP(-dar2);\n"
"        const float2 sigExpProd = SIGMA_EPSILON1*SIGMA_EPSILON2;\n"
"        const real c6 = 64*sigExpProd.x*sigExpProd.x*sigExpProd.x*sigExpProd.y;\n"
"        const real coef = invR2*invR2*invR2*c6;\n"
"        const real eprefac = 1.0f + dar2 + 0.5f*dar4;\n"
"        const real dprefac = eprefac + dar6/6.0f;\n"
"    #endif\n"
"#endif\n"
"    if (needCorrection) {\n"
"        // Subtract off the part of this interaction that was included in the reciprocal space contribution.\n"
"\n"
"#if HAS_COULOMB\n"
"        if (1-erfcAlphaR > 1e-6) {\n"
"            real erfAlphaR = ERF(alphaR); // Our erfc approximation is not accurate enough when r is very small, which happens with Drude particles.\n"
"            tempForce = -prefactor*(erfAlphaR-alphaR*expAlphaRSqr*TWO_OVER_SQRT_PI);\n"
"            tempEnergy += -prefactor*erfAlphaR;\n"
"        }\n"
"        else {\n"
"            includeInteraction = false;\n"
"            tempEnergy -= TWO_OVER_SQRT_PI*EWALD_ALPHA*138.935456f*CHARGE1*CHARGE2;\n"
"        }\n"
"#endif\n"
"#if HAS_LENNARD_JONES\n"
"        #if DO_LJPME\n"
"            // The multiplicative grid term\n"
"            tempEnergy += coef*(1.0f - expDar2*eprefac);\n"
"            tempForce += 6.0f*coef*(1.0f - expDar2*dprefac);\n"
"        #endif\n"
"#endif\n"
"    }\n"
"    else {\n"
"#if HAS_LENNARD_JONES\n"
"        real sig = SIGMA_EPSILON1.x + SIGMA_EPSILON2.x;\n"
"        real sig2 = invR*sig;\n"
"        sig2 *= sig2;\n"
"        real sig6 = sig2*sig2*sig2;\n"
"        real eps = SIGMA_EPSILON1.y*SIGMA_EPSILON2.y;\n"
"        real epssig6 = sig6*eps;\n"
"        tempForce = epssig6*(12.0f*sig6 - 6.0f);\n"
"        real ljEnergy = epssig6*(sig6 - 1.0f);\n"
"        #if USE_LJ_SWITCH\n"
"        if (r > LJ_SWITCH_CUTOFF) {\n"
"            real x = r-LJ_SWITCH_CUTOFF;\n"
"            real switchValue = 1+x*x*x*(LJ_SWITCH_C3+x*(LJ_SWITCH_C4+x*LJ_SWITCH_C5));\n"
"            real switchDeriv = x*x*(3*LJ_SWITCH_C3+x*(4*LJ_SWITCH_C4+x*5*LJ_SWITCH_C5));\n"
"            tempForce = tempForce*switchValue - ljEnergy*switchDeriv*r;\n"
"            ljEnergy *= switchValue;\n"
"        }\n"
"        #endif\n"
"#if DO_LJPME\n"
"        // The multiplicative grid term\n"
"        ljEnergy += coef*(1.0f - expDar2*eprefac);\n"
"        tempForce += 6.0f*coef*(1.0f - expDar2*dprefac);\n"
"        // The potential shift accounts for the step at the cutoff introduced by the\n"
"        // transition from additive to multiplicative combintion rules and is only\n"
"        // needed for the real (not excluded) terms.  By addin these terms to ljEnergy\n"
"        // instead of tempEnergy here, the includeInteraction mask is correctly applied.\n"
"        sig2 = sig*sig;\n"
"        sig6 = sig2*sig2*sig2*INVCUT6;\n"
"        epssig6 = eps*sig6;\n"
"        // The additive part of the potential shift\n"
"        ljEnergy += epssig6*(1.0f - sig6);\n"
"        // The multiplicative part of the potential shift\n"
"        ljEnergy += MULTSHIFT6*c6;\n"
"#endif\n"
"        tempForce += prefactor*(erfcAlphaR+alphaR*expAlphaRSqr*TWO_OVER_SQRT_PI);\n"
"        tempEnergy += includeInteraction ? ljEnergy + prefactor*erfcAlphaR : 0;\n"
"#else\n"
"        tempForce = prefactor*(erfcAlphaR+alphaR*expAlphaRSqr*TWO_OVER_SQRT_PI);\n"
"        tempEnergy += includeInteraction ? prefactor*erfcAlphaR : 0;\n"
"#endif\n"
"    }\n"
"    dEdR += includeInteraction ? tempForce*invR*invR : 0;\n"
"#else\n"
"#ifdef USE_CUTOFF\n"
"    unsigned int includeInteraction = (!isExcluded && r2 < CUTOFF_SQUARED);\n"
"#else\n"
"    unsigned int includeInteraction = (!isExcluded);\n"
"#endif\n"
"    real tempForce = 0.0f;\n"
"  #if HAS_LENNARD_JONES\n"
"    real sig = SIGMA_EPSILON1.x + SIGMA_EPSILON2.x;\n"
"    real sig2 = invR*sig;\n"
"    sig2 *= sig2;\n"
"    real sig6 = sig2*sig2*sig2;\n"
"    real epssig6 = sig6*(SIGMA_EPSILON1.y*SIGMA_EPSILON2.y);\n"
"    tempForce = epssig6*(12.0f*sig6 - 6.0f);\n"
"    real ljEnergy = includeInteraction ? epssig6*(sig6 - 1) : 0;\n"
"    #if USE_LJ_SWITCH\n"
"    if (r > LJ_SWITCH_CUTOFF) {\n"
"        real x = r-LJ_SWITCH_CUTOFF;\n"
"        real switchValue = 1+x*x*x*(LJ_SWITCH_C3+x*(LJ_SWITCH_C4+x*LJ_SWITCH_C5));\n"
"        real switchDeriv = x*x*(3*LJ_SWITCH_C3+x*(4*LJ_SWITCH_C4+x*5*LJ_SWITCH_C5));\n"
"        tempForce = tempForce*switchValue - ljEnergy*switchDeriv*r;\n"
"        ljEnergy *= switchValue;\n"
"    }\n"
"    #endif\n"
"    tempEnergy += ljEnergy;\n"
"  #endif\n"
"#if HAS_COULOMB\n"
"  #ifdef USE_CUTOFF\n"
"    const real prefactor = 138.935456f*CHARGE1*CHARGE2;\n"
"    tempForce += prefactor*(invR - 2.0f*REACTION_FIELD_K*r2);\n"
"    tempEnergy += includeInteraction ? prefactor*(invR + REACTION_FIELD_K*r2 - REACTION_FIELD_C) : 0;\n"
"  #else\n"
"    const real prefactor = 138.935456f*CHARGE1*CHARGE2*invR;\n"
"    tempForce += prefactor;\n"
"    tempEnergy += includeInteraction ? prefactor : 0;\n"
"  #endif\n"
"#endif\n"
"    dEdR += includeInteraction ? tempForce*invR*invR : 0;\n"
"#endif\n"
"}\n"
"";
const string CudaKernelSources::customCVForce = "/**\n"
" * Copy the positions and velocities to the inner context.\n"
" */\n"
"extern \"C\" __global__ void copyState(real4* posq, real4* posqCorrection, mixed4* velm, int* __restrict__ atomOrder,\n"
"        real4* innerPosq, real4* innerPosqCorrection, mixed4* innerVelm, int* __restrict__ innerInvAtomOrder,\n"
"        int numAtoms) {\n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < numAtoms; i += blockDim.x*gridDim.x) {\n"
"        int index = innerInvAtomOrder[atomOrder[i]];\n"
"        innerPosq[index] = posq[i];\n"
"        innerVelm[index] = velm[i];\n"
"#ifdef USE_MIXED_PRECISION\n"
"        innerPosqCorrection[index] = posqCorrection[i];\n"
"#endif\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Copy the forces back to the main context.\n"
" */\n"
"extern \"C\" __global__ void copyForces(long long* forces, int* __restrict__ invAtomOrder, long long* innerForces,\n"
"        int* __restrict__ innerAtomOrder, int numAtoms, int paddedNumAtoms) {\n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < numAtoms; i += blockDim.x*gridDim.x) {\n"
"        int index = invAtomOrder[innerAtomOrder[i]];\n"
"        forces[index] = innerForces[i];\n"
"        forces[index+paddedNumAtoms] = innerForces[i+paddedNumAtoms];\n"
"        forces[index+paddedNumAtoms*2] = innerForces[i+paddedNumAtoms*2];\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Add all the forces from the CVs.\n"
" */\n"
"extern \"C\" __global__ void addForces(long long* forces, int bufferSize\n"
"    PARAMETER_ARGUMENTS) {\n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < bufferSize; i += blockDim.x*gridDim.x) {\n"
"        ADD_FORCES\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customCentroidBond = "/**\n"
" * Compute the center of each group.\n"
" */\n"
"extern \"C\" __global__ void computeGroupCenters(const real4* __restrict__ posq, const int* __restrict__ groupParticles,\n"
"        const real* __restrict__ groupWeights, const int* __restrict__ groupOffsets, real4* __restrict__ centerPositions) {\n"
"    __shared__ volatile real3 temp[64];\n"
"    for (int group = blockIdx.x; group < NUM_GROUPS; group += gridDim.x) {\n"
"        // The threads in this block work together to compute the center one group.\n"
"        \n"
"        int firstIndex = groupOffsets[group];\n"
"        int lastIndex = groupOffsets[group+1];\n"
"        real3 center = make_real3(0, 0, 0);\n"
"        for (int index = threadIdx.x; index < lastIndex-firstIndex; index += blockDim.x) {\n"
"            int atom = groupParticles[firstIndex+index];\n"
"            real weight = groupWeights[firstIndex+index];\n"
"            real4 pos = posq[atom];\n"
"            center.x += weight*pos.x;\n"
"            center.y += weight*pos.y;\n"
"            center.z += weight*pos.z;\n"
"        }\n"
"        \n"
"        // Sum the values.\n"
"        \n"
"        int thread = threadIdx.x;\n"
"        temp[thread].x = center.x;\n"
"        temp[thread].y = center.y;\n"
"        temp[thread].z = center.z;\n"
"        __syncthreads();\n"
"        if (thread < 32) {\n"
"            temp[thread].x += temp[thread+32].x;\n"
"            temp[thread].y += temp[thread+32].y;\n"
"            temp[thread].z += temp[thread+32].z;\n"
"            if (thread < 16) {\n"
"                temp[thread].x += temp[thread+16].x;\n"
"                temp[thread].y += temp[thread+16].y;\n"
"                temp[thread].z += temp[thread+16].z;\n"
"            }\n"
"            if (thread < 8) {\n"
"                temp[thread].x += temp[thread+8].x;\n"
"                temp[thread].y += temp[thread+8].y;\n"
"                temp[thread].z += temp[thread+8].z;\n"
"            }\n"
"            if (thread < 4) {\n"
"                temp[thread].x += temp[thread+4].x;\n"
"                temp[thread].y += temp[thread+4].y;\n"
"                temp[thread].z += temp[thread+4].z;\n"
"            }\n"
"            if (thread < 2) {\n"
"                temp[thread].x += temp[thread+2].x;\n"
"                temp[thread].y += temp[thread+2].y;\n"
"                temp[thread].z += temp[thread+2].z;\n"
"            }\n"
"        }\n"
"        if (thread == 0)\n"
"            centerPositions[group] = make_real4(temp[0].x+temp[1].x, temp[0].y+temp[1].y, temp[0].z+temp[1].z, 0);\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Convert a real4 to a real3 by removing its last element.\n"
" */\n"
"inline __device__ real3 trim(real4 v) {\n"
"    return make_real3(v.x, v.y, v.z);\n"
"}\n"
"\n"
"/**\n"
" * Compute the difference between two vectors, setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 delta(real4 vec1, real4 vec2, bool periodic, real4 periodicBoxSize, real4 invPeriodicBoxSize, \n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ) {\n"
"    real4 result = make_real4(vec1.x-vec2.x, vec1.y-vec2.y, vec1.z-vec2.z, 0);\n"
"    if (periodic)\n"
"        APPLY_PERIODIC_TO_DELTA(result);\n"
"    result.w = result.x*result.x + result.y*result.y + result.z*result.z;\n"
"    return result;\n"
"}\n"
"\n"
"/**\n"
" * Compute the angle between two vectors.  The w component of each vector should contain the squared magnitude.\n"
" */\n"
"__device__ real computeAngle(real4 vec1, real4 vec2) {\n"
"    real dotProduct = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n"
"    real cosine = dotProduct*RSQRT(vec1.w*vec2.w);\n"
"    real angle;\n"
"    if (cosine > 0.99f || cosine < -0.99f) {\n"
"        // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"        real3 crossProduct = cross(vec1, vec2);\n"
"        real scale = vec1.w*vec2.w;\n"
"        angle = ASIN(SQRT(dot(crossProduct, crossProduct)/scale));\n"
"        if (cosine < 0.0f)\n"
"            angle = M_PI-angle;\n"
"    }\n"
"    else\n"
"       angle = ACOS(cosine);\n"
"    return angle;\n"
"}\n"
"\n"
"/**\n"
" * Compute the cross product of two vectors, setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 computeCross(real4 vec1, real4 vec2) {\n"
"    real3 cp = cross(vec1, vec2);\n"
"    return make_real4(cp.x, cp.y, cp.z, cp.x*cp.x+cp.y*cp.y+cp.z*cp.z);\n"
"}\n"
"\n"
"/**\n"
" * Compute the forces on groups based on the bonds.\n"
" */\n"
"extern \"C\" __global__ void computeGroupForces(unsigned long long* __restrict__ groupForce, mixed* __restrict__ energyBuffer, const real4* __restrict__ centerPositions,\n"
"        const int* __restrict__ bondGroups, real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ\n"
"        EXTRA_ARGS) {\n"
"    mixed energy = 0;\n"
"    INIT_PARAM_DERIVS\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_BONDS; index += blockDim.x*gridDim.x) {\n"
"        COMPUTE_FORCE\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"    SAVE_PARAM_DERIVS\n"
"}\n"
"\n"
"/**\n"
" * Apply the forces from the group centers to the individual atoms.\n"
" */\n"
"extern \"C\" __global__ void applyForcesToAtoms(const int* __restrict__ groupParticles, const real* __restrict__ groupWeights, const int* __restrict__ groupOffsets,\n"
"        const long long* __restrict__ groupForce, unsigned long long* __restrict__ atomForce) {\n"
"    for (int group = blockIdx.x; group < NUM_GROUPS; group += gridDim.x) {\n"
"        long long fx = groupForce[group];\n"
"        long long fy = groupForce[group+NUM_GROUPS];\n"
"        long long fz = groupForce[group+NUM_GROUPS*2];\n"
"        int firstIndex = groupOffsets[group];\n"
"        int lastIndex = groupOffsets[group+1];\n"
"        for (int index = threadIdx.x; index < lastIndex-firstIndex; index += blockDim.x) {\n"
"            int atom = groupParticles[firstIndex+index];\n"
"            real weight = groupWeights[firstIndex+index];\n"
"            atomicAdd(&atomForce[atom], static_cast<unsigned long long>((long long) (fx*weight)));\n"
"            atomicAdd(&atomForce[atom+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (fy*weight)));\n"
"            atomicAdd(&atomForce[atom+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (fz*weight)));\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customCompoundBond = "/**\n"
" * Convert a real4 to a real3 by removing its last element.\n"
" */\n"
"inline __device__ real3 ccb_trim(real4 v) {\n"
"    return make_real3(v.x, v.y, v.z);\n"
"}\n"
"\n"
"/**\n"
" * Compute the difference between two vectors, setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 ccb_delta(real4 vec1, real4 vec2, bool periodic, real4 periodicBoxSize, real4 invPeriodicBoxSize, \n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ) {\n"
"    real4 result = make_real4(vec1.x-vec2.x, vec1.y-vec2.y, vec1.z-vec2.z, 0);\n"
"    if (periodic)\n"
"        APPLY_PERIODIC_TO_DELTA(result);\n"
"    result.w = result.x*result.x + result.y*result.y + result.z*result.z;\n"
"    return result;\n"
"}\n"
"\n"
"/**\n"
" * Compute the angle between two vectors.  The w component of each vector should contain the squared magnitude.\n"
" */\n"
"__device__ real ccb_computeAngle(real4 vec1, real4 vec2) {\n"
"    real dotProduct = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n"
"    real cosine = dotProduct*RSQRT(vec1.w*vec2.w);\n"
"    real angle;\n"
"    if (cosine > 0.99f || cosine < -0.99f) {\n"
"        // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"        real3 crossProduct = cross(vec1, vec2);\n"
"        real scale = vec1.w*vec2.w;\n"
"        angle = ASIN(SQRT(dot(crossProduct, crossProduct)/scale));\n"
"        if (cosine < 0.0f)\n"
"            angle = M_PI-angle;\n"
"    }\n"
"    else\n"
"       angle = ACOS(cosine);\n"
"    return angle;\n"
"}\n"
"\n"
"/**\n"
" * Compute the cross product of two vectors, setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 ccb_computeCross(real4 vec1, real4 vec2) {\n"
"    real3 cp = cross(vec1, vec2);\n"
"    return make_real4(cp.x, cp.y, cp.z, cp.x*cp.x+cp.y*cp.y+cp.z*cp.z);\n"
"}\n"
"";
const string CudaKernelSources::customExternalForce = "COMPUTE_FORCE\n"
"real3 force1 = make_real3(-dEdX, -dEdY, -dEdZ);\n"
"";
const string CudaKernelSources::customGBChainRule = "#ifdef USE_CUTOFF\n"
"if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && atom1 != atom2 && r2 < CUTOFF_SQUARED) {\n"
"#else\n"
"if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && atom1 != atom2) {\n"
"#endif\n"
"#ifdef USE_SYMMETRIC\n"
"    real tempForce = 0;\n"
"#else\n"
"    real3 tempForce1 = make_real3(0);\n"
"    real3 tempForce2 = make_real3(0);\n"
"#endif\n"
"    COMPUTE_FORCE\n"
"#ifdef USE_SYMMETRIC\n"
"    dEdR += tempForce*invR;\n"
"#else\n"
"    dEdR1 += tempForce1;\n"
"    dEdR2 += tempForce2;\n"
"#endif\n"
"}\n"
"";
const string CudaKernelSources::customGBEnergyN2 = "#define STORE_DERIVATIVE_1(INDEX) atomicAdd(&derivBuffers[offset+(INDEX-1)*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (deriv##INDEX##_1*0x100000000)));\n"
"#define STORE_DERIVATIVE_2(INDEX) atomicAdd(&derivBuffers[offset+(INDEX-1)*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].deriv##INDEX*0x100000000)));\n"
"\n"
"typedef struct {\n"
"    real3 pos;\n"
"    real3 force;\n"
"    ATOM_PARAMETER_DATA\n"
"#ifdef NEED_PADDING\n"
"    float padding;\n"
"#endif\n"
"} AtomData;\n"
"\n"
"/**\n"
" * Compute a force based on pair interactions.\n"
" */\n"
"extern \"C\" __global__ void computeN2Energy(unsigned long long* __restrict__ forceBuffers, mixed* __restrict__ energyBuffer,\n"
"        const real4* __restrict__ posq, const unsigned int* __restrict__ exclusions, const ushort2* __restrict__ exclusionTiles, bool needEnergy,\n"
"#ifdef USE_CUTOFF\n"
"        const int* __restrict__ tiles, const unsigned int* __restrict__ interactionCount, real4 periodicBoxSize, real4 invPeriodicBoxSize,\n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ, unsigned int maxTiles, const real4* __restrict__ blockCenter,\n"
"        const real4* __restrict__ blockSize, const unsigned int* __restrict__ interactingAtoms\n"
"#else\n"
"        unsigned int numTiles\n"
"#endif\n"
"        PARAMETER_ARGUMENTS) {\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE;\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1);\n"
"    const unsigned int tbx = threadIdx.x - tgx;\n"
"    mixed energy = 0;\n"
"    INIT_PARAM_DERIVS\n"
"    __shared__ AtomData localData[THREAD_BLOCK_SIZE];\n"
"\n"
"    // First loop: process tiles that contain exclusions.\n"
"    \n"
"    const unsigned int firstExclusionTile = FIRST_EXCLUSION_TILE+warp*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    const unsigned int lastExclusionTile = FIRST_EXCLUSION_TILE+(warp+1)*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    for (int pos = firstExclusionTile; pos < lastExclusionTile; pos++) {\n"
"        const ushort2 tileIndices = exclusionTiles[pos];\n"
"        const unsigned int x = tileIndices.x;\n"
"        const unsigned int y = tileIndices.y;\n"
"        real3 force = make_real3(0);\n"
"        DECLARE_ATOM1_DERIVATIVES\n"
"        unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"        real4 pos1 = posq[atom1];\n"
"        LOAD_ATOM1_PARAMETERS\n"
"#ifdef USE_EXCLUSIONS\n"
"        unsigned int excl = exclusions[pos*TILE_SIZE+tgx];\n"
"#endif\n"
"        if (x == y) {\n"
"            // This tile is on the diagonal.\n"
"\n"
"            const unsigned int localAtomIndex = threadIdx.x;\n"
"            localData[localAtomIndex].pos = make_real3(pos1.x, pos1.y, pos1.z);\n"
"            LOAD_LOCAL_PARAMETERS_FROM_1\n"
"            for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                int atom2 = tbx+j;\n"
"                real3 pos2 = localData[atom2].pos;\n"
"                real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    atom2 = y*TILE_SIZE+j;\n"
"                    real dEdR = 0;\n"
"                    real tempEnergy = 0;\n"
"                    const real interactionScale = 0.5f;\n"
"#ifdef USE_EXCLUSIONS\n"
"                    bool isExcluded = !(excl & 0x1);\n"
"#endif\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && atom1 != atom2) {\n"
"                        COMPUTE_INTERACTION\n"
"                        dEdR /= -r;\n"
"                    }\n"
"                    if (needEnergy)\n"
"                        energy += 0.5f*tempEnergy;\n"
"                    delta *= dEdR;\n"
"                    force.x -= delta.x;\n"
"                    force.y -= delta.y;\n"
"                    force.z -= delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                }\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                excl >>= 1;\n"
"#endif\n"
"            }\n"
"        }\n"
"        else {\n"
"            // This is an off-diagonal tile.\n"
"\n"
"            const unsigned int localAtomIndex = threadIdx.x;\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"            real4 tempPosq = posq[j];\n"
"            localData[localAtomIndex].pos = make_real3(tempPosq.x, tempPosq.y, tempPosq.z);\n"
"            LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"            localData[localAtomIndex].force = make_real3(0);\n"
"            CLEAR_LOCAL_DERIVATIVES\n"
"#ifdef USE_EXCLUSIONS\n"
"            excl = (excl >> tgx) | (excl << (TILE_SIZE - tgx));\n"
"#endif\n"
"            unsigned int tj = tgx;\n"
"            for (j = 0; j < TILE_SIZE; j++) {\n"
"                int atom2 = tbx+tj;\n"
"                real3 pos2 = localData[atom2].pos;\n"
"                real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    atom2 = y*TILE_SIZE+tj;\n"
"                    real dEdR = 0;\n"
"                    real tempEnergy = 0;\n"
"                    const real interactionScale = 1;\n"
"#ifdef USE_EXCLUSIONS\n"
"                    bool isExcluded = !(excl & 0x1);\n"
"#endif\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                        COMPUTE_INTERACTION\n"
"                        dEdR /= -r;\n"
"                    }\n"
"                    if (needEnergy)\n"
"                        energy += tempEnergy;\n"
"                    delta *= dEdR;\n"
"                    force.x -= delta.x;\n"
"                    force.y -= delta.y;\n"
"                    force.z -= delta.z;\n"
"                    atom2 = tbx+tj;\n"
"                    localData[atom2].force.x += delta.x;\n"
"                    localData[atom2].force.y += delta.y;\n"
"                    localData[atom2].force.z += delta.z;\n"
"                    RECORD_DERIVATIVE_2\n"
"#ifdef USE_CUTOFF\n"
"                }\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                excl >>= 1;\n"
"#endif\n"
"                tj = (tj + 1) & (TILE_SIZE - 1);\n"
"            }\n"
"        }\n"
"\n"
"        // Write results.\n"
"\n"
"        unsigned int offset = x*TILE_SIZE + tgx;\n"
"        atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"        STORE_DERIVATIVES_1\n"
"        if (x != y) {\n"
"            offset = y*TILE_SIZE + tgx;\n"
"            atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (localData[threadIdx.x].force.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].force.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].force.z*0x100000000)));\n"
"            STORE_DERIVATIVES_2\n"
"        }\n"
"    }\n"
"\n"
"    // Second loop: tiles without exclusions, either from the neighbor list (with cutoff) or just enumerating all\n"
"    // of them (no cutoff).\n"
"\n"
"#ifdef USE_CUTOFF\n"
"    unsigned int numTiles = interactionCount[0];\n"
"    if (numTiles > maxTiles)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    int pos = (int) (warp*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"    int end = (int) ((warp+1)*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"#else\n"
"    int pos = (int) (warp*(long long)numTiles/totalWarps);\n"
"    int end = (int) ((warp+1)*(long long)numTiles/totalWarps);\n"
"#endif\n"
"    int skipBase = 0;\n"
"    int currentSkipIndex = tbx;\n"
"    __shared__ int atomIndices[THREAD_BLOCK_SIZE];\n"
"    __shared__ volatile int skipTiles[THREAD_BLOCK_SIZE];\n"
"    skipTiles[threadIdx.x] = -1;\n"
"    \n"
"    while (pos < end) {\n"
"        const bool isExcluded = false;\n"
"        real3 force = make_real3(0);\n"
"        DECLARE_ATOM1_DERIVATIVES\n"
"        bool includeTile = true;\n"
"        \n"
"        // Extract the coordinates of this tile.\n"
"        \n"
"        int x, y;\n"
"        bool singlePeriodicCopy = false;\n"
"#ifdef USE_CUTOFF\n"
"            x = tiles[pos];\n"
"            real4 blockSizeX = blockSize[x];\n"
"            singlePeriodicCopy = (0.5f*periodicBoxSize.x-blockSizeX.x >= CUTOFF &&\n"
"                                  0.5f*periodicBoxSize.y-blockSizeX.y >= CUTOFF &&\n"
"                                  0.5f*periodicBoxSize.z-blockSizeX.z >= CUTOFF);\n"
"#else\n"
"        y = (int) floor(NUM_BLOCKS+0.5f-SQRT((NUM_BLOCKS+0.5f)*(NUM_BLOCKS+0.5f)-2*pos));\n"
"        x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        if (x < y || x >= NUM_BLOCKS) { // Occasionally happens due to roundoff error.\n"
"            y += (x < y ? -1 : 1);\n"
"            x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        }\n"
"\n"
"        // Skip over tiles that have exclusions, since they were already processed.\n"
"\n"
"        while (skipTiles[tbx+TILE_SIZE-1] < pos) {\n"
"            if (skipBase+tgx < NUM_TILES_WITH_EXCLUSIONS) {\n"
"                ushort2 tile = exclusionTiles[skipBase+tgx];\n"
"                skipTiles[threadIdx.x] = tile.x + tile.y*NUM_BLOCKS - tile.y*(tile.y+1)/2;\n"
"            }\n"
"            else\n"
"                skipTiles[threadIdx.x] = end;\n"
"            skipBase += TILE_SIZE;            \n"
"            currentSkipIndex = tbx;\n"
"        }\n"
"        while (skipTiles[currentSkipIndex] < pos)\n"
"            currentSkipIndex++;\n"
"        includeTile = (skipTiles[currentSkipIndex] != pos);\n"
"#endif\n"
"        if (includeTile) {\n"
"            unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"\n"
"            // Load atom data for this tile.\n"
"\n"
"            real4 pos1 = posq[atom1];\n"
"            LOAD_ATOM1_PARAMETERS\n"
"            const unsigned int localAtomIndex = threadIdx.x;\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int j = interactingAtoms[pos*TILE_SIZE+tgx];\n"
"#else\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            atomIndices[threadIdx.x] = j;\n"
"            if (j < PADDED_NUM_ATOMS) {\n"
"                real4 tempPosq = posq[j];\n"
"                localData[localAtomIndex].pos = make_real3(tempPosq.x, tempPosq.y, tempPosq.z);\n"
"                LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"                localData[localAtomIndex].force = make_real3(0);\n"
"                CLEAR_LOCAL_DERIVATIVES\n"
"            }\n"
"#ifdef USE_PERIODIC\n"
"            if (singlePeriodicCopy) {\n"
"                // The box is small enough that we can just translate all the atoms into a single periodic\n"
"                // box, then skip having to apply periodic boundary conditions later.\n"
"\n"
"                real4 blockCenterX = blockCenter[x];\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(pos1, blockCenterX)\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(localData[threadIdx.x].pos, blockCenterX)\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = tbx+tj;\n"
"                    real3 pos2 = localData[atom2].pos;\n"
"                    real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                    if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        LOAD_ATOM2_PARAMETERS\n"
"                        atom2 = atomIndices[tbx+tj];\n"
"                        real dEdR = 0;\n"
"                        real tempEnergy = 0;\n"
"                        const real interactionScale = 1;\n"
"                        if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                            COMPUTE_INTERACTION\n"
"                            dEdR /= -r;\n"
"                        }\n"
"                        if (needEnergy)\n"
"                            energy += tempEnergy;\n"
"                        delta *= dEdR;\n"
"                        force.x -= delta.x;\n"
"                        force.y -= delta.y;\n"
"                        force.z -= delta.z;\n"
"                        atom2 = tbx+tj;\n"
"                        localData[atom2].force.x += delta.x;\n"
"                        localData[atom2].force.y += delta.y;\n"
"                        localData[atom2].force.z += delta.z;\n"
"                        RECORD_DERIVATIVE_2\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"            else\n"
"#endif\n"
"            {\n"
"                // We need to apply periodic boundary conditions separately for each interaction.\n"
"\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = tbx+tj;\n"
"                    real3 pos2 = localData[atom2].pos;\n"
"                    real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#ifdef USE_PERIODIC\n"
"                    APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                    if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        LOAD_ATOM2_PARAMETERS\n"
"                        atom2 = atomIndices[tbx+tj];\n"
"                        real dEdR = 0;\n"
"                        real tempEnergy = 0;\n"
"                        const real interactionScale = 1;\n"
"                        if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                            COMPUTE_INTERACTION\n"
"                            dEdR /= -r;\n"
"                        }\n"
"                        if (needEnergy)\n"
"                            energy += tempEnergy;\n"
"                        delta *= dEdR;\n"
"                        force.x -= delta.x;\n"
"                        force.y -= delta.y;\n"
"                        force.z -= delta.z;\n"
"                        atom2 = tbx+tj;\n"
"                        localData[atom2].force.x += delta.x;\n"
"                        localData[atom2].force.y += delta.y;\n"
"                        localData[atom2].force.z += delta.z;\n"
"                        RECORD_DERIVATIVE_2\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"        \n"
"            // Write results.\n"
"\n"
"            atomicAdd(&forceBuffers[atom1], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"            unsigned int offset = atom1;\n"
"            STORE_DERIVATIVES_1\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int atom2 = atomIndices[threadIdx.x];\n"
"#else\n"
"            unsigned int atom2 = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            if (atom2 < PADDED_NUM_ATOMS) {\n"
"                atomicAdd(&forceBuffers[atom2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].force.x*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].force.y*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].force.z*0x100000000)));\n"
"                offset = atom2;\n"
"                STORE_DERIVATIVES_2\n"
"            }\n"
"        }\n"
"        pos++;\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"    SAVE_PARAM_DERIVS\n"
"}\n"
"";
const string CudaKernelSources::customGBEnergyPerParticle = "/**\n"
" * Reduce the derivatives computed in the N^2 energy kernel, and compute all per-particle energy terms.\n"
" */\n"
"\n"
"extern \"C\" __global__ void computePerParticleEnergy(long long* __restrict__ forceBuffers, mixed* __restrict__ energyBuffer, const real4* __restrict__ posq\n"
"        PARAMETER_ARGUMENTS) {\n"
"    mixed energy = 0;\n"
"    INIT_PARAM_DERIVS\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        // Load the derivatives\n"
"\n"
"        LOAD_DERIVATIVES\n"
"\n"
"        // Now calculate the per-particle energy terms.\n"
"\n"
"        real4 pos = posq[index];\n"
"        real3 force = make_real3(0, 0, 0);\n"
"        COMPUTE_ENERGY\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"    SAVE_PARAM_DERIVS\n"
"}\n"
"";
const string CudaKernelSources::customGBGradientChainRule = "/**\n"
" * Compute chain rule terms for computed values that depend explicitly on particle coordinates.\n"
" */\n"
"\n"
"extern \"C\" __global__ void computeGradientChainRuleTerms(long long* __restrict__ forceBuffers, const real4* __restrict__ posq\n"
"        PARAMETER_ARGUMENTS) {\n"
"    INIT_PARAM_DERIVS\n"
"    const real scale = RECIP((real) 0x100000000);\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        real4 pos = posq[index];\n"
"        real3 force = make_real3(scale*forceBuffers[index], scale*forceBuffers[index+PADDED_NUM_ATOMS], scale*forceBuffers[index+PADDED_NUM_ATOMS*2]);\n"
"        COMPUTE_FORCES\n"
"        forceBuffers[index] = (long long) (force.x*0x100000000);\n"
"        forceBuffers[index+PADDED_NUM_ATOMS] = (long long) (force.y*0x100000000);\n"
"        forceBuffers[index+PADDED_NUM_ATOMS*2] = (long long) (force.z*0x100000000);\n"
"    }\n"
"    SAVE_PARAM_DERIVS\n"
"}\n"
"";
const string CudaKernelSources::customGBValueN2 = "typedef struct {\n"
"    real3 pos;\n"
"    real value;\n"
"    ATOM_PARAMETER_DATA\n"
"#ifdef NEED_PADDING\n"
"    float padding;\n"
"#endif\n"
"} AtomData;\n"
"\n"
"/**\n"
" * Compute a value based on pair interactions.\n"
" */\n"
"extern \"C\" __global__ void computeN2Value(const real4* __restrict__ posq, const unsigned int* __restrict__ exclusions,\n"
"        const ushort2* __restrict__ exclusionTiles, unsigned long long* __restrict__ global_value,\n"
"#ifdef USE_CUTOFF\n"
"        const int* __restrict__ tiles, const unsigned int* __restrict__ interactionCount, real4 periodicBoxSize, real4 invPeriodicBoxSize,\n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ, unsigned int maxTiles, const real4* __restrict__ blockCenter,\n"
"        const real4* __restrict__ blockSize, const unsigned int* __restrict__ interactingAtoms\n"
"#else\n"
"        unsigned int numTiles\n"
"#endif\n"
"        PARAMETER_ARGUMENTS) {\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE;\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1);\n"
"    const unsigned int tbx = threadIdx.x - tgx;\n"
"    __shared__ AtomData localData[THREAD_BLOCK_SIZE];\n"
"\n"
"    // First loop: process tiles that contain exclusions.\n"
"    \n"
"    const unsigned int firstExclusionTile = FIRST_EXCLUSION_TILE+warp*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    const unsigned int lastExclusionTile = FIRST_EXCLUSION_TILE+(warp+1)*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    for (int pos = firstExclusionTile; pos < lastExclusionTile; pos++) {\n"
"        const ushort2 tileIndices = exclusionTiles[pos];\n"
"        const unsigned int x = tileIndices.x;\n"
"        const unsigned int y = tileIndices.y;\n"
"        real value = 0;\n"
"        unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"        real4 pos1 = posq[atom1];\n"
"        LOAD_ATOM1_PARAMETERS\n"
"#ifdef USE_EXCLUSIONS\n"
"        unsigned int excl = exclusions[pos*TILE_SIZE+tgx];\n"
"#endif\n"
"        if (x == y) {\n"
"            // This tile is on the diagonal.\n"
"\n"
"            const unsigned int localAtomIndex = threadIdx.x;\n"
"            localData[localAtomIndex].pos = make_real3(pos1.x, pos1.y, pos1.z);\n"
"            LOAD_LOCAL_PARAMETERS_FROM_1\n"
"            for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                int atom2 = tbx+j;\n"
"                real3 pos2 = localData[atom2].pos;\n"
"                real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    atom2 = y*TILE_SIZE+j;\n"
"                    real tempValue1 = 0;\n"
"                    real tempValue2 = 0;\n"
"#ifdef USE_EXCLUSIONS\n"
"                    bool isExcluded = (atom1 >= NUM_ATOMS || atom2 >= NUM_ATOMS || !(excl & 0x1));\n"
"                    if (!isExcluded && atom1 != atom2) {\n"
"#else\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && atom1 != atom2) {\n"
"#endif\n"
"                        COMPUTE_VALUE\n"
"                    }\n"
"                    value += tempValue1;\n"
"                    ADD_TEMP_DERIVS1\n"
"#ifdef USE_CUTOFF\n"
"                }\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                excl >>= 1;\n"
"#endif\n"
"            }\n"
"        }\n"
"        else {\n"
"            // This is an off-diagonal tile.\n"
"\n"
"            const unsigned int localAtomIndex = threadIdx.x;\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"            real4 tempPosq = posq[j];\n"
"            localData[localAtomIndex].pos = make_real3(tempPosq.x, tempPosq.y, tempPosq.z);\n"
"            LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"            localData[localAtomIndex].value = 0;\n"
"#ifdef USE_EXCLUSIONS\n"
"            excl = (excl >> tgx) | (excl << (TILE_SIZE - tgx));\n"
"#endif\n"
"            unsigned int tj = tgx;\n"
"            for (j = 0; j < TILE_SIZE; j++) {\n"
"                int atom2 = tbx+tj;\n"
"                real3 pos2 = localData[atom2].pos;\n"
"                real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    atom2 = y*TILE_SIZE+tj;\n"
"                    real tempValue1 = 0;\n"
"                    real tempValue2 = 0;\n"
"#ifdef USE_EXCLUSIONS\n"
"                    bool isExcluded = (atom1 >= NUM_ATOMS || atom2 >= NUM_ATOMS || !(excl & 0x1));\n"
"                    if (!isExcluded) {\n"
"#else\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"#endif\n"
"                        COMPUTE_VALUE\n"
"                    }\n"
"                    value += tempValue1;\n"
"                    localData[tbx+tj].value += tempValue2;\n"
"                    ADD_TEMP_DERIVS1\n"
"                    ADD_TEMP_DERIVS2\n"
"#ifdef USE_CUTOFF\n"
"                }\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                excl >>= 1;\n"
"#endif\n"
"                tj = (tj + 1) & (TILE_SIZE - 1);\n"
"            }\n"
"        }\n"
"\n"
"        // Write results.\n"
"\n"
"        unsigned int offset1 = x*TILE_SIZE + tgx;\n"
"        atomicAdd(&global_value[offset1], static_cast<unsigned long long>((long long) (value*0x100000000)));\n"
"        STORE_PARAM_DERIVS1\n"
"        if (x != y) {\n"
"            unsigned int offset2 = y*TILE_SIZE + tgx;\n"
"            atomicAdd(&global_value[offset2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].value*0x100000000)));\n"
"            STORE_PARAM_DERIVS2\n"
"        }\n"
"    }\n"
"\n"
"    // Second loop: tiles without exclusions, either from the neighbor list (with cutoff) or just enumerating all\n"
"    // of them (no cutoff).\n"
"\n"
"#ifdef USE_CUTOFF\n"
"    unsigned int numTiles = interactionCount[0];\n"
"    if (numTiles > maxTiles)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    int pos = (int) (warp*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"    int end = (int) ((warp+1)*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"#else\n"
"    int pos = (int) (warp*(long long)numTiles/totalWarps);\n"
"    int end = (int) ((warp+1)*(long long)numTiles/totalWarps);\n"
"#endif\n"
"    int skipBase = 0;\n"
"    int currentSkipIndex = tbx;\n"
"    __shared__ int atomIndices[THREAD_BLOCK_SIZE];\n"
"    __shared__ volatile int skipTiles[THREAD_BLOCK_SIZE];\n"
"    skipTiles[threadIdx.x] = -1;\n"
"    \n"
"    while (pos < end) {\n"
"        real value = 0;\n"
"        bool includeTile = true;\n"
"        \n"
"        // Extract the coordinates of this tile.\n"
"        \n"
"        int x, y;\n"
"        bool singlePeriodicCopy = false;\n"
"#ifdef USE_CUTOFF\n"
"        x = tiles[pos];\n"
"        real4 blockSizeX = blockSize[x];\n"
"        singlePeriodicCopy = (0.5f*periodicBoxSize.x-blockSizeX.x >= CUTOFF &&\n"
"                              0.5f*periodicBoxSize.y-blockSizeX.y >= CUTOFF &&\n"
"                              0.5f*periodicBoxSize.z-blockSizeX.z >= CUTOFF);\n"
"#else\n"
"        y = (int) floor(NUM_BLOCKS+0.5f-SQRT((NUM_BLOCKS+0.5f)*(NUM_BLOCKS+0.5f)-2*pos));\n"
"        x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        if (x < y || x >= NUM_BLOCKS) { // Occasionally happens due to roundoff error.\n"
"            y += (x < y ? -1 : 1);\n"
"            x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        }\n"
"\n"
"        // Skip over tiles that have exclusions, since they were already processed.\n"
"\n"
"        while (skipTiles[tbx+TILE_SIZE-1] < pos) {\n"
"            if (skipBase+tgx < NUM_TILES_WITH_EXCLUSIONS) {\n"
"                ushort2 tile = exclusionTiles[skipBase+tgx];\n"
"                skipTiles[threadIdx.x] = tile.x + tile.y*NUM_BLOCKS - tile.y*(tile.y+1)/2;\n"
"            }\n"
"            else\n"
"                skipTiles[threadIdx.x] = end;\n"
"            skipBase += TILE_SIZE;            \n"
"            currentSkipIndex = tbx;\n"
"        }\n"
"        while (skipTiles[currentSkipIndex] < pos)\n"
"            currentSkipIndex++;\n"
"        includeTile = (skipTiles[currentSkipIndex] != pos);\n"
"#endif\n"
"        if (includeTile) {\n"
"            unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"\n"
"            // Load atom data for this tile.\n"
"            \n"
"            real4 pos1 = posq[atom1];\n"
"            LOAD_ATOM1_PARAMETERS\n"
"            const unsigned int localAtomIndex = threadIdx.x;\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int j = interactingAtoms[pos*TILE_SIZE+tgx];\n"
"#else\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            atomIndices[threadIdx.x] = j;\n"
"            if (j < PADDED_NUM_ATOMS) {\n"
"                real4 tempPosq = posq[j];\n"
"                localData[localAtomIndex].pos = make_real3(tempPosq.x, tempPosq.y, tempPosq.z);\n"
"                LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"                localData[localAtomIndex].value = 0;\n"
"            }\n"
"#ifdef USE_PERIODIC\n"
"            if (singlePeriodicCopy) {\n"
"                // The box is small enough that we can just translate all the atoms into a single periodic\n"
"                // box, then skip having to apply periodic boundary conditions later.\n"
"\n"
"                real4 blockCenterX = blockCenter[x];\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(pos1, blockCenterX)\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(localData[threadIdx.x].pos, blockCenterX)\n"
"                unsigned int tj = tgx;\n"
"                for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = tbx+tj;\n"
"                    real3 pos2 = localData[atom2].pos;\n"
"                    real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                    if (r2 < CUTOFF_SQUARED) {\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        LOAD_ATOM2_PARAMETERS\n"
"                        atom2 = atomIndices[tbx+tj];\n"
"                        real tempValue1 = 0;\n"
"                        real tempValue2 = 0;\n"
"                        if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                            COMPUTE_VALUE\n"
"                        }\n"
"                        value += tempValue1;\n"
"                        localData[tbx+tj].value += tempValue2;\n"
"                        ADD_TEMP_DERIVS1\n"
"                        ADD_TEMP_DERIVS2\n"
"                    }\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"            else\n"
"#endif\n"
"            {\n"
"                // We need to apply periodic boundary conditions separately for each interaction.\n"
"\n"
"                unsigned int tj = tgx;\n"
"                for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = tbx+tj;\n"
"                    real3 pos2 = localData[atom2].pos;\n"
"                    real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"#ifdef USE_PERIODIC\n"
"                    APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                    if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        LOAD_ATOM2_PARAMETERS\n"
"                        atom2 = atomIndices[tbx+tj];\n"
"                        real tempValue1 = 0;\n"
"                        real tempValue2 = 0;\n"
"                        if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                            COMPUTE_VALUE\n"
"                        }\n"
"                        value += tempValue1;\n"
"                        localData[tbx+tj].value += tempValue2;\n"
"                        ADD_TEMP_DERIVS1\n"
"                        ADD_TEMP_DERIVS2\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"        \n"
"            // Write results.\n"
"\n"
"            unsigned int offset1 = atom1;\n"
"            atomicAdd(&global_value[offset1], static_cast<unsigned long long>((long long) (value*0x100000000)));\n"
"            STORE_PARAM_DERIVS1\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int atom2 = atomIndices[threadIdx.x];\n"
"#else\n"
"            unsigned int atom2 = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            if (atom2 < PADDED_NUM_ATOMS) {\n"
"                unsigned int offset2 = atom2;\n"
"                atomicAdd(&global_value[offset2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].value*0x100000000)));\n"
"                STORE_PARAM_DERIVS2\n"
"            }\n"
"        }\n"
"        pos++;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customGBValuePerParticle = "/**\n"
" * Reduce a pairwise computed value, and compute per-particle values.\n"
" */\n"
"\n"
"extern \"C\" __global__ void computePerParticleValues(real4* posq, long long* valueBuffers\n"
"        PARAMETER_ARGUMENTS) {\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        // Load the pairwise value\n"
"\n"
"        real sum = valueBuffers[index]/(real) 0x100000000;\n"
"        REDUCE_PARAM0_DERIV\n"
"        \n"
"        // Now calculate other values\n"
"\n"
"        real4 pos = posq[index];\n"
"        COMPUTE_VALUES\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customHbondForce = "/**\n"
" * Convert a real4 to a real3 by removing its last element.\n"
" */\n"
"inline __device__ real3 trim(real4 v) {\n"
"    return make_real3(v.x, v.y, v.z);\n"
"}\n"
"\n"
"/**\n"
" * This does nothing, and just exists to simplify the code generation.\n"
" */\n"
"inline __device__ real3 trim(real3 v) {\n"
"    return v;\n"
"}\n"
"\n"
"/**\n"
" * Compute the difference between two vectors, optionally taking periodic boundary conditions into account\n"
" * and setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 delta(real4 vec1, real4 vec2, real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ) {\n"
"    real4 result = make_real4(vec1.x-vec2.x, vec1.y-vec2.y, vec1.z-vec2.z, 0.0f);\n"
"#ifdef USE_PERIODIC\n"
"    APPLY_PERIODIC_TO_DELTA(result)\n"
"#endif\n"
"    result.w = result.x*result.x + result.y*result.y + result.z*result.z;\n"
"    return result;\n"
"}\n"
"\n"
"/**\n"
" * Compute the angle between two vectors.  The w component of each vector should contain the squared magnitude.\n"
" */\n"
"inline __device__ real computeAngle(real4 vec1, real4 vec2) {\n"
"    real dotProduct = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n"
"    real cosine = dotProduct*RSQRT(vec1.w*vec2.w);\n"
"    real angle;\n"
"    if (cosine > 0.99f || cosine < -0.99f) {\n"
"        // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"        real3 crossProduct = cross(vec1, vec2);\n"
"        real scale = vec1.w*vec2.w;\n"
"        angle = ASIN(SQRT(dot(crossProduct, crossProduct)/scale));\n"
"        if (cosine < 0.0f)\n"
"            angle = M_PI-angle;\n"
"    }\n"
"    else\n"
"       angle = ACOS(cosine);\n"
"    return angle;\n"
"}\n"
"\n"
"/**\n"
" * Compute the cross product of two vectors, setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 computeCross(real4 vec1, real4 vec2) {\n"
"    real3 result = cross(vec1, vec2);\n"
"    return make_real4(result.x, result.y, result.z, result.x*result.x + result.y*result.y + result.z*result.z);\n"
"}\n"
"\n"
"/**\n"
" * Compute forces on donors.\n"
" */\n"
"extern \"C\" __global__ void computeDonorForces(unsigned long long* __restrict__ force, mixed* __restrict__ energyBuffer, const real4* __restrict__ posq,\n"
"        const int4* __restrict__ exclusions, const int4* __restrict__ donorAtoms, const int4* __restrict__ acceptorAtoms, real4 periodicBoxSize, real4 invPeriodicBoxSize,\n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ\n"
"        PARAMETER_ARGUMENTS) {\n"
"    extern __shared__ real4 posBuffer[];\n"
"    mixed energy = 0;\n"
"    real3 f1 = make_real3(0);\n"
"    real3 f2 = make_real3(0);\n"
"    real3 f3 = make_real3(0);\n"
"    for (int donorStart = 0; donorStart < NUM_DONORS; donorStart += blockDim.x*gridDim.x) {\n"
"        // Load information about the donor this thread will compute forces on.\n"
"\n"
"        int donorIndex = donorStart+blockIdx.x*blockDim.x+threadIdx.x;\n"
"        int4 atoms, exclusionIndices;\n"
"        real4 d1, d2, d3;\n"
"        if (donorIndex < NUM_DONORS) {\n"
"            atoms = donorAtoms[donorIndex];\n"
"            d1 = (atoms.x > -1 ? posq[atoms.x] : make_real4(0));\n"
"            d2 = (atoms.y > -1 ? posq[atoms.y] : make_real4(0));\n"
"            d3 = (atoms.z > -1 ? posq[atoms.z] : make_real4(0));\n"
"#ifdef USE_EXCLUSIONS\n"
"            exclusionIndices = exclusions[donorIndex];\n"
"#endif\n"
"        }\n"
"        else\n"
"            atoms = make_int4(-1, -1, -1, -1);\n"
"        for (int acceptorStart = 0; acceptorStart < NUM_ACCEPTORS; acceptorStart += blockDim.x) {\n"
"            // Load the next block of acceptors into local memory.\n"
"\n"
"            __syncthreads();\n"
"            int blockSize = min((int) blockDim.x, NUM_ACCEPTORS-acceptorStart);\n"
"            if (threadIdx.x < blockSize) {\n"
"                int4 atoms2 = acceptorAtoms[acceptorStart+threadIdx.x];\n"
"                posBuffer[3*threadIdx.x] = (atoms2.x > -1 ? posq[atoms2.x] : make_real4(0));\n"
"                posBuffer[3*threadIdx.x+1] = (atoms2.y > -1 ? posq[atoms2.y] : make_real4(0));\n"
"                posBuffer[3*threadIdx.x+2] = (atoms2.z > -1 ? posq[atoms2.z] : make_real4(0));\n"
"            }\n"
"            __syncthreads();\n"
"            if (donorIndex < NUM_DONORS) {\n"
"                for (int index = 0; index < blockSize; index++) {\n"
"                    int acceptorIndex = acceptorStart+index;\n"
"#ifdef USE_EXCLUSIONS\n"
"                    if (acceptorIndex == exclusionIndices.x || acceptorIndex == exclusionIndices.y || acceptorIndex == exclusionIndices.z || acceptorIndex == exclusionIndices.w)\n"
"                        continue;\n"
"#endif\n"
"                    // Compute the interaction between a donor and an acceptor.\n"
"\n"
"                    real4 a1 = posBuffer[3*index];\n"
"                    real4 a2 = posBuffer[3*index+1];\n"
"                    real4 a3 = posBuffer[3*index+2];\n"
"                    real4 deltaD1A1 = delta(d1, a1, periodicBoxSize, invPeriodicBoxSize, periodicBoxVecX, periodicBoxVecY, periodicBoxVecZ);\n"
"#ifdef USE_CUTOFF\n"
"                    if (deltaD1A1.w < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        COMPUTE_DONOR_FORCE\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                }\n"
"            }\n"
"        }\n"
"\n"
"        // Write results\n"
"\n"
"        if (donorIndex < NUM_DONORS) {\n"
"            if (atoms.x > -1) {\n"
"                atomicAdd(&force[atoms.x], static_cast<unsigned long long>((long long) (f1.x*0x100000000)));\n"
"                atomicAdd(&force[atoms.x+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f1.y*0x100000000)));\n"
"                atomicAdd(&force[atoms.x+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f1.z*0x100000000)));\n"
"                __threadfence_block();\n"
"            }\n"
"            if (atoms.y > -1) {\n"
"                atomicAdd(&force[atoms.y], static_cast<unsigned long long>((long long) (f2.x*0x100000000)));\n"
"                atomicAdd(&force[atoms.y+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f2.y*0x100000000)));\n"
"                atomicAdd(&force[atoms.y+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f2.z*0x100000000)));\n"
"                __threadfence_block();\n"
"            }\n"
"            if (atoms.z > -1) {\n"
"                atomicAdd(&force[atoms.z], static_cast<unsigned long long>((long long) (f3.x*0x100000000)));\n"
"                atomicAdd(&force[atoms.z+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f3.y*0x100000000)));\n"
"                atomicAdd(&force[atoms.z+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f3.z*0x100000000)));\n"
"                __threadfence_block();\n"
"            }\n"
"        }\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"}\n"
"/**\n"
" * Compute forces on acceptors.\n"
" */\n"
"extern \"C\" __global__ void computeAcceptorForces(unsigned long long* __restrict__ force, mixed* __restrict__ energyBuffer, const real4* __restrict__ posq,\n"
"        const int4* __restrict__ exclusions, const int4* __restrict__ donorAtoms, const int4* __restrict__ acceptorAtoms, real4 periodicBoxSize, real4 invPeriodicBoxSize,\n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ\n"
"        PARAMETER_ARGUMENTS) {\n"
"    extern __shared__ real4 posBuffer[];\n"
"    real3 f1 = make_real3(0);\n"
"    real3 f2 = make_real3(0);\n"
"    real3 f3 = make_real3(0);\n"
"    for (int acceptorStart = 0; acceptorStart < NUM_ACCEPTORS; acceptorStart += blockDim.x*gridDim.x) {\n"
"        // Load information about the acceptor this thread will compute forces on.\n"
"\n"
"        int acceptorIndex = acceptorStart+blockIdx.x*blockDim.x+threadIdx.x;\n"
"        int4 atoms, exclusionIndices;\n"
"        real4 a1, a2, a3;\n"
"        if (acceptorIndex < NUM_ACCEPTORS) {\n"
"            atoms = acceptorAtoms[acceptorIndex];\n"
"            a1 = (atoms.x > -1 ? posq[atoms.x] : make_real4(0));\n"
"            a2 = (atoms.y > -1 ? posq[atoms.y] : make_real4(0));\n"
"            a3 = (atoms.z > -1 ? posq[atoms.z] : make_real4(0));\n"
"#ifdef USE_EXCLUSIONS\n"
"            exclusionIndices = exclusions[acceptorIndex];\n"
"#endif\n"
"        }\n"
"        else\n"
"            atoms = make_int4(-1, -1, -1, -1);\n"
"        for (int donorStart = 0; donorStart < NUM_DONORS; donorStart += blockDim.x) {\n"
"            // Load the next block of donors into local memory.\n"
"\n"
"            __syncthreads();\n"
"            int blockSize = min((int) blockDim.x, NUM_DONORS-donorStart);\n"
"            if (threadIdx.x < blockSize) {\n"
"                int4 atoms2 = donorAtoms[donorStart+threadIdx.x];\n"
"                posBuffer[3*threadIdx.x] = (atoms2.x > -1 ? posq[atoms2.x] : make_real4(0));\n"
"                posBuffer[3*threadIdx.x+1] = (atoms2.y > -1 ? posq[atoms2.y] : make_real4(0));\n"
"                posBuffer[3*threadIdx.x+2] = (atoms2.z > -1 ? posq[atoms2.z] : make_real4(0));\n"
"            }\n"
"            __syncthreads();\n"
"            if (acceptorIndex < NUM_ACCEPTORS) {\n"
"                for (int index = 0; index < blockSize; index++) {\n"
"                    int donorIndex = donorStart+index;\n"
"#ifdef USE_EXCLUSIONS\n"
"                    if (donorIndex == exclusionIndices.x || donorIndex == exclusionIndices.y || donorIndex == exclusionIndices.z || donorIndex == exclusionIndices.w)\n"
"                        continue;\n"
"#endif\n"
"                    // Compute the interaction between a donor and an acceptor.\n"
"\n"
"                    real4 d1 = posBuffer[3*index];\n"
"                    real4 d2 = posBuffer[3*index+1];\n"
"                    real4 d3 = posBuffer[3*index+2];\n"
"                    real4 deltaD1A1 = delta(d1, a1, periodicBoxSize, invPeriodicBoxSize, periodicBoxVecX, periodicBoxVecY, periodicBoxVecZ);\n"
"#ifdef USE_CUTOFF\n"
"                    if (deltaD1A1.w < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        COMPUTE_ACCEPTOR_FORCE\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                }\n"
"            }\n"
"        }\n"
"\n"
"        // Write results\n"
"\n"
"        if (acceptorIndex < NUM_ACCEPTORS) {\n"
"            if (atoms.x > -1) {\n"
"                atomicAdd(&force[atoms.x], static_cast<unsigned long long>((long long) (f1.x*0x100000000)));\n"
"                atomicAdd(&force[atoms.x+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f1.y*0x100000000)));\n"
"                atomicAdd(&force[atoms.x+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f1.z*0x100000000)));\n"
"                __threadfence_block();\n"
"            }\n"
"            if (atoms.y > -1) {\n"
"                atomicAdd(&force[atoms.y], static_cast<unsigned long long>((long long) (f2.x*0x100000000)));\n"
"                atomicAdd(&force[atoms.y+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f2.y*0x100000000)));\n"
"                atomicAdd(&force[atoms.y+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f2.z*0x100000000)));\n"
"                __threadfence_block();\n"
"            }\n"
"            if (atoms.z > -1) {\n"
"                atomicAdd(&force[atoms.z], static_cast<unsigned long long>((long long) (f3.x*0x100000000)));\n"
"                atomicAdd(&force[atoms.z+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f3.y*0x100000000)));\n"
"                atomicAdd(&force[atoms.z+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (f3.z*0x100000000)));\n"
"                __threadfence_block();\n"
"            }\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customIntegrator = "extern \"C\" __global__ void computeFloatSum(const float* __restrict__ sumBuffer, float* result) {\n"
"    __shared__ float tempBuffer[WORK_GROUP_SIZE];\n"
"    const unsigned int thread = threadIdx.x;\n"
"    float sum = 0;\n"
"    for (unsigned int index = thread; index < SUM_BUFFER_SIZE; index += blockDim.x)\n"
"        sum += sumBuffer[index];\n"
"    tempBuffer[thread] = sum;\n"
"    for (int i = 1; i < WORK_GROUP_SIZE; i *= 2) {\n"
"        __syncthreads();\n"
"        if (thread%(i*2) == 0 && thread+i < WORK_GROUP_SIZE)\n"
"            tempBuffer[thread] += tempBuffer[thread+i];\n"
"    }\n"
"    if (thread == 0)\n"
"        *result = tempBuffer[0];\n"
"}\n"
"\n"
"extern \"C\" __global__ void computeDoubleSum(const double* __restrict__ sumBuffer, double* result) {\n"
"    __shared__ double tempBuffer[WORK_GROUP_SIZE];\n"
"    const unsigned int thread = threadIdx.x;\n"
"    double sum = 0;\n"
"    for (unsigned int index = thread; index < SUM_BUFFER_SIZE; index += blockDim.x)\n"
"        sum += sumBuffer[index];\n"
"    tempBuffer[thread] = sum;\n"
"    for (int i = 1; i < WORK_GROUP_SIZE; i *= 2) {\n"
"        __syncthreads();\n"
"        if (thread%(i*2) == 0 && thread+i < WORK_GROUP_SIZE)\n"
"            tempBuffer[thread] += tempBuffer[thread+i];\n"
"    }\n"
"    if (thread == 0)\n"
"        *result = tempBuffer[0];\n"
"}\n"
"\n"
"extern \"C\" __global__ void applyPositionDeltas(real4* __restrict__ posq, real4* __restrict__ posqCorrection, mixed4* __restrict__ posDelta) {\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"        real4 pos1 = posq[index];\n"
"        real4 pos2 = posqCorrection[index];\n"
"        mixed4 pos = make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"        real4 pos = posq[index];\n"
"#endif\n"
"        pos.x += posDelta[index].x;\n"
"        pos.y += posDelta[index].y;\n"
"        pos.z += posDelta[index].z;\n"
"#ifdef USE_MIXED_PRECISION\n"
"        posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"        posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"        posq[index] = pos;\n"
"#endif\n"
"        posDelta[index] = make_mixed4(0, 0, 0, 0);\n"
"    }\n"
"}\n"
"\n"
"extern \"C\" __global__ void generateRandomNumbers(int numValues, float4* __restrict__ random, uint4* __restrict__ seed) {\n"
"    uint4 state = seed[blockIdx.x*blockDim.x+threadIdx.x];\n"
"    unsigned int carry = 0;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numValues; index += blockDim.x*gridDim.x) {\n"
"        // Generate three uniform random numbers.\n"
"\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        unsigned int k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        unsigned int m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x1 = (float)max(state.x + state.y + state.w, 0x00000001u) / (float)0xffffffff;\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x2 = (float)max(state.x + state.y + state.w, 0x00000001u) / (float)0xffffffff;\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x3 = (float)max(state.x + state.y + state.w, 0x00000001u) / (float)0xffffffff;\n"
"\n"
"        // Record the values.\n"
"\n"
"        random[index] = make_float4(x1, x2, x3, 0.0f);\n"
"    }\n"
"    seed[blockIdx.x*blockDim.x+threadIdx.x] = state;\n"
"}\n"
"";
const string CudaKernelSources::customIntegratorPerDof = "/**\n"
" * Load the position of a particle.\n"
" */\n"
"inline __device__ mixed4 loadPos(const real4* __restrict__ posq, const real4* __restrict__ posqCorrection, int index) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"    real4 pos1 = posq[index];\n"
"    real4 pos2 = posqCorrection[index];\n"
"    return make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"    return posq[index];\n"
"#endif\n"
"}\n"
"\n"
"/**\n"
" * Store the position of a particle.\n"
" */\n"
"inline __device__ void storePos(real4* __restrict__ posq, real4* __restrict__ posqCorrection, int index, mixed4 pos) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"    posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"    posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"    posq[index] = pos;\n"
"#endif\n"
"}\n"
"\n"
"inline __device__ double4 convertToDouble4(float4 a) {\n"
"    return make_double4(a.x, a.y, a.z, a.w);\n"
"}\n"
"\n"
"inline __device__ double4 convertToDouble4(double4 a) {\n"
"    return a;\n"
"}\n"
"\n"
"inline __device__ mixed4 convertFromDouble4(double4 a) {\n"
"    return make_mixed4(a.x, a.y, a.z, a.w);\n"
"}\n"
"\n"
"extern \"C\" __global__ void computePerDof(real4* __restrict__ posq, real4* __restrict__ posqCorrection, mixed4* __restrict__ posDelta,\n"
"        mixed4* __restrict__ velm, const long long* __restrict__ force, const mixed2* __restrict__ dt, const mixed* __restrict__ globals,\n"
"        mixed* __restrict__ sum, const float4* __restrict__ gaussianValues, unsigned int gaussianBaseIndex, const float4* __restrict__ uniformValues,\n"
"        const mixed energy, mixed* __restrict__ energyParamDerivs\n"
"        PARAMETER_ARGUMENTS) {\n"
"    double3 stepSize = make_double3(dt[0].y);\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    const double forceScale = 1.0/0xFFFFFFFF;\n"
"    while (index < NUM_ATOMS) {\n"
"#ifdef LOAD_POS_AS_DELTA\n"
"        double4 position = convertToDouble4(loadPos(posq, posqCorrection, index)+posDelta[index]);\n"
"#else\n"
"        double4 position = convertToDouble4(loadPos(posq, posqCorrection, index));\n"
"#endif\n"
"        double4 velocity = convertToDouble4(velm[index]);\n"
"        double4 f = make_double4(forceScale*force[index], forceScale*force[index+PADDED_NUM_ATOMS], forceScale*force[index+PADDED_NUM_ATOMS*2], 0.0);\n"
"        double3 mass = make_double3(1.0/velocity.w);\n"
"        if (velocity.w != 0.0) {\n"
"            int gaussianIndex = gaussianBaseIndex;\n"
"            int uniformIndex = 0;\n"
"            COMPUTE_STEP\n"
"        }\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customManyParticle = "/**\n"
" * Record the force on an atom to global memory.\n"
" */\n"
"inline __device__ void storeForce(int atom, real3 force, unsigned long long* __restrict__ forceBuffers) {\n"
"    atomicAdd(&forceBuffers[atom], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"    atomicAdd(&forceBuffers[atom+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"    atomicAdd(&forceBuffers[atom+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"}\n"
"\n"
"/**\n"
" * Convert a real4 to a real3 by removing its last element.\n"
" */\n"
"inline __device__ real3 trim(real4 v) {\n"
"    return make_real3(v.x, v.y, v.z);\n"
"}\n"
"\n"
"/**\n"
" * Compute the difference between two vectors, taking periodic boundary conditions into account\n"
" * and setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 delta(real3 vec1, real3 vec2, real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ) {\n"
"    real4 result = make_real4(vec1.x-vec2.x, vec1.y-vec2.y, vec1.z-vec2.z, 0.0f);\n"
"#ifdef USE_PERIODIC\n"
"    APPLY_PERIODIC_TO_DELTA(result)\n"
"#endif\n"
"    result.w = result.x*result.x + result.y*result.y + result.z*result.z;\n"
"    return result;\n"
"}\n"
"\n"
"/**\n"
" * Compute the angle between two vectors.  The w component of each vector should contain the squared magnitude.\n"
" */\n"
"__device__ real computeAngle(real4 vec1, real4 vec2) {\n"
"    real dotProduct = vec1.x*vec2.x + vec1.y*vec2.y + vec1.z*vec2.z;\n"
"    real cosine = dotProduct*RSQRT(vec1.w*vec2.w);\n"
"    real angle;\n"
"    if (cosine > 0.99f || cosine < -0.99f) {\n"
"        // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"        real3 crossProduct = cross(vec1, vec2);\n"
"        real scale = vec1.w*vec2.w;\n"
"        angle = ASIN(SQRT(dot(crossProduct, crossProduct)/scale));\n"
"        if (cosine < 0.0f)\n"
"            angle = M_PI-angle;\n"
"    }\n"
"    else\n"
"       angle = ACOS(cosine);\n"
"    return angle;\n"
"}\n"
"\n"
"/**\n"
" * Compute the cross product of two vectors, setting the fourth component to the squared magnitude.\n"
" */\n"
"inline __device__ real4 computeCross(real4 vec1, real4 vec2) {\n"
"    real3 cp = cross(vec1, vec2);\n"
"    return make_real4(cp.x, cp.y, cp.z, cp.x*cp.x+cp.y*cp.y+cp.z*cp.z);\n"
"}\n"
"\n"
"/**\n"
" * Determine whether a particular interaction is in the list of exclusions.\n"
" */\n"
"inline __device__ bool isInteractionExcluded(int atom1, int atom2, const int* __restrict__ exclusions, const int* __restrict__ exclusionStartIndex) {\n"
"    if (atom1 > atom2) {\n"
"        int temp = atom1;\n"
"        atom1 = atom2;\n"
"        atom2 = temp;\n"
"    }\n"
"    int first = exclusionStartIndex[atom1];\n"
"    int last = exclusionStartIndex[atom1+1];\n"
"    for (int i = last-1; i >= first; i--) {\n"
"        int excluded = exclusions[i];\n"
"        if (excluded == atom2)\n"
"            return true;\n"
"        if (excluded <= atom1)\n"
"            return false;\n"
"    }\n"
"    return false;\n"
"}\n"
"\n"
"__constant__ float globals[NUM_GLOBALS];\n"
"\n"
"/**\n"
" * Compute the interaction.\n"
" */\n"
"extern \"C\" __global__ void computeInteraction(\n"
"        unsigned long long* __restrict__ forceBuffers, mixed* __restrict__ energyBuffer, const real4* __restrict__ posq,\n"
"        real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ\n"
"#ifdef USE_CUTOFF\n"
"        , const int* __restrict__ neighbors, const int* __restrict__ neighborStartIndex\n"
"#endif\n"
"#ifdef USE_FILTERS\n"
"        , int* __restrict__ particleTypes, int* __restrict__ orderIndex, int* __restrict__ particleOrder\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"        , int* __restrict__ exclusions, int* __restrict__ exclusionStartIndex\n"
"#endif\n"
"        PARAMETER_ARGUMENTS) {\n"
"    mixed energy = 0;\n"
"    \n"
"    // Loop over particles to be the first one in the set.\n"
"    \n"
"    for (int p1 = blockIdx.x; p1 < NUM_ATOMS; p1 += gridDim.x) {\n"
"#ifdef USE_CENTRAL_PARTICLE\n"
"        const int a1 = p1;\n"
"#else\n"
"        const int a1 = 0;\n"
"#endif\n"
"#ifdef USE_CUTOFF\n"
"        int firstNeighbor = neighborStartIndex[p1];\n"
"        int numNeighbors = neighborStartIndex[p1+1]-firstNeighbor;\n"
"#else\n"
"  #ifdef USE_CENTRAL_PARTICLE\n"
"        int numNeighbors = NUM_ATOMS;\n"
"  #else\n"
"        int numNeighbors = NUM_ATOMS-p1-1;\n"
"  #endif\n"
"#endif\n"
"        int numCombinations = NUM_CANDIDATE_COMBINATIONS;\n"
"        for (int index = threadIdx.x; index < numCombinations; index += blockDim.x) {\n"
"            FIND_ATOMS_FOR_COMBINATION_INDEX;\n"
"            bool includeInteraction = IS_VALID_COMBINATION;\n"
"#ifdef USE_CUTOFF\n"
"            if (includeInteraction) {\n"
"                VERIFY_CUTOFF;\n"
"            }\n"
"#endif\n"
"#ifdef USE_FILTERS\n"
"            int order = orderIndex[COMPUTE_TYPE_INDEX];\n"
"            if (order == -1)\n"
"                includeInteraction = false;\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"            if (includeInteraction) {\n"
"                VERIFY_EXCLUSIONS;\n"
"            }\n"
"#endif\n"
"            if (includeInteraction) {\n"
"                PERMUTE_ATOMS;\n"
"                LOAD_PARTICLE_DATA;\n"
"                COMPUTE_INTERACTION;\n"
"            }\n"
"        }\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"}\n"
"\n"
"/**\n"
" * Find a bounding box for the atoms in each block.\n"
" */\n"
"extern \"C\" __global__ void findBlockBounds(real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        const real4* __restrict__ posq, real4* __restrict__ blockCenter, real4* __restrict__ blockBoundingBox, int* __restrict__ numNeighborPairs) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    int base = index*TILE_SIZE;\n"
"    while (base < NUM_ATOMS) {\n"
"        real4 pos = posq[base];\n"
"#ifdef USE_PERIODIC\n"
"        APPLY_PERIODIC_TO_POS(pos)\n"
"#endif\n"
"        real4 minPos = pos;\n"
"        real4 maxPos = pos;\n"
"        int last = min(base+TILE_SIZE, NUM_ATOMS);\n"
"        for (int i = base+1; i < last; i++) {\n"
"            pos = posq[i];\n"
"#ifdef USE_PERIODIC\n"
"            real4 center = 0.5f*(maxPos+minPos);\n"
"            APPLY_PERIODIC_TO_POS_WITH_CENTER(pos, center)\n"
"#endif\n"
"            minPos = make_real4(min(minPos.x,pos.x), min(minPos.y,pos.y), min(minPos.z,pos.z), 0);\n"
"            maxPos = make_real4(max(maxPos.x,pos.x), max(maxPos.y,pos.y), max(maxPos.z,pos.z), 0);\n"
"        }\n"
"        real4 blockSize = 0.5f*(maxPos-minPos);\n"
"        blockBoundingBox[index] = blockSize;\n"
"        blockCenter[index] = 0.5f*(maxPos+minPos);\n"
"        index += blockDim.x*gridDim.x;\n"
"        base = index*TILE_SIZE;\n"
"    }\n"
"    if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"        *numNeighborPairs = 0;\n"
"}\n"
"\n"
"/**\n"
" * Find a list of neighbors for each atom.\n"
" */\n"
"extern \"C\" __global__ void findNeighbors(real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        const real4* __restrict__ posq, const real4* __restrict__ blockCenter, const real4* __restrict__ blockBoundingBox, int2* __restrict__ neighborPairs,\n"
"        int* __restrict__ numNeighborPairs, int* __restrict__ numNeighborsForAtom, int maxNeighborPairs\n"
"#ifdef USE_EXCLUSIONS\n"
"        , const int* __restrict__ exclusions, const int* __restrict__ exclusionStartIndex\n"
"#endif\n"
"        ) {\n"
"    __shared__ real3 positionCache[FIND_NEIGHBORS_WORKGROUP_SIZE];\n"
"    int indexInWarp = threadIdx.x%32;\n"
"    for (int atom1 = blockIdx.x*blockDim.x+threadIdx.x; atom1 < PADDED_NUM_ATOMS; atom1 += blockDim.x*gridDim.x) {\n"
"        // Load data for this atom.  Note that all threads in a warp are processing atoms from the same block.\n"
"        \n"
"        real3 pos1 = trim(posq[atom1]);\n"
"        int block1 = atom1/TILE_SIZE;\n"
"        real4 blockCenter1 = blockCenter[block1];\n"
"        real4 blockSize1 = blockBoundingBox[block1];\n"
"        int totalNeighborsForAtom1 = 0;\n"
"        \n"
"        // Loop over atom blocks to search for neighbors.  The threads in a warp compare block1 against 32\n"
"        // other blocks in parallel.\n"
"\n"
"#ifdef USE_CENTRAL_PARTICLE\n"
"        int startBlock = 0;\n"
"#else\n"
"        int startBlock = block1;\n"
"#endif\n"
"        for (int block2Base = startBlock; block2Base < NUM_BLOCKS; block2Base += 32) {\n"
"            int block2 = block2Base+indexInWarp;\n"
"            bool includeBlock2 = (block2 < NUM_BLOCKS);\n"
"            if (includeBlock2) {\n"
"                real4 blockCenter2 = blockCenter[block2];\n"
"                real4 blockSize2 = blockBoundingBox[block2];\n"
"                real4 blockDelta = blockCenter1-blockCenter2;\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(blockDelta)\n"
"#endif\n"
"                blockDelta.x = max(0.0f, fabs(blockDelta.x)-blockSize1.x-blockSize2.x);\n"
"                blockDelta.y = max(0.0f, fabs(blockDelta.y)-blockSize1.y-blockSize2.y);\n"
"                blockDelta.z = max(0.0f, fabs(blockDelta.z)-blockSize1.z-blockSize2.z);\n"
"                includeBlock2 &= (blockDelta.x*blockDelta.x+blockDelta.y*blockDelta.y+blockDelta.z*blockDelta.z < CUTOFF_SQUARED);\n"
"            }\n"
"            \n"
"            // Loop over any blocks we identified as potentially containing neighbors.\n"
"            \n"
"            int includeBlockFlags = BALLOT(includeBlock2);\n"
"            while (includeBlockFlags != 0) {\n"
"                int i = __ffs(includeBlockFlags)-1;\n"
"                includeBlockFlags &= includeBlockFlags-1;\n"
"                int block2 = block2Base+i;\n"
"\n"
"                // Loop over atoms in this block.\n"
"\n"
"                int start = block2*TILE_SIZE;\n"
"                int included[TILE_SIZE];\n"
"                int numIncluded = 0;\n"
"                positionCache[threadIdx.x] = trim(posq[start+indexInWarp]);\n"
"                if (atom1 < NUM_ATOMS) {\n"
"                    for (int j = 0; j < 32; j++) {\n"
"                        int atom2 = start+j;\n"
"                        real3 pos2 = positionCache[threadIdx.x-indexInWarp+j];\n"
"\n"
"                        // Decide whether to include this atom pair in the neighbor list.\n"
"\n"
"                        real4 atomDelta = delta(pos1, pos2, periodicBoxSize, invPeriodicBoxSize, periodicBoxVecX, periodicBoxVecY, periodicBoxVecZ);\n"
"#ifdef USE_CENTRAL_PARTICLE\n"
"                        bool includeAtom = (atom2 != atom1 && atom2 < NUM_ATOMS && atomDelta.w < CUTOFF_SQUARED);\n"
"#else\n"
"                        bool includeAtom = (atom2 > atom1 && atom2 < NUM_ATOMS && atomDelta.w < CUTOFF_SQUARED);\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                        if (includeAtom)\n"
"                            includeAtom &= !isInteractionExcluded(atom1, atom2, exclusions, exclusionStartIndex);\n"
"#endif\n"
"                        if (includeAtom)\n"
"                            included[numIncluded++] = atom2;\n"
"                    }\n"
"                }\n"
"\n"
"                // If we found any neighbors, store them to the neighbor list.\n"
"\n"
"                if (numIncluded > 0) {\n"
"                    int baseIndex = atomicAdd(numNeighborPairs, numIncluded);\n"
"                    if (baseIndex+numIncluded <= maxNeighborPairs)\n"
"                        for (int j = 0; j < numIncluded; j++)\n"
"                            neighborPairs[baseIndex+j] = make_int2(atom1, included[j]);\n"
"                    totalNeighborsForAtom1 += numIncluded;\n"
"                }\n"
"            }\n"
"        }\n"
"        if (atom1 < NUM_ATOMS)\n"
"            numNeighborsForAtom[atom1] = totalNeighborsForAtom1;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Sum the neighbor counts to compute the start position of each atom.  This kernel\n"
" * is executed as a single work group.\n"
" */\n"
"extern \"C\" __global__ void computeNeighborStartIndices(int* __restrict__ numNeighborsForAtom, int* __restrict__ neighborStartIndex,\n"
"            int* __restrict__ numNeighborPairs, int maxNeighborPairs) {\n"
"    extern __shared__ unsigned int posBuffer[];\n"
"    if (*numNeighborPairs > maxNeighborPairs) {\n"
"        // There wasn't enough memory for the neighbor list, so we'll need to rebuild it.  Set the neighbor start\n"
"        // indices to indicate no neighbors for any atom.\n"
"        \n"
"        for (int i = threadIdx.x; i <= NUM_ATOMS; i += blockDim.x)\n"
"            neighborStartIndex[i] = 0;\n"
"        return;\n"
"    }\n"
"    unsigned int globalOffset = 0;\n"
"    for (unsigned int startAtom = 0; startAtom < NUM_ATOMS; startAtom += blockDim.x) {\n"
"        // Load the neighbor counts into local memory.\n"
"\n"
"        unsigned int globalIndex = startAtom+threadIdx.x;\n"
"        posBuffer[threadIdx.x] = (globalIndex < NUM_ATOMS ? numNeighborsForAtom[globalIndex] : 0);\n"
"        __syncthreads();\n"
"\n"
"        // Perform a parallel prefix sum.\n"
"\n"
"        for (unsigned int step = 1; step < blockDim.x; step *= 2) {\n"
"            unsigned int add = (threadIdx.x >= step ? posBuffer[threadIdx.x-step] : 0);\n"
"            __syncthreads();\n"
"            posBuffer[threadIdx.x] += add;\n"
"            __syncthreads();\n"
"        }\n"
"\n"
"        // Write the results back to global memory.\n"
"\n"
"        if (globalIndex < NUM_ATOMS) {\n"
"            neighborStartIndex[globalIndex+1] = posBuffer[threadIdx.x]+globalOffset;\n"
"            numNeighborsForAtom[globalIndex] = 0; // Clear this so the next kernel can use it as a counter\n"
"        }\n"
"        globalOffset += posBuffer[blockDim.x-1];\n"
"        __syncthreads();\n"
"    }\n"
"    if (threadIdx.x == 0)\n"
"        neighborStartIndex[0] = 0;\n"
"}\n"
"\n"
"/**\n"
" * Assemble the final neighbor list.\n"
" */\n"
"extern \"C\" __global__ void copyPairsToNeighborList(const int2* __restrict__ neighborPairs, int* __restrict__ neighbors, int* __restrict__ numNeighborPairs,\n"
"            int maxNeighborPairs, int* __restrict__ numNeighborsForAtom, const int* __restrict__ neighborStartIndex) {\n"
"    int actualPairs = *numNeighborPairs;\n"
"    if (actualPairs > maxNeighborPairs)\n"
"        return; // There wasn't enough memory for the neighbor list, so we'll need to rebuild it.\n"
"    for (unsigned int index = blockDim.x*blockIdx.x+threadIdx.x; index < actualPairs; index += blockDim.x*gridDim.x) {\n"
"        int2 pair = neighborPairs[index];\n"
"        int startIndex = neighborStartIndex[pair.x];\n"
"        int offset = atomicAdd(numNeighborsForAtom+pair.x, 1);\n"
"        neighbors[startIndex+offset] = pair.y;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::customNonbonded = "#ifdef USE_CUTOFF\n"
"if (!isExcluded && r2 < CUTOFF_SQUARED) {\n"
"#else\n"
"if (!isExcluded) {\n"
"#endif\n"
"    real tempForce = 0;\n"
"    real switchValue = 1, switchDeriv = 0;\n"
"#if USE_SWITCH\n"
"    if (r > SWITCH_CUTOFF) {\n"
"        real x = r-SWITCH_CUTOFF;\n"
"        switchValue = 1+x*x*x*(SWITCH_C3+x*(SWITCH_C4+x*SWITCH_C5));\n"
"        switchDeriv = x*x*(3*SWITCH_C3+x*(4*SWITCH_C4+x*5*SWITCH_C5));\n"
"    }\n"
"#endif\n"
"    COMPUTE_FORCE\n"
"#if USE_SWITCH\n"
"    tempForce = tempForce*switchValue - customEnergy*switchDeriv;\n"
"    tempEnergy += customEnergy*switchValue;\n"
"#else\n"
"    tempEnergy += customEnergy;\n"
"#endif\n"
"    dEdR += tempForce*invR;\n"
"}\n"
"";
const string CudaKernelSources::customNonbondedGroups = "typedef struct {\n"
"    real x, y, z;\n"
"    real q;\n"
"    real fx, fy, fz;\n"
"    ATOM_PARAMETER_DATA\n"
"#ifndef PARAMETER_SIZE_IS_EVEN\n"
"    real padding;\n"
"#endif\n"
"} AtomData;\n"
"\n"
"/**\n"
" * Find the maximum of a value across all threads in a warp, and return that to\n"
" * every thread.  This is only needed on Volta and later.  On earlier architectures,\n"
" * we can just return the value that was passed in.\n"
" */\n"
"__device__ int reduceMax(int val) {\n"
"#if __CUDA_ARCH__ >= 700\n"
"    for (int mask = 16; mask > 0; mask /= 2) \n"
"        val = max(val, __shfl_xor(val, mask));\n"
"#endif\n"
"    return val;\n"
"}\n"
"\n"
"extern \"C\" __global__ void computeInteractionGroups(\n"
"        unsigned long long* __restrict__ forceBuffers, mixed* __restrict__ energyBuffer, const real4* __restrict__ posq, const int4* __restrict__ groupData,\n"
"        const int* __restrict__ numGroupTiles, bool useNeighborList,\n"
"        real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ\n"
"        PARAMETER_ARGUMENTS) {\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE; // global warpIndex\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1); // index within the warp\n"
"    const unsigned int tbx = threadIdx.x - tgx;           // block warpIndex\n"
"    mixed energy = 0;\n"
"    INIT_DERIVATIVES\n"
"    __shared__ AtomData localData[LOCAL_MEMORY_SIZE];\n"
"\n"
"    const unsigned int startTile = (useNeighborList ? warp*numGroupTiles[0]/totalWarps : FIRST_TILE+warp*(LAST_TILE-FIRST_TILE)/totalWarps);\n"
"    const unsigned int endTile = (useNeighborList ? (warp+1)*numGroupTiles[0]/totalWarps : FIRST_TILE+(warp+1)*(LAST_TILE-FIRST_TILE)/totalWarps);\n"
"    for (int tile = startTile; tile < endTile; tile++) {\n"
"        const int4 atomData = groupData[TILE_SIZE*tile+tgx];\n"
"        const int atom1 = atomData.x;\n"
"        const int atom2 = atomData.y;\n"
"        const int rangeStart = atomData.z&0xFFFF;\n"
"        const int rangeEnd = (atomData.z>>16)&0xFFFF;\n"
"        const int exclusions = atomData.w;\n"
"        real4 posq1 = posq[atom1];\n"
"        LOAD_ATOM1_PARAMETERS\n"
"        real3 force = make_real3(0);\n"
"        real4 posq2 = posq[atom2];\n"
"        localData[threadIdx.x].x = posq2.x;\n"
"        localData[threadIdx.x].y = posq2.y;\n"
"        localData[threadIdx.x].z = posq2.z;\n"
"        localData[threadIdx.x].q = posq2.w;\n"
"        LOAD_LOCAL_PARAMETERS\n"
"        localData[threadIdx.x].fx = 0.0f;\n"
"        localData[threadIdx.x].fy = 0.0f;\n"
"        localData[threadIdx.x].fz = 0.0f;\n"
"        int tj = tgx;\n"
"        int rangeStop = rangeStart + reduceMax(rangeEnd-rangeStart);\n"
"        SYNC_WARPS;\n"
"        for (int j = rangeStart; j < rangeStop; j++) {\n"
"            if (j < rangeEnd) {\n"
"                bool isExcluded = (((exclusions>>tj)&1) == 0);\n"
"                int localIndex = tbx+tj;\n"
"                posq2 = make_real4(localData[localIndex].x, localData[localIndex].y, localData[localIndex].z, localData[localIndex].q);\n"
"                real3 delta = make_real3(posq2.x-posq1.x, posq2.y-posq1.y, posq2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (!isExcluded && r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    real dEdR = 0.0f;\n"
"                    real tempEnergy = 0.0f;\n"
"                    const real interactionScale = 1.0f;\n"
"                    COMPUTE_INTERACTION\n"
"                    energy += tempEnergy;\n"
"                    delta *= dEdR;\n"
"                    force.x -= delta.x;\n"
"                    force.y -= delta.y;\n"
"                    force.z -= delta.z;\n"
"                    localData[localIndex].fx += delta.x;\n"
"                    localData[localIndex].fy += delta.y;\n"
"                    localData[localIndex].fz += delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                }\n"
"#endif\n"
"                tj = (tj == rangeEnd-1 ? rangeStart : tj+1);\n"
"            }\n"
"            SYNC_WARPS;\n"
"        }\n"
"        if (exclusions != 0) {\n"
"            atomicAdd(&forceBuffers[atom1], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"        }\n"
"        atomicAdd(&forceBuffers[atom2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fx*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fy*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fz*0x100000000)));\n"
"        SYNC_WARPS;\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"    SAVE_DERIVATIVES\n"
"}\n"
"\n"
"/**\n"
" * If the neighbor list needs to be rebuilt, reset the number of tiles to 0.  This is\n"
" * executed by a single thread.\n"
" */\n"
"extern \"C\" __global__  void prepareToBuildNeighborList(int* __restrict__ rebuildNeighborList, int* __restrict__ numGroupTiles) {\n"
"    if (rebuildNeighborList[0] == 1)\n"
"        numGroupTiles[0] = 0;\n"
"}\n"
"\n"
"/**\n"
" * Filter the list of tiles to include only ones that have interactions within the\n"
" * padded cutoff.\n"
" */\n"
"extern \"C\" __global__  void buildNeighborList(int* __restrict__ rebuildNeighborList, int* __restrict__ numGroupTiles,\n"
"        const real4* __restrict__ posq, const int4* __restrict__ groupData, int4* __restrict__ filteredGroupData,\n"
"        real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ) {\n"
"    \n"
"    // If the neighbor list doesn't need to be rebuilt on this step, return immediately.\n"
"    \n"
"    if (rebuildNeighborList[0] == 0)\n"
"        return;\n"
"\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE; // global warpIndex\n"
"    const unsigned int local_warp = threadIdx.x/TILE_SIZE; // local warpIndex\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1); // index within the warp\n"
"    const unsigned int tbx = threadIdx.x - tgx;           // block warpIndex\n"
"\n"
"    __shared__ real4 localPos[LOCAL_MEMORY_SIZE];\n"
"    __shared__ volatile bool anyInteraction[WARPS_IN_BLOCK];\n"
"    __shared__ volatile int tileIndex[WARPS_IN_BLOCK];\n"
"\n"
"    const unsigned int startTile = warp*NUM_TILES/totalWarps;\n"
"    const unsigned int endTile = (warp+1)*NUM_TILES/totalWarps;\n"
"    for (int tile = startTile; tile < endTile; tile++) {\n"
"        const int4 atomData = groupData[TILE_SIZE*tile+tgx];\n"
"        const int atom1 = atomData.x;\n"
"        const int atom2 = atomData.y;\n"
"        const int rangeStart = atomData.z&0xFFFF;\n"
"        const int rangeEnd = (atomData.z>>16)&0xFFFF;\n"
"        const int exclusions = atomData.w;\n"
"        real4 posq1 = posq[atom1];\n"
"        localPos[threadIdx.x] = posq[atom2];\n"
"        if (tgx == 0)\n"
"            anyInteraction[local_warp] = false;\n"
"        int tj = tgx;\n"
"        int rangeStop = rangeStart + reduceMax(rangeEnd-rangeStart);\n"
"        SYNC_WARPS;\n"
"        for (int j = rangeStart; j < rangeStop && !anyInteraction[local_warp]; j++) {\n"
"            SYNC_WARPS;\n"
"            if (j < rangeEnd && tj < rangeEnd) {\n"
"                bool isExcluded = (((exclusions>>tj)&1) == 0);\n"
"                int localIndex = tbx+tj;\n"
"                real3 delta = make_real3(localPos[localIndex].x-posq1.x, localPos[localIndex].y-posq1.y, localPos[localIndex].z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                if (!isExcluded && r2 < PADDED_CUTOFF_SQUARED)\n"
"                    anyInteraction[local_warp] = true;\n"
"            }\n"
"            tj = (tj == rangeEnd-1 ? rangeStart : tj+1);\n"
"            SYNC_WARPS;\n"
"        }\n"
"        if (anyInteraction[local_warp]) {\n"
"            SYNC_WARPS;\n"
"            if (tgx == 0)\n"
"                tileIndex[local_warp] = atomicAdd(numGroupTiles, 1);\n"
"            SYNC_WARPS;\n"
"            filteredGroupData[TILE_SIZE*tileIndex[local_warp]+tgx] = atomData;\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::ewald = "__device__ real2 multofReal2(real2 a, real2 b) {\n"
"    return make_real2(a.x*b.x - a.y*b.y, a.x*b.y + a.y*b.x);\n"
"}\n"
"\n"
"/**\n"
" * Precompute the cosine and sine sums which appear in each force term.\n"
" */\n"
"\n"
"extern \"C\" __global__ void calculateEwaldCosSinSums(mixed* __restrict__ energyBuffer, const real4* __restrict__ posq, real2* __restrict__ cosSinSum, real4 periodicBoxSize) {\n"
"    const unsigned int ksizex = 2*KMAX_X-1;\n"
"    const unsigned int ksizey = 2*KMAX_Y-1;\n"
"    const unsigned int ksizez = 2*KMAX_Z-1;\n"
"    const unsigned int totalK = ksizex*ksizey*ksizez;\n"
"    real3 reciprocalBoxSize = make_real3(2*M_PI/periodicBoxSize.x, 2*M_PI/periodicBoxSize.y, 2*M_PI/periodicBoxSize.z);\n"
"    real reciprocalCoefficient = ONE_4PI_EPS0*4*M_PI/(periodicBoxSize.x*periodicBoxSize.y*periodicBoxSize.z);\n"
"    unsigned int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    mixed energy = 0;\n"
"    while (index < (KMAX_Y-1)*ksizez+KMAX_Z)\n"
"        index += blockDim.x*gridDim.x;\n"
"    while (index < totalK) {\n"
"        // Find the wave vector (kx, ky, kz) this index corresponds to.\n"
"\n"
"        int rx = index/(ksizey*ksizez);\n"
"        int remainder = index - rx*ksizey*ksizez;\n"
"        int ry = remainder/ksizez;\n"
"        int rz = remainder - ry*ksizez - KMAX_Z + 1;\n"
"        ry += -KMAX_Y + 1;\n"
"        real kx = rx*reciprocalBoxSize.x;\n"
"        real ky = ry*reciprocalBoxSize.y;\n"
"        real kz = rz*reciprocalBoxSize.z;\n"
"\n"
"        // Compute the sum for this wave vector.\n"
"\n"
"        real2 sum = make_real2(0);\n"
"        for (int atom = 0; atom < NUM_ATOMS; atom++) {\n"
"            real4 apos = posq[atom];\n"
"            real phase = apos.x*kx;\n"
"            real2 structureFactor = make_real2(COS(phase), SIN(phase));\n"
"            phase = apos.y*ky;\n"
"            structureFactor = multofReal2(structureFactor, make_real2(COS(phase), SIN(phase)));\n"
"            phase = apos.z*kz;\n"
"            structureFactor = multofReal2(structureFactor, make_real2(COS(phase), SIN(phase)));\n"
"            sum += apos.w*structureFactor;\n"
"        }\n"
"        cosSinSum[index] = sum;\n"
"\n"
"        // Compute the contribution to the energy.\n"
"\n"
"        real k2 = kx*kx + ky*ky + kz*kz;\n"
"        real ak = EXP(k2*EXP_COEFFICIENT) / k2;\n"
"        energy += reciprocalCoefficient*ak*(sum.x*sum.x + sum.y*sum.y);\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"}\n"
"\n"
"/**\n"
" * Compute the reciprocal space part of the Ewald force, using the precomputed sums from the\n"
" * previous routine.\n"
" */\n"
"\n"
"extern \"C\" __global__ void calculateEwaldForces(unsigned long long* __restrict__ forceBuffers, const real4* __restrict__ posq, const real2* __restrict__ cosSinSum, real4 periodicBoxSize) {\n"
"    unsigned int atom = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    real3 reciprocalBoxSize = make_real3(2*M_PI/periodicBoxSize.x, 2*M_PI/periodicBoxSize.y, 2*M_PI/periodicBoxSize.z);\n"
"    real reciprocalCoefficient = ONE_4PI_EPS0*4*M_PI/(periodicBoxSize.x*periodicBoxSize.y*periodicBoxSize.z);\n"
"    while (atom < NUM_ATOMS) {\n"
"        real3 force = make_real3(0);\n"
"        real4 apos = posq[atom];\n"
"\n"
"        // Loop over all wave vectors.\n"
"\n"
"        int lowry = 0;\n"
"        int lowrz = 1;\n"
"        for (int rx = 0; rx < KMAX_X; rx++) {\n"
"            real kx = rx*reciprocalBoxSize.x;\n"
"            for (int ry = lowry; ry < KMAX_Y; ry++) {\n"
"                real ky = ry*reciprocalBoxSize.y;\n"
"                real phase = apos.x*kx;\n"
"                real2 tab_xy = make_real2(COS(phase), SIN(phase));\n"
"                phase = apos.y*ky;\n"
"                tab_xy = multofReal2(tab_xy, make_real2(COS(phase), SIN(phase)));\n"
"                for (int rz = lowrz; rz < KMAX_Z; rz++) {\n"
"                    real kz = rz*reciprocalBoxSize.z;\n"
"\n"
"                    // Compute the force contribution of this wave vector.\n"
"\n"
"                    int index = rx*(KMAX_Y*2-1)*(KMAX_Z*2-1) + (ry+KMAX_Y-1)*(KMAX_Z*2-1) + (rz+KMAX_Z-1);\n"
"                    real k2 = kx*kx + ky*ky + kz*kz;\n"
"                    real ak = EXP(k2*EXP_COEFFICIENT)/k2;\n"
"                    phase = apos.z*kz;\n"
"                    real2 structureFactor = multofReal2(tab_xy, make_real2(COS(phase), SIN(phase)));\n"
"                    real2 sum = cosSinSum[index];\n"
"                    real dEdR = 2*reciprocalCoefficient*ak*apos.w*(sum.x*structureFactor.y - sum.y*structureFactor.x);\n"
"                    force.x += dEdR*kx;\n"
"                    force.y += dEdR*ky;\n"
"                    force.z += dEdR*kz;\n"
"                    lowrz = 1 - KMAX_Z;\n"
"                }\n"
"                lowry = 1 - KMAX_Y;\n"
"            }\n"
"        }\n"
"\n"
"        // Record the force on the atom.\n"
"\n"
"        atomicAdd(&forceBuffers[atom], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"        atom += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::fft = "static __inline__ __device__ real2 multiplyComplex(real2 c1, real2 c2) {\n"
"    return make_real2(c1.x*c2.x-c1.y*c2.y, c1.x*c2.y+c1.y*c2.x);\n"
"}\n"
"\n"
"/**\n"
" * Load a value from the half-complex grid produces by a real-to-complex transform.\n"
" */\n"
"static __inline__ __device__ real2 loadComplexValue(const real2* __restrict__ in, int x, int y, int z) {\n"
"    const int inputZSize = ZSIZE/2+1;\n"
"    if (z < inputZSize)\n"
"        return in[x*YSIZE*inputZSize+y*inputZSize+z];\n"
"    int xp = (x == 0 ? 0 : XSIZE-x);\n"
"    int yp = (y == 0 ? 0 : YSIZE-y);\n"
"    real2 value = in[xp*YSIZE*inputZSize+yp*inputZSize+(ZSIZE-z)];\n"
"    return make_real2(value.x, -value.y);\n"
"}\n"
"\n"
"/**\n"
" * Perform a 1D FFT on each row along one axis.\n"
" */\n"
"\n"
"extern \"C\" __global__ void execFFT(const INPUT_TYPE* __restrict__ in, OUTPUT_TYPE* __restrict__ out) {\n"
"    __shared__ real2 w[ZSIZE];\n"
"    __shared__ real2 data0[BLOCKS_PER_GROUP*ZSIZE];\n"
"    __shared__ real2 data1[BLOCKS_PER_GROUP*ZSIZE];\n"
"    for (int i = threadIdx.x; i < ZSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(cos(-(SIGN)*i*2*M_PI/ZSIZE), sin(-(SIGN)*i*2*M_PI/ZSIZE));\n"
"    __syncthreads();\n"
"    \n"
"    const int block = threadIdx.x/THREADS_PER_BLOCK;\n"
"    for (int baseIndex = blockIdx.x*BLOCKS_PER_GROUP; baseIndex < XSIZE*YSIZE; baseIndex += gridDim.x*BLOCKS_PER_GROUP) {\n"
"        int index = baseIndex+block;\n"
"        int x = index/YSIZE;\n"
"        int y = index-x*YSIZE;\n"
"#if OUTPUT_IS_PACKED\n"
"        if (x < XSIZE/2+1) {\n"
"#endif\n"
"        if (index < XSIZE*YSIZE)\n"
"            for (int i = threadIdx.x-block*THREADS_PER_BLOCK; i < ZSIZE; i += THREADS_PER_BLOCK)\n"
"    #if INPUT_IS_REAL\n"
"                data0[i+block*ZSIZE] = make_real2(in[x*(YSIZE*ZSIZE)+y*ZSIZE+i], 0);\n"
"    #elif INPUT_IS_PACKED\n"
"                data0[i+block*ZSIZE] = loadComplexValue(in, x, y, i);\n"
"    #else\n"
"                data0[i+block*ZSIZE] = in[x*(YSIZE*ZSIZE)+y*ZSIZE+i];\n"
"    #endif\n"
"#if OUTPUT_IS_PACKED\n"
"        }\n"
"#endif\n"
"        __syncthreads();\n"
"        COMPUTE_FFT\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::fftR2C = "/**\n"
" * Combine the two halves of a real grid into a complex grid that is half as large.\n"
" */\n"
"extern \"C\" __global__ void packForwardData(const real* __restrict__ in, real2* __restrict__ out) {\n"
"    const int gridSize = PACKED_XSIZE*PACKED_YSIZE*PACKED_ZSIZE;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x) {\n"
"        int x = index/(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int remainder = index-x*(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int y = remainder/PACKED_ZSIZE;\n"
"        int z = remainder-y*PACKED_ZSIZE;\n"
"#if PACKED_AXIS == 0\n"
"        real2 value = make_real2(in[2*x*YSIZE*ZSIZE+y*ZSIZE+z], in[(2*x+1)*YSIZE*ZSIZE+y*ZSIZE+z]);\n"
"#elif PACKED_AXIS == 1\n"
"        real2 value = make_real2(in[x*YSIZE*ZSIZE+2*y*ZSIZE+z], in[x*YSIZE*ZSIZE+(2*y+1)*ZSIZE+z]);\n"
"#else\n"
"        real2 value = make_real2(in[x*YSIZE*ZSIZE+y*ZSIZE+2*z], in[x*YSIZE*ZSIZE+y*ZSIZE+(2*z+1)]);\n"
"#endif\n"
"        out[index] = value;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Split the transformed data back into a full sized, symmetric grid.\n"
" */\n"
"extern \"C\" __global__ void unpackForwardData(const real2* __restrict__ in, real2* __restrict__ out) {\n"
"    // Compute the phase factors.\n"
"    \n"
"#if PACKED_AXIS == 0\n"
"    __shared__ real2 w[PACKED_XSIZE];\n"
"    for (int i = threadIdx.x; i < PACKED_XSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(sin(i*2*M_PI/XSIZE), cos(i*2*M_PI/XSIZE));\n"
"#elif PACKED_AXIS == 1\n"
"    __shared__ real2 w[PACKED_YSIZE];\n"
"    for (int i = threadIdx.x; i < PACKED_YSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(sin(i*2*M_PI/YSIZE), cos(i*2*M_PI/YSIZE));\n"
"#else\n"
"    __shared__ real2 w[PACKED_ZSIZE];\n"
"    for (int i = threadIdx.x; i < PACKED_ZSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(sin(i*2*M_PI/ZSIZE), cos(i*2*M_PI/ZSIZE));\n"
"#endif\n"
"    __syncthreads();\n"
"\n"
"    // Transform the data.\n"
"    \n"
"    const int gridSize = PACKED_XSIZE*PACKED_YSIZE*PACKED_ZSIZE;\n"
"    const int outputZSize = ZSIZE/2+1;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x) {\n"
"        int x = index/(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int remainder = index-x*(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int y = remainder/PACKED_ZSIZE;\n"
"        int z = remainder-y*PACKED_ZSIZE;\n"
"        int xp = (x == 0 ? 0 : PACKED_XSIZE-x);\n"
"        int yp = (y == 0 ? 0 : PACKED_YSIZE-y);\n"
"        int zp = (z == 0 ? 0 : PACKED_ZSIZE-z);\n"
"        real2 z1 = in[x*PACKED_YSIZE*PACKED_ZSIZE+y*PACKED_ZSIZE+z];\n"
"        real2 z2 = in[xp*PACKED_YSIZE*PACKED_ZSIZE+yp*PACKED_ZSIZE+zp];\n"
"#if PACKED_AXIS == 0\n"
"        real2 wfac = w[x];\n"
"#elif PACKED_AXIS == 1\n"
"        real2 wfac = w[y];\n"
"#else\n"
"        real2 wfac = w[z];\n"
"#endif\n"
"        real2 output = make_real2((z1.x+z2.x - wfac.x*(z1.x-z2.x) + wfac.y*(z1.y+z2.y))/2, (z1.y-z2.y - wfac.y*(z1.x-z2.x) - wfac.x*(z1.y+z2.y))/2);\n"
"        if (z < outputZSize)\n"
"            out[x*YSIZE*outputZSize+y*outputZSize+z] = output;\n"
"        xp = (x == 0 ? 0 : XSIZE-x);\n"
"        yp = (y == 0 ? 0 : YSIZE-y);\n"
"        zp = (z == 0 ? 0 : ZSIZE-z);\n"
"        if (zp < outputZSize) {\n"
"#if PACKED_AXIS == 0\n"
"            if (x == 0)\n"
"                out[PACKED_XSIZE*YSIZE*outputZSize+yp*outputZSize+zp] = make_real2((z1.x-z1.y+z2.x-z2.y)/2, (-z1.x-z1.y+z2.x+z2.y)/2);\n"
"#elif PACKED_AXIS == 1\n"
"            if (y == 0)\n"
"                out[xp*YSIZE*outputZSize+PACKED_YSIZE*outputZSize+zp] = make_real2((z1.x-z1.y+z2.x-z2.y)/2, (-z1.x-z1.y+z2.x+z2.y)/2);\n"
"#else\n"
"            if (z == 0)\n"
"                out[xp*YSIZE*outputZSize+yp*outputZSize+PACKED_ZSIZE] = make_real2((z1.x-z1.y+z2.x-z2.y)/2, (-z1.x-z1.y+z2.x+z2.y)/2);\n"
"#endif\n"
"            else\n"
"                out[xp*YSIZE*outputZSize+yp*outputZSize+zp] = make_real2(output.x, -output.y);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Load a value from the half-complex grid produced by a real-to-complex transform.\n"
" */\n"
"static __inline__ __device__ real2 loadComplexValue(const real2* __restrict__ in, int x, int y, int z) {\n"
"    const int inputZSize = ZSIZE/2+1;\n"
"    if (z < inputZSize)\n"
"        return in[x*YSIZE*inputZSize+y*inputZSize+z];\n"
"    int xp = (x == 0 ? 0 : XSIZE-x);\n"
"    int yp = (y == 0 ? 0 : YSIZE-y);\n"
"    real2 value = in[xp*YSIZE*inputZSize+yp*inputZSize+(ZSIZE-z)];\n"
"    return make_real2(value.x, -value.y);\n"
"}\n"
"\n"
"/**\n"
" * Repack the symmetric complex grid into one half as large in preparation for doing an inverse complex-to-real transform.\n"
" */\n"
"extern \"C\" __global__ void packBackwardData(const real2* __restrict__ in, real2* __restrict__ out) {\n"
"    // Compute the phase factors.\n"
"    \n"
"#if PACKED_AXIS == 0\n"
"    __shared__ real2 w[PACKED_XSIZE];\n"
"    for (int i = threadIdx.x; i < PACKED_XSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(cos(i*2*M_PI/XSIZE), sin(i*2*M_PI/XSIZE));\n"
"#elif PACKED_AXIS == 1\n"
"    __shared__ real2 w[PACKED_YSIZE];\n"
"    for (int i = threadIdx.x; i < PACKED_YSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(cos(i*2*M_PI/YSIZE), sin(i*2*M_PI/YSIZE));\n"
"#else\n"
"    __shared__ real2 w[PACKED_ZSIZE];\n"
"    for (int i = threadIdx.x; i < PACKED_ZSIZE; i += blockDim.x)\n"
"        w[i] = make_real2(cos(i*2*M_PI/ZSIZE), sin(i*2*M_PI/ZSIZE));\n"
"#endif\n"
"    __syncthreads();\n"
"\n"
"    // Transform the data.\n"
"    \n"
"    const int gridSize = PACKED_XSIZE*PACKED_YSIZE*PACKED_ZSIZE;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x) {\n"
"        int x = index/(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int remainder = index-x*(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int y = remainder/PACKED_ZSIZE;\n"
"        int z = remainder-y*PACKED_ZSIZE;\n"
"        int xp = (x == 0 ? 0 : PACKED_XSIZE-x);\n"
"        int yp = (y == 0 ? 0 : PACKED_YSIZE-y);\n"
"        int zp = (z == 0 ? 0 : PACKED_ZSIZE-z);\n"
"        real2 z1 = loadComplexValue(in, x, y, z);\n"
"#if PACKED_AXIS == 0\n"
"        real2 wfac = w[x];\n"
"        real2 z2 = loadComplexValue(in, PACKED_XSIZE-x, yp, zp);\n"
"#elif PACKED_AXIS == 1\n"
"        real2 wfac = w[y];\n"
"        real2 z2 = loadComplexValue(in, xp, PACKED_YSIZE-y, zp);\n"
"#else\n"
"        real2 wfac = w[z];\n"
"        real2 z2 = loadComplexValue(in, xp, yp, PACKED_ZSIZE-z);\n"
"#endif\n"
"        real2 even = make_real2((z1.x+z2.x)/2, (z1.y-z2.y)/2);\n"
"        real2 odd = make_real2((z1.x-z2.x)/2, (z1.y+z2.y)/2);\n"
"        odd = make_real2(odd.x*wfac.x-odd.y*wfac.y, odd.y*wfac.x+odd.x*wfac.y);\n"
"        out[x*PACKED_YSIZE*PACKED_ZSIZE+y*PACKED_ZSIZE+z] = make_real2(even.x-odd.y, even.y+odd.x);\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Split the data back into a full sized, real grid after an inverse transform.\n"
" */\n"
"extern \"C\" __global__ void unpackBackwardData(const real2* __restrict__ in, real* __restrict__ out) {\n"
"    const int gridSize = PACKED_XSIZE*PACKED_YSIZE*PACKED_ZSIZE;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x) {\n"
"        int x = index/(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int remainder = index-x*(PACKED_YSIZE*PACKED_ZSIZE);\n"
"        int y = remainder/PACKED_ZSIZE;\n"
"        int z = remainder-y*PACKED_ZSIZE;\n"
"        real2 value = 2*in[index];\n"
"#if PACKED_AXIS == 0\n"
"        out[2*x*YSIZE*ZSIZE+y*ZSIZE+z] = value.x;\n"
"        out[(2*x+1)*YSIZE*ZSIZE+y*ZSIZE+z] = value.y;\n"
"#elif PACKED_AXIS == 1\n"
"        out[x*YSIZE*ZSIZE+2*y*ZSIZE+z] = value.x;\n"
"        out[x*YSIZE*ZSIZE+(2*y+1)*ZSIZE+z] = value.y;\n"
"#else\n"
"        out[x*YSIZE*ZSIZE+y*ZSIZE+2*z] = value.x;\n"
"        out[x*YSIZE*ZSIZE+y*ZSIZE+(2*z+1)] = value.y;\n"
"#endif\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::findInteractingBlocks = "#define GROUP_SIZE 256\n"
"#define BUFFER_SIZE 256\n"
"\n"
"/**\n"
" * Find a bounding box for the atoms in each block.\n"
" */\n"
"extern \"C\" __global__ void findBlockBounds(int numAtoms, real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        const real4* __restrict__ posq, real4* __restrict__ blockCenter, real4* __restrict__ blockBoundingBox, int* __restrict__ rebuildNeighborList,\n"
"        real2* __restrict__ sortedBlocks) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    int base = index*TILE_SIZE;\n"
"    while (base < numAtoms) {\n"
"        real4 pos = posq[base];\n"
"#ifdef USE_PERIODIC\n"
"        APPLY_PERIODIC_TO_POS(pos)\n"
"#endif\n"
"        real4 minPos = pos;\n"
"        real4 maxPos = pos;\n"
"        int last = min(base+TILE_SIZE, numAtoms);\n"
"        for (int i = base+1; i < last; i++) {\n"
"            pos = posq[i];\n"
"#ifdef USE_PERIODIC\n"
"            real4 center = 0.5f*(maxPos+minPos);\n"
"            APPLY_PERIODIC_TO_POS_WITH_CENTER(pos, center)\n"
"#endif\n"
"            minPos = make_real4(min(minPos.x,pos.x), min(minPos.y,pos.y), min(minPos.z,pos.z), 0);\n"
"            maxPos = make_real4(max(maxPos.x,pos.x), max(maxPos.y,pos.y), max(maxPos.z,pos.z), 0);\n"
"        }\n"
"        real4 blockSize = 0.5f*(maxPos-minPos);\n"
"        real4 center = 0.5f*(maxPos+minPos);\n"
"        center.w = 0;\n"
"        for (int i = base; i < last; i++) {\n"
"            pos = posq[i];\n"
"            real4 delta = posq[i]-center;\n"
"#ifdef USE_PERIODIC\n"
"            APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"            center.w = max(center.w, delta.x*delta.x+delta.y*delta.y+delta.z*delta.z);\n"
"        }\n"
"        center.w = sqrt(center.w);\n"
"        blockBoundingBox[index] = blockSize;\n"
"        blockCenter[index] = center;\n"
"        sortedBlocks[index] = make_real2(blockSize.x+blockSize.y+blockSize.z, index);\n"
"        index += blockDim.x*gridDim.x;\n"
"        base = index*TILE_SIZE;\n"
"    }\n"
"    if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"        rebuildNeighborList[0] = 0;\n"
"}\n"
"\n"
"/**\n"
" * Sort the data about bounding boxes so it can be accessed more efficiently in the next kernel.\n"
" */\n"
"extern \"C\" __global__ void sortBoxData(const real2* __restrict__ sortedBlock, const real4* __restrict__ blockCenter,\n"
"        const real4* __restrict__ blockBoundingBox, real4* __restrict__ sortedBlockCenter,\n"
"        real4* __restrict__ sortedBlockBoundingBox, const real4* __restrict__ posq, const real4* __restrict__ oldPositions,\n"
"        unsigned int* __restrict__ interactionCount, int* __restrict__ rebuildNeighborList, bool forceRebuild) {\n"
"    for (int i = threadIdx.x+blockIdx.x*blockDim.x; i < NUM_BLOCKS; i += blockDim.x*gridDim.x) {\n"
"        int index = (int) sortedBlock[i].y;\n"
"        sortedBlockCenter[i] = blockCenter[index];\n"
"        sortedBlockBoundingBox[i] = blockBoundingBox[index];\n"
"    }\n"
"    \n"
"    // Also check whether any atom has moved enough so that we really need to rebuild the neighbor list.\n"
"\n"
"    bool rebuild = forceRebuild;\n"
"    for (int i = threadIdx.x+blockIdx.x*blockDim.x; i < NUM_ATOMS; i += blockDim.x*gridDim.x) {\n"
"        real4 delta = oldPositions[i]-posq[i];\n"
"        if (delta.x*delta.x + delta.y*delta.y + delta.z*delta.z > 0.25f*PADDING*PADDING)\n"
"            rebuild = true;\n"
"    }\n"
"    if (rebuild) {\n"
"        rebuildNeighborList[0] = 1;\n"
"        interactionCount[0] = 0;\n"
"        interactionCount[1] = 0;\n"
"    }\n"
"}\n"
"\n"
"__device__ int saveSinglePairs(int x, int* atoms, int* flags, int length, unsigned int maxSinglePairs, unsigned int* singlePairCount, int2* singlePairs, int* sumBuffer, volatile int& pairStartIndex) {\n"
"    // Record interactions that should be computed as single pairs rather than in blocks.\n"
"    \n"
"    const int indexInWarp = threadIdx.x%32;\n"
"    int sum = 0;\n"
"    for (int i = indexInWarp; i < length; i += 32) {\n"
"        int count = __popc(flags[i]);\n"
"        sum += (count <= MAX_BITS_FOR_PAIRS ? count : 0);\n"
"    }\n"
"    sumBuffer[indexInWarp] = sum;\n"
"    for (int step = 1; step < 32; step *= 2) {\n"
"        int add = (indexInWarp >= step ? sumBuffer[indexInWarp-step] : 0);\n"
"        sumBuffer[indexInWarp] += add;\n"
"    }\n"
"    int pairsToStore = sumBuffer[31];\n"
"    if (indexInWarp == 0)\n"
"        pairStartIndex = atomicAdd(singlePairCount, pairsToStore);\n"
"    int pairIndex = pairStartIndex + (indexInWarp > 0 ? sumBuffer[indexInWarp-1] : 0);\n"
"    for (int i = indexInWarp; i < length; i += 32) {\n"
"        int count = __popc(flags[i]);\n"
"        if (count <= MAX_BITS_FOR_PAIRS && pairIndex+count < maxSinglePairs) {\n"
"            int f = flags[i];\n"
"            while (f != 0) {\n"
"                singlePairs[pairIndex] = make_int2(atoms[i], x*TILE_SIZE+__ffs(f)-1);\n"
"                f &= f-1;\n"
"                pairIndex++;\n"
"            }\n"
"        }\n"
"    }\n"
"    \n"
"    // Compact the remaining interactions.\n"
"    \n"
"    const int warpMask = (1<<indexInWarp)-1;\n"
"    int numCompacted = 0;\n"
"    for (int start = 0; start < length; start += 32) {\n"
"        int i = start+indexInWarp;\n"
"        int atom = atoms[i];\n"
"        int flag = flags[i];\n"
"        bool include = (i < length && __popc(flags[i]) > MAX_BITS_FOR_PAIRS);\n"
"        int includeFlags = BALLOT(include);\n"
"        if (include) {\n"
"            int index = numCompacted+__popc(includeFlags&warpMask);\n"
"            atoms[index] = atom;\n"
"            flags[index] = flag;\n"
"        }\n"
"        numCompacted += __popc(includeFlags);\n"
"    }\n"
"    return numCompacted;\n"
"}\n"
"\n"
"/**\n"
" * Compare the bounding boxes for each pair of atom blocks (comprised of 32 atoms each), forming a tile. If the two\n"
" * atom blocks are sufficiently far apart, mark them as non-interacting. There are two stages in the algorithm.\n"
" *\n"
" * STAGE 1:\n"
" *\n"
" * A coarse grained atom block against interacting atom block neighbour list is constructed. \n"
" *\n"
" * Each warp first loads in some block X of interest. Each thread within the warp then loads \n"
" * in a different atom block Y. If Y has exclusions with X, then Y is not processed.  If the bounding boxes \n"
" * of the two atom blocks are within the cutoff distance, then the two atom blocks are considered to be\n"
" * interacting and Y is added to the buffer for X.\n"
" *\n"
" * STAGE 2:\n"
" *\n"
" * A fine grained atom block against interacting atoms neighbour list is constructed.\n"
" *\n"
" * The warp loops over atom blocks Y that were found to (possibly) interact with atom block X.  Each thread\n"
" * in the warp loops over the 32 atoms in X and compares their positions to one particular atom from block Y.\n"
" * If it finds one closer than the cutoff distance, the atom is added to the list of atoms interacting with block X.\n"
" * This continues until the buffer fills up, at which point the results are written to global memory.\n"
" *\n"
" * [in] periodicBoxSize        - size of the rectangular periodic box\n"
" * [in] invPeriodicBoxSize     - inverse of the periodic box\n"
" * [in] blockCenter            - the center of each bounding box\n"
" * [in] blockBoundingBox       - bounding box of each atom block\n"
" * [out] interactionCount      - total number of tiles that have interactions\n"
" * [out] interactingTiles      - set of blocks that have interactions\n"
" * [out] interactingAtoms      - a list of atoms that interact with each atom block\n"
" * [in] posq                   - x,y,z coordinates of each atom and charge q\n"
" * [in] maxTiles               - maximum number of tiles to process, used for multi-GPUs\n"
" * [in] startBlockIndex        - first block to process, used for multi-GPUs,\n"
" * [in] numBlocks              - total number of atom blocks\n"
" * [in] sortedBlocks           - a sorted list of atom blocks based on volume\n"
" * [in] sortedBlockCenter      - sorted centers, duplicated for fast access to avoid indexing\n"
" * [in] sortedBlockBoundingBox - sorted bounding boxes, duplicated for fast access\n"
" * [in] exclusionIndices       - maps into exclusionRowIndices with the starting position for a given atom\n"
" * [in] exclusionRowIndices    - stores the a continuous list of exclusions\n"
" *           eg: block 0 is excluded from atom 3,5,6\n"
" *               block 1 is excluded from atom 3,4\n"
" *               block 2 is excluded from atom 1,3,5,6\n"
" *              exclusionIndices[0][3][5][8]\n"
" *           exclusionRowIndices[3][5][6][3][4][1][3][5][6]\n"
" *                         index 0  1  2  3  4  5  6  7  8 \n"
" * [out] oldPos                - stores the positions of the atoms in which this neighbourlist was built on\n"
" *                             - this is used to decide when to rebuild a neighbourlist\n"
" * [in] rebuildNeighbourList   - whether or not to execute this kernel\n"
" *\n"
" */\n"
"extern \"C\" __global__ void findBlocksWithInteractions(real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        unsigned int* __restrict__ interactionCount, int* __restrict__ interactingTiles, unsigned int* __restrict__ interactingAtoms,\n"
"        int2* __restrict__ singlePairs, const real4* __restrict__ posq, unsigned int maxTiles, unsigned int maxSinglePairs,\n"
"        unsigned int startBlockIndex, unsigned int numBlocks, real2* __restrict__ sortedBlocks, const real4* __restrict__ sortedBlockCenter,\n"
"        const real4* __restrict__ sortedBlockBoundingBox, const unsigned int* __restrict__ exclusionIndices, const unsigned int* __restrict__ exclusionRowIndices,\n"
"        real4* __restrict__ oldPositions, const int* __restrict__ rebuildNeighborList) {\n"
"\n"
"    if (rebuildNeighborList[0] == 0)\n"
"        return; // The neighbor list doesn't need to be rebuilt.\n"
"\n"
"    const int indexInWarp = threadIdx.x%32;\n"
"    const int warpStart = threadIdx.x-indexInWarp;\n"
"    const int totalWarps = blockDim.x*gridDim.x/32;\n"
"    const int warpIndex = (blockIdx.x*blockDim.x+threadIdx.x)/32;\n"
"    const int warpMask = (1<<indexInWarp)-1;\n"
"    __shared__ int workgroupBuffer[BUFFER_SIZE*(GROUP_SIZE/32)];\n"
"    __shared__ int workgroupFlagsBuffer[BUFFER_SIZE*(GROUP_SIZE/32)];\n"
"    __shared__ int warpExclusions[MAX_EXCLUSIONS*(GROUP_SIZE/32)];\n"
"    __shared__ real3 posBuffer[GROUP_SIZE];\n"
"    __shared__ volatile int workgroupTileIndex[GROUP_SIZE/32];\n"
"    __shared__ int worksgroupPairStartIndex[GROUP_SIZE/32];\n"
"    int* sumBuffer = (int*) posBuffer; // Reuse the same buffer to save memory\n"
"    int* buffer = workgroupBuffer+BUFFER_SIZE*(warpStart/32);\n"
"    int* flagsBuffer = workgroupFlagsBuffer+BUFFER_SIZE*(warpStart/32);\n"
"    int* exclusionsForX = warpExclusions+MAX_EXCLUSIONS*(warpStart/32);\n"
"    volatile int& tileStartIndex = workgroupTileIndex[warpStart/32];\n"
"    volatile int& pairStartIndex = worksgroupPairStartIndex[warpStart/32];\n"
"\n"
"    // Loop over blocks.\n"
"    \n"
"    for (int block1 = startBlockIndex+warpIndex; block1 < startBlockIndex+numBlocks; block1 += totalWarps) {\n"
"        // Load data for this block.  Note that all threads in a warp are processing the same block.\n"
"        \n"
"        real2 sortedKey = sortedBlocks[block1];\n"
"        int x = (int) sortedKey.y;\n"
"        real4 blockCenterX = sortedBlockCenter[block1];\n"
"        real4 blockSizeX = sortedBlockBoundingBox[block1];\n"
"        int neighborsInBuffer = 0;\n"
"        real3 pos1 = trimTo3(posq[x*TILE_SIZE+indexInWarp]);\n"
"#ifdef USE_PERIODIC\n"
"        const bool singlePeriodicCopy = (0.5f*periodicBoxSize.x-blockSizeX.x >= PADDED_CUTOFF &&\n"
"                                         0.5f*periodicBoxSize.y-blockSizeX.y >= PADDED_CUTOFF &&\n"
"                                         0.5f*periodicBoxSize.z-blockSizeX.z >= PADDED_CUTOFF);\n"
"        if (singlePeriodicCopy) {\n"
"            // The box is small enough that we can just translate all the atoms into a single periodic\n"
"            // box, then skip having to apply periodic boundary conditions later.\n"
"            \n"
"            APPLY_PERIODIC_TO_POS_WITH_CENTER(pos1, blockCenterX)\n"
"        }\n"
"#endif\n"
"        posBuffer[threadIdx.x] = pos1;\n"
"\n"
"        // Load exclusion data for block x.\n"
"        \n"
"        const int exclusionStart = exclusionRowIndices[x];\n"
"        const int exclusionEnd = exclusionRowIndices[x+1];\n"
"        const int numExclusions = exclusionEnd-exclusionStart;\n"
"        for (int j = indexInWarp; j < numExclusions; j += 32)\n"
"            exclusionsForX[j] = exclusionIndices[exclusionStart+j];\n"
"        if (MAX_EXCLUSIONS > 32)\n"
"            __syncthreads();\n"
"        \n"
"        // Loop over atom blocks to search for neighbors.  The threads in a warp compare block1 against 32\n"
"        // other blocks in parallel.\n"
"\n"
"        for (int block2Base = block1+1; block2Base < NUM_BLOCKS; block2Base += 32) {\n"
"            int block2 = block2Base+indexInWarp;\n"
"            bool includeBlock2 = (block2 < NUM_BLOCKS);\n"
"            if (includeBlock2) {\n"
"                real4 blockCenterY = sortedBlockCenter[block2];\n"
"                real4 blockSizeY = sortedBlockBoundingBox[block2];\n"
"                real4 blockDelta = blockCenterX-blockCenterY;\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(blockDelta)\n"
"#endif\n"
"                includeBlock2 &= (blockDelta.x*blockDelta.x+blockDelta.y*blockDelta.y+blockDelta.z*blockDelta.z < (PADDED_CUTOFF+blockCenterX.w+blockCenterY.w)*(PADDED_CUTOFF+blockCenterX.w+blockCenterY.w));\n"
"                blockDelta.x = max(0.0f, fabs(blockDelta.x)-blockSizeX.x-blockSizeY.x);\n"
"                blockDelta.y = max(0.0f, fabs(blockDelta.y)-blockSizeX.y-blockSizeY.y);\n"
"                blockDelta.z = max(0.0f, fabs(blockDelta.z)-blockSizeX.z-blockSizeY.z);\n"
"                includeBlock2 &= (blockDelta.x*blockDelta.x+blockDelta.y*blockDelta.y+blockDelta.z*blockDelta.z < PADDED_CUTOFF_SQUARED);\n"
"#ifdef TRICLINIC\n"
"                // The calculation to find the nearest periodic copy is only guaranteed to work if the nearest copy is less than half a box width away.\n"
"                // If there's any possibility we might have missed it, do a detailed check.\n"
"\n"
"                if (periodicBoxSize.z/2-blockSizeX.z-blockSizeY.z < PADDED_CUTOFF || periodicBoxSize.y/2-blockSizeX.y-blockSizeY.y < PADDED_CUTOFF)\n"
"                    includeBlock2 = true;\n"
"#endif\n"
"                if (includeBlock2) {\n"
"                    unsigned short y = (unsigned short) sortedBlocks[block2].y;\n"
"                    for (int k = 0; k < numExclusions; k++)\n"
"                        includeBlock2 &= (exclusionsForX[k] != y);\n"
"                }\n"
"            }\n"
"            \n"
"            // Loop over any blocks we identified as potentially containing neighbors.\n"
"            \n"
"            int includeBlockFlags = BALLOT(includeBlock2);\n"
"            while (includeBlockFlags != 0) {\n"
"                int i = __ffs(includeBlockFlags)-1;\n"
"                includeBlockFlags &= includeBlockFlags-1;\n"
"                unsigned short y = (unsigned short) sortedBlocks[block2Base+i].y;\n"
"\n"
"                // Check each atom in block Y for interactions.\n"
"\n"
"                int atom2 = y*TILE_SIZE+indexInWarp;\n"
"                real3 pos2 = trimTo3(posq[atom2]);\n"
"#ifdef USE_PERIODIC\n"
"                if (singlePeriodicCopy) {\n"
"                    APPLY_PERIODIC_TO_POS_WITH_CENTER(pos2, blockCenterX)\n"
"                }\n"
"#endif\n"
"                real4 blockCenterY = sortedBlockCenter[block2Base+i];\n"
"                real3 atomDelta = posBuffer[warpStart+indexInWarp]-trimTo3(blockCenterY);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(atomDelta)\n"
"#endif\n"
"                int atomFlags = BALLOT(atomDelta.x*atomDelta.x+atomDelta.y*atomDelta.y+atomDelta.z*atomDelta.z < (PADDED_CUTOFF+blockCenterY.w)*(PADDED_CUTOFF+blockCenterY.w));\n"
"                int interacts = 0;\n"
"                if (atom2 < NUM_ATOMS && atomFlags != 0) {\n"
"                    int first = __ffs(atomFlags)-1;\n"
"                    int last = 32-__clz(atomFlags);\n"
"#ifdef USE_PERIODIC\n"
"                    if (!singlePeriodicCopy) {\n"
"                        for (int j = first; j < last; j++) {\n"
"                            real3 delta = pos2-posBuffer[warpStart+j];\n"
"                            APPLY_PERIODIC_TO_DELTA(delta)\n"
"                            interacts |= (delta.x*delta.x+delta.y*delta.y+delta.z*delta.z < PADDED_CUTOFF_SQUARED ? 1<<j : 0);\n"
"                        }\n"
"                    }\n"
"                    else {\n"
"#endif\n"
"                        for (int j = first; j < last; j++) {\n"
"                            real3 delta = pos2-posBuffer[warpStart+j];\n"
"                            interacts |= (delta.x*delta.x+delta.y*delta.y+delta.z*delta.z < PADDED_CUTOFF_SQUARED ? 1<<j : 0);\n"
"                        }\n"
"#ifdef USE_PERIODIC\n"
"                    }\n"
"#endif\n"
"                }\n"
"                \n"
"                // Add any interacting atoms to the buffer.\n"
"                \n"
"                int includeAtomFlags = BALLOT(interacts);\n"
"                if (interacts) {\n"
"                    int index = neighborsInBuffer+__popc(includeAtomFlags&warpMask);\n"
"                    buffer[index] = atom2;\n"
"                    flagsBuffer[index] = interacts;\n"
"                }\n"
"                neighborsInBuffer += __popc(includeAtomFlags);\n"
"                if (neighborsInBuffer > BUFFER_SIZE-TILE_SIZE) {\n"
"                    // Store the new tiles to memory.\n"
"                    \n"
"#if MAX_BITS_FOR_PAIRS > 0\n"
"                    neighborsInBuffer = saveSinglePairs(x, buffer, flagsBuffer, neighborsInBuffer, maxSinglePairs, &interactionCount[1], singlePairs, sumBuffer+warpStart, pairStartIndex);\n"
"#endif\n"
"                    int tilesToStore = neighborsInBuffer/TILE_SIZE;\n"
"                    if (tilesToStore > 0) {\n"
"                        if (indexInWarp == 0)\n"
"                            tileStartIndex = atomicAdd(&interactionCount[0], tilesToStore);\n"
"                        int newTileStartIndex = tileStartIndex;\n"
"                        if (newTileStartIndex+tilesToStore <= maxTiles) {\n"
"                            if (indexInWarp < tilesToStore)\n"
"                                interactingTiles[newTileStartIndex+indexInWarp] = x;\n"
"                            for (int j = 0; j < tilesToStore; j++)\n"
"                                interactingAtoms[(newTileStartIndex+j)*TILE_SIZE+indexInWarp] = buffer[indexInWarp+j*TILE_SIZE];\n"
"                        }\n"
"                        buffer[indexInWarp] = buffer[indexInWarp+TILE_SIZE*tilesToStore];\n"
"                        neighborsInBuffer -= TILE_SIZE*tilesToStore;\n"
"                    }\n"
"                }\n"
"            }\n"
"        }\n"
"        \n"
"        // If we have a partially filled buffer,  store it to memory.\n"
"        \n"
"#if MAX_BITS_FOR_PAIRS > 0\n"
"        if (neighborsInBuffer > 32)\n"
"            neighborsInBuffer = saveSinglePairs(x, buffer, flagsBuffer, neighborsInBuffer, maxSinglePairs, &interactionCount[1], singlePairs, sumBuffer+warpStart, pairStartIndex);\n"
"#endif\n"
"        if (neighborsInBuffer > 0) {\n"
"            int tilesToStore = (neighborsInBuffer+TILE_SIZE-1)/TILE_SIZE;\n"
"            if (indexInWarp == 0)\n"
"                tileStartIndex = atomicAdd(&interactionCount[0], tilesToStore);\n"
"            int newTileStartIndex = tileStartIndex;\n"
"            if (newTileStartIndex+tilesToStore <= maxTiles) {\n"
"                if (indexInWarp < tilesToStore)\n"
"                    interactingTiles[newTileStartIndex+indexInWarp] = x;\n"
"                for (int j = 0; j < tilesToStore; j++)\n"
"                    interactingAtoms[(newTileStartIndex+j)*TILE_SIZE+indexInWarp] = (indexInWarp+j*TILE_SIZE < neighborsInBuffer ? buffer[indexInWarp+j*TILE_SIZE] : NUM_ATOMS);\n"
"            }\n"
"        }\n"
"    }\n"
"    \n"
"    // Record the positions the neighbor list is based on.\n"
"    \n"
"    for (int i = threadIdx.x+blockIdx.x*blockDim.x; i < NUM_ATOMS; i += blockDim.x*gridDim.x)\n"
"        oldPositions[i] = posq[i];\n"
"}\n"
"";
const string CudaKernelSources::gayBerne = "#define TILE_SIZE 32\n"
"#define NEIGHBOR_BLOCK_SIZE 32\n"
"\n"
"/**\n"
" * Calculate the ellipsoid coordinate frames and associated matrices.\n"
" */\n"
"extern \"C\" __global__ void computeEllipsoidFrames(int numParticles, const real4* __restrict__ posq, int2* const __restrict__ axisParticleIndices,\n"
"        const float4* __restrict__ sigParams, const float4* __restrict__ scale, real* __restrict__ aMatrix,\n"
"        real* __restrict__ bMatrix, real* __restrict__ gMatrix, const int* sortedParticles) {\n"
"    for (int sortedIndex = blockIdx.x*blockDim.x+threadIdx.x; sortedIndex < numParticles; sortedIndex += blockDim.x*gridDim.x) {\n"
"        // Compute the local coordinate system of the ellipsoid;\n"
"\n"
"        int originalIndex = sortedParticles[sortedIndex];\n"
"        real3 pos = trimTo3(posq[originalIndex]);\n"
"        int2 axisParticles = axisParticleIndices[originalIndex];\n"
"        real3 xdir, ydir, zdir;\n"
"        if (axisParticles.x == -1) {\n"
"            xdir = make_real3(1, 0, 0);\n"
"            ydir = make_real3(0, 1, 0);\n"
"        }\n"
"        else {\n"
"            xdir = pos-trimTo3(posq[axisParticles.x]);\n"
"            xdir = normalize(xdir);\n"
"            if (axisParticles.y == -1) {\n"
"                if (xdir.y > -0.5f && xdir.y < 0.5f)\n"
"                    ydir = make_real3(0, 1, 0);\n"
"                else\n"
"                    ydir = make_real3(1, 0, 0);\n"
"            }\n"
"            else\n"
"                ydir = pos-trimTo3(posq[axisParticles.y]);\n"
"            ydir -= xdir*dot(xdir, ydir);\n"
"            ydir = normalize(ydir);\n"
"        }\n"
"        zdir = cross(xdir, ydir);\n"
"\n"
"        // Compute matrices we will need later.\n"
"\n"
"        real (*a)[3] = (real (*)[3]) (aMatrix+sortedIndex*9);\n"
"        real (*b)[3] = (real (*)[3]) (bMatrix+sortedIndex*9);\n"
"        real (*g)[3] = (real (*)[3]) (gMatrix+sortedIndex*9);\n"
"        a[0][0] = xdir.x;\n"
"        a[0][1] = xdir.y;\n"
"        a[0][2] = xdir.z;\n"
"        a[1][0] = ydir.x;\n"
"        a[1][1] = ydir.y;\n"
"        a[1][2] = ydir.z;\n"
"        a[2][0] = zdir.x;\n"
"        a[2][1] = zdir.y;\n"
"        a[2][2] = zdir.z;\n"
"        float4 sig = sigParams[originalIndex];\n"
"        float3 r2 = make_float3(sig.y, sig.z, sig.w);\n"
"        float3 e2 = trimTo3(scale[originalIndex]);\n"
"        for (int i = 0; i < 3; i++)\n"
"            for (int j = 0; j < 3; j++) {\n"
"                b[i][j] = a[0][i]*e2.x*a[0][j] + a[1][i]*e2.y*a[1][j] + a[2][i]*e2.z*a[2][j];\n"
"                g[i][j] = a[0][i]*r2.x*a[0][j] + a[1][i]*r2.y*a[1][j] + a[2][i]*r2.z*a[2][j];\n"
"            }\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Find a bounding box for the atoms in each block.\n"
" */\n"
"extern \"C\" __global__ void findBlockBounds(int numAtoms, real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        const int* sortedAtoms, const real4* __restrict__ posq, real4* __restrict__ sortedPos, real4* __restrict__ blockCenter,\n"
"        real4* __restrict__ blockBoundingBox, int* __restrict__ neighborBlockCount) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    int base = index*TILE_SIZE;\n"
"    while (base < numAtoms) {\n"
"        real4 pos = posq[sortedAtoms[base]];\n"
"        sortedPos[base] = pos;\n"
"#ifdef USE_PERIODIC\n"
"        APPLY_PERIODIC_TO_POS(pos)\n"
"#endif\n"
"        real4 minPos = pos;\n"
"        real4 maxPos = pos;\n"
"        int last = min(base+TILE_SIZE, numAtoms);\n"
"        for (int i = base+1; i < last; i++) {\n"
"            pos = posq[sortedAtoms[i]];\n"
"            sortedPos[i] = pos;\n"
"#ifdef USE_PERIODIC\n"
"            real4 center = 0.5f*(maxPos+minPos);\n"
"            APPLY_PERIODIC_TO_POS_WITH_CENTER(pos, center)\n"
"#endif\n"
"            minPos = make_real4(min(minPos.x,pos.x), min(minPos.y,pos.y), min(minPos.z,pos.z), 0);\n"
"            maxPos = make_real4(max(maxPos.x,pos.x), max(maxPos.y,pos.y), max(maxPos.z,pos.z), 0);\n"
"        }\n"
"        real4 blockSize = 0.5f*(maxPos-minPos);\n"
"        blockBoundingBox[index] = blockSize;\n"
"        blockCenter[index] = 0.5f*(maxPos+minPos);\n"
"        index += blockDim.x*gridDim.x;\n"
"        base = index*TILE_SIZE;\n"
"    }\n"
"    if (blockIdx.x*blockDim.x+threadIdx.x == 0)\n"
"        *neighborBlockCount = 0;\n"
"}\n"
"\n"
"/**\n"
" * This is called by findNeighbors() to write a block to the neighbor list.\n"
" */\n"
"__device__ void storeNeighbors(int atom1, int* neighborBuffer, int numAtomsInBuffer, int maxNeighborBlocks, int* __restrict__ neighbors,\n"
"        int* __restrict__ neighborIndex, int* __restrict__ neighborBlockCount) {\n"
"    int blockIndex = atomicAdd(neighborBlockCount, 1);\n"
"    if (blockIndex >= maxNeighborBlocks)\n"
"        return; // We don't have enough room for the neighbor list.\n"
"    neighborIndex[blockIndex] = atom1;\n"
"    int baseIndex = blockIndex*NEIGHBOR_BLOCK_SIZE;\n"
"    for (int i = 0; i < numAtomsInBuffer; i++)\n"
"        neighbors[baseIndex+i] = neighborBuffer[i];\n"
"    for (int i = numAtomsInBuffer; i < NEIGHBOR_BLOCK_SIZE; i++)\n"
"        neighbors[baseIndex+i] = -1;\n"
"}\n"
"\n"
"/**\n"
" * Build a list of neighbors for each atom.\n"
" */\n"
"extern \"C\" __global__ void findNeighbors(int numAtoms, int maxNeighborBlocks, real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        real4* __restrict__ sortedPos, real4* __restrict__ blockCenter, real4* __restrict__ blockBoundingBox, int* __restrict__ neighbors,\n"
"        int* __restrict__ neighborIndex, int* __restrict__ neighborBlockCount, const int* __restrict__ exclusions, const int* __restrict__ exclusionStartIndex) {\n"
"    const int numBlocks = (numAtoms+TILE_SIZE-1)/TILE_SIZE;\n"
"    int neighborBuffer[NEIGHBOR_BLOCK_SIZE];\n"
"    for (int atom1 = blockIdx.x*blockDim.x+threadIdx.x; atom1 < numAtoms; atom1 += blockDim.x*gridDim.x) {\n"
"        int nextExclusion = exclusionStartIndex[atom1];\n"
"        int lastExclusion = exclusionStartIndex[atom1+1];\n"
"        real4 pos = sortedPos[atom1];\n"
"        int nextBufferIndex = 0;\n"
"        \n"
"        // Loop over atom blocks and compute the distance of this atom from each one's bounding box.\n"
"        \n"
"        for (int block = (atom1+1)/TILE_SIZE; block < numBlocks; block++) {\n"
"            real4 center = blockCenter[block];\n"
"            real4 blockSize = blockBoundingBox[block];\n"
"            real4 blockDelta = center-pos;\n"
"#ifdef USE_PERIODIC\n"
"            APPLY_PERIODIC_TO_DELTA(blockDelta)\n"
"#endif\n"
"            blockDelta.x = max((real) 0, fabs(blockDelta.x)-blockSize.x);\n"
"            blockDelta.y = max((real) 0, fabs(blockDelta.y)-blockSize.y);\n"
"            blockDelta.z = max((real) 0, fabs(blockDelta.z)-blockSize.z);\n"
"            if (blockDelta.x*blockDelta.x+blockDelta.y*blockDelta.y+blockDelta.z*blockDelta.z >= CUTOFF_SQUARED)\n"
"                continue;\n"
"            \n"
"            // Loop over atoms within this block.\n"
"            \n"
"            int first = max(block*TILE_SIZE, atom1+1);\n"
"            int last = min((block+1)*TILE_SIZE, numAtoms);\n"
"            for (int atom2 = first; atom2 < last; atom2++) {\n"
"                // Skip over excluded interactions.\n"
"\n"
"                if (nextExclusion < lastExclusion && exclusions[nextExclusion] >= atom2) {\n"
"                    nextExclusion++;\n"
"                    continue;\n"
"                }\n"
"                real4 delta = pos-sortedPos[atom2];\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                if (r2 < CUTOFF_SQUARED) {\n"
"                    neighborBuffer[nextBufferIndex++] = atom2;\n"
"                    if (nextBufferIndex == NEIGHBOR_BLOCK_SIZE) {\n"
"                        storeNeighbors(atom1, neighborBuffer, nextBufferIndex, maxNeighborBlocks, neighbors, neighborIndex, neighborBlockCount);\n"
"                        nextBufferIndex = 0;\n"
"                    }\n"
"                }\n"
"            }\n"
"        }\n"
"        if (nextBufferIndex > 0)\n"
"            storeNeighbors(atom1, neighborBuffer, nextBufferIndex, maxNeighborBlocks, neighbors, neighborIndex, neighborBlockCount);\n"
"    }\n"
"}\n"
"\n"
"typedef struct {\n"
"    float4 sig;\n"
"    float2 eps;\n"
"    real3 pos;\n"
"    real a[3][3], b[3][3], g[3][3];\n"
"} AtomData;\n"
"\n"
"__device__ void loadAtomData(AtomData* data, int sortedIndex, int originalIndex, const real4* __restrict__ pos, const float4* __restrict__ sigParams,\n"
"        const float2* __restrict__ epsParams, const real* __restrict__ aMatrix, const real* __restrict__ bMatrix, const real* __restrict__ gMatrix) {\n"
"    data->sig = sigParams[originalIndex];\n"
"    data->eps = epsParams[originalIndex];\n"
"    data->pos = trimTo3(pos[sortedIndex]);\n"
"    for (int i = 0; i < 3; i++)\n"
"        for (int j = 0; j < 3; j++) {\n"
"            int k = 9*sortedIndex+3*i+j;\n"
"            data->a[i][j] = aMatrix[k];\n"
"            data->b[i][j] = bMatrix[k];\n"
"            data->g[i][j] = gMatrix[k];\n"
"        }\n"
"}\n"
"\n"
"inline __device__ real3 matrixVectorProduct(real (*m)[3], real3 v) {\n"
"    return make_real3(m[0][0]*v.x + m[0][1]*v.y + m[0][2]*v.z,\n"
"                      m[1][0]*v.x + m[1][1]*v.y + m[1][2]*v.z,\n"
"                      m[2][0]*v.x + m[2][1]*v.y + m[2][2]*v.z);\n"
"}\n"
"\n"
"inline __device__ real3 vectorMatrixProduct(real3 v, real (*m)[3]) {\n"
"    return make_real3(m[0][0]*v.x + m[1][0]*v.y + m[2][0]*v.z,\n"
"                      m[0][1]*v.x + m[1][1]*v.y + m[2][1]*v.z,\n"
"                      m[0][2]*v.x + m[1][2]*v.y + m[2][2]*v.z);\n"
"}\n"
"\n"
"inline __device__ void matrixSum(real (*result)[3], real (*a)[3], real (*b)[3]) {\n"
"    result[0][0] = a[0][0]+b[0][0];\n"
"    result[0][1] = a[0][1]+b[0][1];\n"
"    result[0][2] = a[0][2]+b[0][2];\n"
"    result[1][0] = a[1][0]+b[1][0];\n"
"    result[1][1] = a[1][1]+b[1][1];\n"
"    result[1][2] = a[1][2]+b[1][2];\n"
"    result[2][0] = a[2][0]+b[2][0];\n"
"    result[2][1] = a[2][1]+b[2][1];\n"
"    result[2][2] = a[2][2]+b[2][2];\n"
"}\n"
"\n"
"inline __device__ real determinant(real (*m)[3]) {\n"
"    return (m[0][0]*m[1][1]*m[2][2] + m[0][1]*m[1][2]*m[2][0] + m[0][2]*m[1][0]*m[2][1] -\n"
"            m[0][0]*m[1][2]*m[2][1] - m[0][1]*m[1][0]*m[2][2] - m[0][2]*m[1][1]*m[2][0]);\n"
"}\n"
"\n"
"inline __device__ void matrixInverse(real (*result)[3], real (*m)[3]) {\n"
"    real invDet = RECIP(determinant(m));\n"
"    result[0][0] = invDet*(m[1][1]*m[2][2] - m[1][2]*m[2][1]);\n"
"    result[1][0] = -invDet*(m[1][0]*m[2][2] - m[1][2]*m[2][0]);\n"
"    result[2][0] = invDet*(m[1][0]*m[2][1] - m[1][1]*m[2][0]);\n"
"    result[0][1] = -invDet*(m[0][1]*m[2][2] - m[0][2]*m[2][1]);\n"
"    result[1][1] = invDet*(m[0][0]*m[2][2] - m[0][2]*m[2][0]);\n"
"    result[2][1] = -invDet*(m[0][0]*m[2][1] - m[0][1]*m[2][0]);\n"
"    result[0][2] = invDet*(m[0][1]*m[1][2] - m[0][2]*m[1][1]);\n"
"    result[1][2] = -invDet*(m[0][0]*m[1][2] - m[0][2]*m[1][0]);\n"
"    result[2][2] = invDet*(m[0][0]*m[1][1] - m[0][1]*m[1][0]);\n"
"}\n"
"\n"
"__device__ void computeOneInteraction(AtomData* data1, AtomData* data2, real sigma, real epsilon, real3 dr, real r2, real3* force1, real3* force2, real3* torque1, real3* torque2, mixed *totalEnergy) {\n"
"    real rInv = RSQRT(r2);\n"
"    real r = r2*rInv;\n"
"    real3 drUnit = dr*rInv;\n"
"    \n"
"    // Compute the switching function.\n"
"\n"
"    real switchValue = 1, switchDeriv = 0;\n"
"    #if USE_SWITCH\n"
"    if (r > SWITCH_CUTOFF) {\n"
"        real x = r-SWITCH_CUTOFF;\n"
"        switchValue = 1+x*x*x*(SWITCH_C3+x*(SWITCH_C4+x*SWITCH_C5));\n"
"        switchDeriv = x*x*(3*SWITCH_C3+x*(4*SWITCH_C4+x*5*SWITCH_C5));\n"
"    }\n"
"    #endif\n"
"\n"
"    // Compute vectors and matrices we'll be needing.\n"
"\n"
"    real B12[3][3], G12[3][3], B12inv[3][3], G12inv[3][3];\n"
"    matrixSum(B12, data1->b, data2->b);\n"
"    matrixSum(G12, data1->g, data2->g);\n"
"    matrixInverse(B12inv, B12);\n"
"    matrixInverse(G12inv, G12);\n"
"    real detG12 = determinant(G12);\n"
"\n"
"    // Estimate the distance between the ellipsoids and compute the first terms needed for the energy.\n"
"\n"
"    real sigma12 = 1/SQRT(0.5f*dot(drUnit, matrixVectorProduct(G12inv, drUnit)));\n"
"    real h12 = r - sigma12;\n"
"    real rho = sigma/(h12+sigma);\n"
"    real rho2 = rho*rho;\n"
"    real rho6 = rho2*rho2*rho2;\n"
"    real u = 4*epsilon*(rho6*rho6-rho6);\n"
"    real eta = SQRT(2*data1->eps.y*data2->eps.y/detG12);\n"
"    real chi = 2*dot(drUnit, matrixVectorProduct(B12inv, drUnit));\n"
"    chi *= chi;\n"
"    real energy = u*eta*chi;\n"
"    \n"
"    // Compute the terms needed for the force.\n"
"\n"
"    real3 kappa = matrixVectorProduct(G12inv, dr);\n"
"    real3 iota = matrixVectorProduct(B12inv, dr);\n"
"    real rInv2 = rInv*rInv;\n"
"    real dUSLJdr = 24*epsilon*(2*rho6-1)*rho6*rho/sigma;\n"
"    real temp = 0.5f*sigma12*sigma12*sigma12*rInv2;\n"
"    real3 dudr = (drUnit + (kappa-drUnit*dot(kappa, drUnit))*temp)*dUSLJdr;\n"
"    real3 dchidr = (iota-drUnit*dot(iota, drUnit))*(-8*rInv2*SQRT(chi));\n"
"    real3 force = (dchidr*u + dudr*chi)*(eta*switchValue) - drUnit*(energy*switchDeriv);\n"
"    *force1 += force;\n"
"    *force2 -= force;\n"
"\n"
"    // Compute the terms needed for the torque.\n"
"\n"
"    for (int j = 0; j < 2; j++) {\n"
"        real (*a)[3] = (j == 0 ? data1->a : data2->a);\n"
"        real (*b)[3] = (j == 0 ? data1->b : data2->b);\n"
"        real (*g)[3] = (j == 0 ? data1->g : data2->g);\n"
"        float4 sig = (j == 0 ? data1->sig : data2->sig);\n"
"        real3 dudq = cross(vectorMatrixProduct(kappa, g), kappa*(temp*dUSLJdr));\n"
"        real3 dchidq = cross(vectorMatrixProduct(iota, b), iota)*(-4*rInv2);\n"
"        real3 scale = make_real3(sig.y, sig.z, sig.w)*(-0.5f*eta/detG12);\n"
"        real d[3][3];\n"
"        d[0][0] = scale.x*(2*a[0][0]*(G12[1][1]*G12[2][2] - G12[1][2]*G12[2][1]) +\n"
"                             a[0][2]*(G12[1][2]*G12[0][1] + G12[1][0]*G12[2][1] - G12[1][1]*(G12[0][2] + G12[2][0])) +\n"
"                             a[0][1]*(G12[0][2]*G12[2][1] + G12[2][0]*G12[1][2] - G12[2][2]*(G12[0][1] + G12[1][0])));\n"
"        d[0][1] = scale.x*(  a[0][0]*(G12[0][2]*G12[2][1] + G12[2][0]*G12[1][2] - G12[2][2]*(G12[0][1] + G12[1][0])) +\n"
"                           2*a[0][1]*(G12[0][0]*G12[2][2] - G12[2][0]*G12[0][2]) +\n"
"                             a[0][2]*(G12[1][0]*G12[0][2] + G12[2][0]*G12[0][1] - G12[0][0]*(G12[1][2] + G12[2][1])));\n"
"        d[0][2] = scale.x*(  a[0][0]*(G12[0][1]*G12[1][2] + G12[1][0]*G12[2][1] - G12[1][1]*(G12[0][2] + G12[2][0])) +\n"
"                             a[0][1]*(G12[1][0]*G12[0][2] + G12[2][0]*G12[0][1] - G12[0][0]*(G12[1][2] + G12[2][1])) +\n"
"                           2*a[0][2]*(G12[1][1]*G12[0][0] - G12[1][0]*G12[0][1]));\n"
"        d[1][0] = scale.y*(2*a[1][0]*(G12[1][1]*G12[2][2] - G12[1][2]*G12[2][1]) +\n"
"                             a[1][1]*(G12[0][2]*G12[2][1] + G12[2][0]*G12[1][2] - G12[2][2]*(G12[0][1] + G12[1][0])) +\n"
"                             a[1][2]*(G12[1][2]*G12[0][1] + G12[1][0]*G12[2][1] - G12[1][1]*(G12[0][2] + G12[2][0])));\n"
"        d[1][1] = scale.y*(  a[1][0]*(G12[0][2]*G12[2][1] + G12[2][0]*G12[1][2] - G12[2][2]*(G12[0][1] + G12[1][0])) +\n"
"                           2*a[1][1]*(G12[2][2]*G12[0][0] - G12[2][0]*G12[0][2]) +\n"
"                             a[1][2]*(G12[1][0]*G12[0][2] + G12[0][1]*G12[2][0] - G12[0][0]*(G12[1][2] + G12[2][1])));\n"
"        d[1][2] = scale.y*(  a[1][0]*(G12[0][1]*G12[1][2] + G12[1][0]*G12[2][1] - G12[1][1]*(G12[0][2] + G12[2][0])) +\n"
"                             a[1][1]*(G12[1][0]*G12[0][2] + G12[0][1]*G12[2][0] - G12[0][0]*(G12[1][2] + G12[2][1])) +\n"
"                           2*a[1][2]*(G12[1][1]*G12[0][0] - G12[1][0]*G12[0][1]));\n"
"        d[2][0] = scale.z*(2*a[2][0]*(G12[1][1]*G12[2][2] - G12[2][1]*G12[1][2]) +\n"
"                             a[2][1]*(G12[0][2]*G12[2][1] + G12[1][2]*G12[2][0] - G12[2][2]*(G12[0][1] + G12[1][0])) +\n"
"                             a[2][2]*(G12[0][1]*G12[1][2] + G12[2][1]*G12[1][0] - G12[1][1]*(G12[0][2] + G12[2][0])));\n"
"        d[2][1] = scale.z*(  a[2][0]*(G12[0][2]*G12[2][1] + G12[1][2]*G12[2][0] - G12[2][2]*(G12[0][1] + G12[1][0])) +\n"
"                           2*a[2][1]*(G12[0][0]*G12[2][2] - G12[0][2]*G12[2][0]) +\n"
"                             a[2][2]*(G12[1][0]*G12[0][2] + G12[0][1]*G12[2][0] - G12[0][0]*(G12[1][2] + G12[2][1])));\n"
"        d[2][2] = scale.z*(  a[2][0]*(G12[0][1]*G12[1][2] + G12[2][1]*G12[1][0] - G12[1][1]*(G12[0][2] + G12[2][0])) +\n"
"                             a[2][1]*(G12[1][0]*G12[0][2] + G12[2][0]*G12[0][1] - G12[0][0]*(G12[1][2] + G12[2][1])) +\n"
"                           2*a[2][2]*(G12[1][1]*G12[0][0] - G12[1][0]*G12[0][1]));\n"
"        real3 detadq = make_real3(0);\n"
"        for (int i = 0; i < 3; i++)\n"
"            detadq += cross(make_real3(a[i][0], a[i][1], a[i][2]), make_real3(d[i][0], d[i][1], d[i][2]));\n"
"        real3 torque = (dchidq*(u*eta) + detadq*(u*chi) + dudq*(eta*chi))*switchValue;\n"
"        *(j == 0 ? torque1 : torque2) -= torque;\n"
"    }\n"
"    *totalEnergy += switchValue*energy;\n"
"}\n"
"\n"
"/**\n"
" * Compute the interactions.\n"
" */\n"
"extern \"C\" __global__ void computeForce(\n"
"        unsigned long long* __restrict__ forceBuffers, unsigned long long* __restrict__ torqueBuffers,\n"
"        int numAtoms, int numExceptions, mixed* __restrict__ energyBuffer, const real4* __restrict__ pos,\n"
"        const float4* __restrict__ sigParams, const float2* __restrict__ epsParams, const int* __restrict__ sortedAtoms,\n"
"        const real* __restrict__ aMatrix, const real* __restrict__ bMatrix, const real* __restrict__ gMatrix,\n"
"        const int* __restrict__ exclusions, const int* __restrict__ exclusionStartIndex,\n"
"        const int4* __restrict__ exceptionParticles, const float2* __restrict__ exceptionParams\n"
"#ifdef USE_CUTOFF\n"
"        , int maxNeighborBlocks, int* __restrict__ neighbors, int* __restrict__ neighborIndex, int* __restrict__ neighborBlockCount,\n"
"        real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ\n"
"#endif\n"
"        ) {\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE;\n"
"    mixed energy = 0;\n"
"#ifdef USE_CUTOFF\n"
"    const int numBlocks = *neighborBlockCount;\n"
"    if (numBlocks > maxNeighborBlocks)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    for (int block = blockIdx.x*blockDim.x+threadIdx.x; block < numBlocks; block += blockDim.x*gridDim.x) {\n"
"        // Load parameters for atom1.\n"
"        \n"
"        int atom1 = neighborIndex[block];\n"
"        int index1 = sortedAtoms[atom1];\n"
"        AtomData data1;\n"
"        loadAtomData(&data1, atom1, index1, pos, sigParams, epsParams, aMatrix, bMatrix, gMatrix);\n"
"        real3 force1 = make_real3(0);\n"
"        real3 torque1 = make_real3(0);\n"
"        for (int indexInBlock = 0; indexInBlock < NEIGHBOR_BLOCK_SIZE; indexInBlock++) {\n"
"            // Load parameters for atom2.\n"
"            \n"
"            int atom2 = neighbors[NEIGHBOR_BLOCK_SIZE*block+indexInBlock];\n"
"            if (atom2 == -1)\n"
"                continue;\n"
"            int index2 = sortedAtoms[atom2];\n"
"            AtomData data2;\n"
"            loadAtomData(&data2, atom2, index2, pos, sigParams, epsParams, aMatrix, bMatrix, gMatrix);\n"
"            real3 force2 = make_real3(0);\n"
"            real3 torque2 = make_real3(0);\n"
"            \n"
"            // Compute the interaction.\n"
"            \n"
"            real3 delta = data1.pos-data2.pos;\n"
"#ifdef USE_PERIODIC\n"
"            APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"            real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"            real sigma = data1.sig.x+data2.sig.x;\n"
"            real epsilon = data1.eps.x*data2.eps.x;\n"
"            computeOneInteraction(&data1, &data2, sigma, epsilon, delta, r2, &force1, &force2, &torque1, &torque2, &energy);\n"
"            atomicAdd(&forceBuffers[index2], static_cast<unsigned long long>((long long) (force2.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force2.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force2.z*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2], static_cast<unsigned long long>((long long) (torque2.x*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque2.y*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque2.z*0x100000000)));\n"
"        }\n"
"        atomicAdd(&forceBuffers[index1], static_cast<unsigned long long>((long long) (force1.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[index1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force1.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[index1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force1.z*0x100000000)));\n"
"        atomicAdd(&torqueBuffers[index1], static_cast<unsigned long long>((long long) (torque1.x*0x100000000)));\n"
"        atomicAdd(&torqueBuffers[index1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque1.y*0x100000000)));\n"
"        atomicAdd(&torqueBuffers[index1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque1.z*0x100000000)));\n"
"    }\n"
"#else\n"
"    for (int atom1 = blockIdx.x*blockDim.x+threadIdx.x; atom1 < numAtoms; atom1 += blockDim.x*gridDim.x) {\n"
"        // Load parameters for atom1.\n"
"        \n"
"        int index1 = sortedAtoms[atom1];\n"
"        AtomData data1;\n"
"        loadAtomData(&data1, atom1, index1, pos, sigParams, epsParams, aMatrix, bMatrix, gMatrix);\n"
"        real3 force1 = make_real3(0);\n"
"        real3 torque1 = make_real3(0);\n"
"        int nextExclusion = exclusionStartIndex[atom1];\n"
"        int lastExclusion = exclusionStartIndex[atom1+1];\n"
"        for (int atom2 = atom1+1; atom2 < numAtoms; atom2++) {\n"
"            // Skip over excluded interactions.\n"
"            \n"
"            if (nextExclusion < lastExclusion && exclusions[nextExclusion] == atom2) {\n"
"                nextExclusion++;\n"
"                continue;\n"
"            }\n"
"            \n"
"            // Load parameters for atom2.\n"
"            \n"
"            int index2 = sortedAtoms[atom2];\n"
"            AtomData data2;\n"
"            loadAtomData(&data2, atom2, index2, pos, sigParams, epsParams, aMatrix, bMatrix, gMatrix);\n"
"            real3 force2 = make_real3(0);\n"
"            real3 torque2 = make_real3(0);\n"
"            \n"
"            // Compute the interaction.\n"
"            \n"
"            real3 delta = data1.pos-data2.pos;\n"
"            real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"            real sigma = data1.sig.x+data2.sig.x;\n"
"            real epsilon = data1.eps.x*data2.eps.x;\n"
"            computeOneInteraction(&data1, &data2, sigma, epsilon, delta, r2, &force1, &force2, &torque1, &torque2, &energy);\n"
"            atomicAdd(&forceBuffers[index2], static_cast<unsigned long long>((long long) (force2.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force2.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force2.z*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2], static_cast<unsigned long long>((long long) (torque2.x*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque2.y*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque2.z*0x100000000)));\n"
"        }\n"
"        atomicAdd(&forceBuffers[index1], static_cast<unsigned long long>((long long) (force1.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[index1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force1.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[index1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force1.z*0x100000000)));\n"
"        atomicAdd(&torqueBuffers[index1], static_cast<unsigned long long>((long long) (torque1.x*0x100000000)));\n"
"        atomicAdd(&torqueBuffers[index1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque1.y*0x100000000)));\n"
"        atomicAdd(&torqueBuffers[index1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque1.z*0x100000000)));\n"
"    }\n"
"#endif\n"
"    \n"
"    // Now compute exceptions.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numExceptions; index += blockDim.x*gridDim.x) {\n"
"        int4 atomIndices = exceptionParticles[index];\n"
"        float2 params = exceptionParams[index];\n"
"        int index1 = atomIndices.x, index2 = atomIndices.y;\n"
"        int atom1 = atomIndices.z, atom2 = atomIndices.w;\n"
"        AtomData data1, data2;\n"
"        loadAtomData(&data1, atom1, index1, pos, sigParams, epsParams, aMatrix, bMatrix, gMatrix);\n"
"        loadAtomData(&data2, atom2, index2, pos, sigParams, epsParams, aMatrix, bMatrix, gMatrix);\n"
"        real3 force1 = make_real3(0), force2 = make_real3(0);\n"
"        real3 torque1 = make_real3(0), torque2 = make_real3(0);\n"
"        real3 delta = data1.pos-data2.pos;\n"
"        real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"        if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"            computeOneInteraction(&data1, &data2, params.x, params.y, delta, r2, &force1, &force2, &torque1, &torque2, &energy);\n"
"            atomicAdd(&forceBuffers[index1], static_cast<unsigned long long>((long long) (force1.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force1.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force1.z*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2], static_cast<unsigned long long>((long long) (force2.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force2.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[index2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force2.z*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index1], static_cast<unsigned long long>((long long) (torque1.x*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque1.y*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque1.z*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2], static_cast<unsigned long long>((long long) (torque2.x*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque2.y*0x100000000)));\n"
"            atomicAdd(&torqueBuffers[index2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (torque2.z*0x100000000)));\n"
"#ifdef USE_CUTOFF\n"
"        }\n"
"#endif\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"}\n"
"\n"
"/**\n"
" * Convert the torques to forces on the connected particles.\n"
" */\n"
"extern \"C\" __global__ void applyTorques(\n"
"        unsigned long long* __restrict__ forceBuffers, long long* __restrict__ torqueBuffers,\n"
"        int numParticles, const real4* __restrict__ posq, int2* const __restrict__ axisParticleIndices,\n"
"        const int* sortedParticles) {\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE;\n"
"    for (int sortedIndex = blockIdx.x*blockDim.x+threadIdx.x; sortedIndex < numParticles; sortedIndex += blockDim.x*gridDim.x) {\n"
"        int originalIndex = sortedParticles[sortedIndex];\n"
"        real3 pos = trimTo3(posq[originalIndex]);\n"
"        int2 axisParticles = axisParticleIndices[originalIndex];\n"
"        if (axisParticles.x != -1) {\n"
"            // Load the torque.\n"
"\n"
"            real scale = 1/(real) 0x100000000;\n"
"            real3 torque = make_real3(scale*torqueBuffers[originalIndex], scale*torqueBuffers[originalIndex+PADDED_NUM_ATOMS], scale*torqueBuffers[originalIndex+2*PADDED_NUM_ATOMS]);\n"
"            real3 force = make_real3(0), xforce = make_real3(0), yforce = make_real3(0);\n"
"\n"
"            // Apply a force to the x particle.\n"
"            \n"
"            real3 dx = trimTo3(posq[axisParticles.x])-pos;\n"
"            real dx2 = dot(dx, dx);\n"
"            real3 f = cross(torque, dx)/dx2;\n"
"            xforce += f;\n"
"            force -= f;\n"
"            if (axisParticles.y != -1) {\n"
"                // Apply a force to the y particle.  This is based on the component of the torque\n"
"                // that was not already applied to the x particle.\n"
"                \n"
"                real3 dy = trimTo3(posq[axisParticles.y])-pos;\n"
"                real dy2 = dot(dy, dy);\n"
"                real3 torque2 = dx*dot(torque, dx)/dx2;\n"
"                f = cross(torque2, dy)/dy2;\n"
"                yforce += f;\n"
"                force -= f;\n"
"            }\n"
"            atomicAdd(&forceBuffers[originalIndex], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[originalIndex+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[originalIndex+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"            atomicAdd(&forceBuffers[axisParticles.x], static_cast<unsigned long long>((long long) (xforce.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[axisParticles.x+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (xforce.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[axisParticles.x+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (xforce.z*0x100000000)));\n"
"            if (axisParticles.y != -1) {\n"
"                atomicAdd(&forceBuffers[axisParticles.y], static_cast<unsigned long long>((long long) (yforce.x*0x100000000)));\n"
"                atomicAdd(&forceBuffers[axisParticles.y+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (yforce.y*0x100000000)));\n"
"                atomicAdd(&forceBuffers[axisParticles.y+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (yforce.z*0x100000000)));\n"
"            }\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::gbsaObc1 = "#define DIELECTRIC_OFFSET 0.009f\n"
"#define PROBE_RADIUS 0.14f\n"
"#define WARPS_PER_GROUP (FORCE_WORK_GROUP_SIZE/TILE_SIZE)\n"
"\n"
"/**\n"
" * Reduce the Born sums to compute the Born radii.\n"
" */\n"
"\n"
"extern \"C\" __global__ void reduceBornSum(float alpha, float beta, float gamma, const long long* __restrict__ bornSum,\n"
"            const float2* __restrict__ params, real* __restrict__ bornRadii, real* __restrict__ obcChain) {\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        // Get summed Born data\n"
"\n"
"        real sum = RECIP(0x100000000)*bornSum[index];\n"
"\n"
"        // Now calculate Born radius and OBC term.\n"
"\n"
"        float offsetRadius = params[index].x;\n"
"        sum *= 0.5f*offsetRadius;\n"
"        real sum2 = sum*sum;\n"
"        real sum3 = sum*sum2;\n"
"        real tanhSum = tanh(alpha*sum - beta*sum2 + gamma*sum3);\n"
"        real nonOffsetRadius = offsetRadius + DIELECTRIC_OFFSET;\n"
"        real radius = RECIP(RECIP(offsetRadius) - tanhSum/nonOffsetRadius);\n"
"        real chain = offsetRadius*(alpha - 2.0f*beta*sum + 3.0f*gamma*sum2);\n"
"        chain = (1-tanhSum*tanhSum)*chain / nonOffsetRadius;\n"
"        bornRadii[index] = radius;\n"
"        obcChain[index] = chain;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Reduce the Born force.\n"
" */\n"
"\n"
"extern \"C\" __global__ void reduceBornForce(long long* __restrict__ bornForce, mixed* __restrict__ energyBuffer,\n"
"        const float2* __restrict__ params, const real* __restrict__ bornRadii, const real* __restrict__ obcChain) {\n"
"    mixed energy = 0;\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        // Get summed Born force\n"
"\n"
"        real force = RECIP(0x100000000)*bornForce[index];\n"
"\n"
"        // Now calculate the actual force\n"
"\n"
"        float offsetRadius = params[index].x;\n"
"        real bornRadius = bornRadii[index];\n"
"        real r = offsetRadius+DIELECTRIC_OFFSET+PROBE_RADIUS;\n"
"        real ratio6 = POW((offsetRadius+DIELECTRIC_OFFSET)/bornRadius, 6);\n"
"        real saTerm = SURFACE_AREA_FACTOR*r*r*ratio6;\n"
"        force += saTerm/bornRadius;\n"
"        energy += saTerm;\n"
"        force *= bornRadius*bornRadius*obcChain[index];\n"
"        bornForce[index] = (long long) (force*0x100000000);\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy/-6;\n"
"}\n"
"\n"
"typedef struct {\n"
"    real x, y, z;\n"
"    real q;\n"
"    float radius, scaledRadius;\n"
"    real bornSum;\n"
"} AtomData1;\n"
"\n"
"/**\n"
" * Compute the Born sum.\n"
" */\n"
"extern \"C\" __global__ void computeBornSum(unsigned long long* __restrict__ global_bornSum, const real4* __restrict__ posq, const real* __restrict__ charge, const float2* __restrict__ global_params,\n"
"#ifdef USE_CUTOFF\n"
"        const int* __restrict__ tiles, const unsigned int* __restrict__ interactionCount, real4 periodicBoxSize, real4 invPeriodicBoxSize,\n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ, unsigned int maxTiles, const real4* __restrict__ blockCenter,\n"
"        const real4* __restrict__ blockSize, const unsigned int* __restrict__ interactingAtoms,\n"
"#else\n"
"        unsigned int numTiles,\n"
"#endif\n"
"        const ushort2* __restrict__ exclusionTiles) {\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE;\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1);\n"
"    const unsigned int tbx = threadIdx.x - tgx;\n"
"    __shared__ AtomData1 localData[FORCE_WORK_GROUP_SIZE];\n"
"\n"
"    // First loop: process tiles that contain exclusions.\n"
"    \n"
"    const unsigned int firstExclusionTile = FIRST_EXCLUSION_TILE+warp*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    const unsigned int lastExclusionTile = FIRST_EXCLUSION_TILE+(warp+1)*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    for (int pos = firstExclusionTile; pos < lastExclusionTile; pos++) {\n"
"        const ushort2 tileIndices = exclusionTiles[pos];\n"
"        const unsigned int x = tileIndices.x;\n"
"        const unsigned int y = tileIndices.y;\n"
"        real bornSum = 0;\n"
"        unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"        real4 posq1 = posq[atom1];\n"
"        real charge1 = charge[atom1];\n"
"        float2 params1 = global_params[atom1];\n"
"        if (x == y) {\n"
"            // This tile is on the diagonal.\n"
"\n"
"            localData[threadIdx.x].x = posq1.x;\n"
"            localData[threadIdx.x].y = posq1.y;\n"
"            localData[threadIdx.x].z = posq1.z;\n"
"            localData[threadIdx.x].q = charge1;\n"
"            localData[threadIdx.x].radius = params1.x;\n"
"            localData[threadIdx.x].scaledRadius = params1.y;\n"
"            for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                real3 delta = make_real3(localData[tbx+j].x-posq1.x, localData[tbx+j].y-posq1.y, localData[tbx+j].z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (atom1 < NUM_ATOMS && y*TILE_SIZE+j < NUM_ATOMS && r2 < CUTOFF_SQUARED) {\n"
"#else\n"
"                if (atom1 < NUM_ATOMS && y*TILE_SIZE+j < NUM_ATOMS) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    float2 params2 = make_float2(localData[tbx+j].radius, localData[tbx+j].scaledRadius);\n"
"                    real rScaledRadiusJ = r+params2.y;\n"
"                    if ((j != tgx) && (params1.x < rScaledRadiusJ)) {\n"
"                        real l_ij = RECIP(max(params1.x, fabs(r-params2.y)));\n"
"                        real u_ij = RECIP(rScaledRadiusJ);\n"
"                        real l_ij2 = l_ij*l_ij;\n"
"                        real u_ij2 = u_ij*u_ij;\n"
"                        real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                        bornSum += l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                            (params2.y*params2.y*invR)*(l_ij2-u_ij2));\n"
"                        bornSum += (params1.x < params2.y-r ? 2.0f*(RECIP(params1.x)-l_ij) : 0);\n"
"                    }\n"
"                }\n"
"            }\n"
"        }\n"
"        else {\n"
"            // This is an off-diagonal tile.\n"
"\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"            real4 tempPosq = posq[j];\n"
"            localData[threadIdx.x].x = tempPosq.x;\n"
"            localData[threadIdx.x].y = tempPosq.y;\n"
"            localData[threadIdx.x].z = tempPosq.z;\n"
"            localData[threadIdx.x].q = charge[j];\n"
"            float2 tempParams = global_params[j];\n"
"            localData[threadIdx.x].radius = tempParams.x;\n"
"            localData[threadIdx.x].scaledRadius = tempParams.y;\n"
"            localData[threadIdx.x].bornSum = 0.0f;\n"
"\n"
"            // Compute the full set of interactions in this tile.\n"
"\n"
"            unsigned int tj = tgx;\n"
"            for (j = 0; j < TILE_SIZE; j++) {\n"
"                real3 delta = make_real3(localData[tbx+tj].x-posq1.x, localData[tbx+tj].y-posq1.y, localData[tbx+tj].z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                if (atom1 < NUM_ATOMS && y*TILE_SIZE+tj < NUM_ATOMS && r2 < CUTOFF_SQUARED) {\n"
"#else\n"
"                if (atom1 < NUM_ATOMS && y*TILE_SIZE+tj < NUM_ATOMS) {\n"
"#endif\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    float2 params2 = make_float2(localData[tbx+tj].radius, localData[tbx+tj].scaledRadius);\n"
"                    real rScaledRadiusJ = r+params2.y;\n"
"                    if (params1.x < rScaledRadiusJ) {\n"
"                        real l_ij = RECIP(max(params1.x, fabs(r-params2.y)));\n"
"                        real u_ij = RECIP(rScaledRadiusJ);\n"
"                        real l_ij2 = l_ij*l_ij;\n"
"                        real u_ij2 = u_ij*u_ij;\n"
"                        real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                        bornSum += l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                            (params2.y*params2.y*invR)*(l_ij2-u_ij2));\n"
"                        bornSum += (params1.x < params2.y-r ? 2.0f*(RECIP(params1.x)-l_ij) : 0);\n"
"                    }\n"
"                    real rScaledRadiusI = r+params1.y;\n"
"                    if (params2.x < rScaledRadiusI) {\n"
"                        real l_ij = RECIP(max(params2.x, fabs(r-params1.y)));\n"
"                        real u_ij = RECIP(rScaledRadiusI);\n"
"                        real l_ij2 = l_ij*l_ij;\n"
"                        real u_ij2 = u_ij*u_ij;\n"
"                        real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                        real term = l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                            (params1.y*params1.y*invR)*(l_ij2-u_ij2));\n"
"                        term += (params2.x < params1.y-r ? 2.0f*(RECIP(params2.x)-l_ij) : 0);\n"
"                        localData[tbx+tj].bornSum += term;\n"
"                    }\n"
"                }\n"
"                tj = (tj + 1) & (TILE_SIZE - 1);\n"
"            }\n"
"        }\n"
"        \n"
"        // Write results.\n"
"        \n"
"        unsigned int offset = x*TILE_SIZE + tgx;\n"
"        atomicAdd(&global_bornSum[offset], static_cast<unsigned long long>((long long) (bornSum*0x100000000)));\n"
"        if (x != y) {\n"
"            offset = y*TILE_SIZE + tgx;\n"
"            atomicAdd(&global_bornSum[offset], static_cast<unsigned long long>((long long) (localData[threadIdx.x].bornSum*0x100000000)));\n"
"        }\n"
"    }\n"
"\n"
"    // Second loop: tiles without exclusions, either from the neighbor list (with cutoff) or just enumerating all\n"
"    // of them (no cutoff).\n"
"\n"
"#ifdef USE_CUTOFF\n"
"    unsigned int numTiles = interactionCount[0];\n"
"    if (numTiles > maxTiles)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    int pos = (int) (warp*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"    int end = (int) ((warp+1)*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"#else\n"
"    int pos = (int) (warp*(long long)numTiles/totalWarps);\n"
"    int end = (int) ((warp+1)*(long long)numTiles/totalWarps);\n"
"#endif\n"
"    int skipBase = 0;\n"
"    int currentSkipIndex = tbx;\n"
"    __shared__ int atomIndices[FORCE_WORK_GROUP_SIZE];\n"
"    __shared__ volatile int skipTiles[FORCE_WORK_GROUP_SIZE];\n"
"    skipTiles[threadIdx.x] = -1;\n"
"\n"
"    while (pos < end) {\n"
"        real bornSum = 0;\n"
"        bool includeTile = true;\n"
"\n"
"        // Extract the coordinates of this tile.\n"
"        \n"
"        int x, y;\n"
"        bool singlePeriodicCopy = false;\n"
"#ifdef USE_CUTOFF\n"
"            x = tiles[pos];\n"
"            real4 blockSizeX = blockSize[x];\n"
"            singlePeriodicCopy = (0.5f*periodicBoxSize.x-blockSizeX.x >= CUTOFF &&\n"
"                                  0.5f*periodicBoxSize.y-blockSizeX.y >= CUTOFF &&\n"
"                                  0.5f*periodicBoxSize.z-blockSizeX.z >= CUTOFF);\n"
"#else\n"
"        y = (int) floor(NUM_BLOCKS+0.5f-SQRT((NUM_BLOCKS+0.5f)*(NUM_BLOCKS+0.5f)-2*pos));\n"
"        x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        if (x < y || x >= NUM_BLOCKS) { // Occasionally happens due to roundoff error.\n"
"            y += (x < y ? -1 : 1);\n"
"            x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        }\n"
"\n"
"        // Skip over tiles that have exclusions, since they were already processed.\n"
"\n"
"        while (skipTiles[tbx+TILE_SIZE-1] < pos) {\n"
"            if (skipBase+tgx < NUM_TILES_WITH_EXCLUSIONS) {\n"
"                ushort2 tile = exclusionTiles[skipBase+tgx];\n"
"                skipTiles[threadIdx.x] = tile.x + tile.y*NUM_BLOCKS - tile.y*(tile.y+1)/2;\n"
"            }\n"
"            else\n"
"                skipTiles[threadIdx.x] = end;\n"
"            skipBase += TILE_SIZE;            \n"
"            currentSkipIndex = tbx;\n"
"        }\n"
"        while (skipTiles[currentSkipIndex] < pos)\n"
"            currentSkipIndex++;\n"
"        includeTile = (skipTiles[currentSkipIndex] != pos);\n"
"#endif\n"
"        if (includeTile) {\n"
"            unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"\n"
"            // Load atom data for this tile.\n"
"\n"
"            real4 posq1 = posq[atom1];\n"
"            real charge1 = charge[atom1];\n"
"            float2 params1 = global_params[atom1];\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int j = interactingAtoms[pos*TILE_SIZE+tgx];\n"
"#else\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            atomIndices[threadIdx.x] = j;\n"
"            if (j < PADDED_NUM_ATOMS) {\n"
"                real4 tempPosq = posq[j];\n"
"                localData[threadIdx.x].x = tempPosq.x;\n"
"                localData[threadIdx.x].y = tempPosq.y;\n"
"                localData[threadIdx.x].z = tempPosq.z;\n"
"                localData[threadIdx.x].q = charge[j];\n"
"                float2 tempParams = global_params[j];\n"
"                localData[threadIdx.x].radius = tempParams.x;\n"
"                localData[threadIdx.x].scaledRadius = tempParams.y;\n"
"                localData[threadIdx.x].bornSum = 0.0f;\n"
"            }\n"
"#ifdef USE_PERIODIC\n"
"            if (singlePeriodicCopy) {\n"
"                // The box is small enough that we can just translate all the atoms into a single periodic\n"
"                // box, then skip having to apply periodic boundary conditions later.\n"
"\n"
"                real4 blockCenterX = blockCenter[x];\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(posq1, blockCenterX)\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(localData[threadIdx.x], blockCenterX)\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    real3 delta = make_real3(localData[tbx+tj].x-posq1.x, localData[tbx+tj].y-posq1.y, localData[tbx+tj].z-posq1.z);\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                    int atom2 = atomIndices[tbx+tj];\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && r2 < CUTOFF_SQUARED) {\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        float2 params2 = make_float2(localData[tbx+tj].radius, localData[tbx+tj].scaledRadius);\n"
"                        real rScaledRadiusJ = r+params2.y;\n"
"                        if (params1.x < rScaledRadiusJ) {\n"
"                            real l_ij = RECIP(max(params1.x, fabs(r-params2.y)));\n"
"                            real u_ij = RECIP(rScaledRadiusJ);\n"
"                            real l_ij2 = l_ij*l_ij;\n"
"                            real u_ij2 = u_ij*u_ij;\n"
"                            real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                            bornSum += l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                                (params2.y*params2.y*invR)*(l_ij2-u_ij2));\n"
"                            bornSum += (params1.x < params2.y-r ? 2.0f*(RECIP(params1.x)-l_ij) : 0);\n"
"                        }\n"
"                        real rScaledRadiusI = r+params1.y;\n"
"                        if (params2.x < rScaledRadiusI) {\n"
"                            real l_ij = RECIP(max(params2.x, fabs(r-params1.y)));\n"
"                            real u_ij = RECIP(rScaledRadiusI);\n"
"                            real l_ij2 = l_ij*l_ij;\n"
"                            real u_ij2 = u_ij*u_ij;\n"
"                            real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                            real term = l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                                (params1.y*params1.y*invR)*(l_ij2-u_ij2));\n"
"                            term += (params2.x < params1.y-r ? 2.0f*(RECIP(params2.x)-l_ij) : 0);\n"
"                            localData[tbx+tj].bornSum += term;\n"
"                        }\n"
"                    }\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"            else\n"
"#endif\n"
"            {\n"
"                // We need to apply periodic boundary conditions separately for each interaction.\n"
"\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    real3 delta = make_real3(localData[tbx+tj].x-posq1.x, localData[tbx+tj].y-posq1.y, localData[tbx+tj].z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                    APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                    int atom2 = atomIndices[tbx+tj];\n"
"#ifdef USE_CUTOFF\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && r2 < CUTOFF_SQUARED) {\n"
"#else\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"#endif\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        float2 params2 = make_float2(localData[tbx+tj].radius, localData[tbx+tj].scaledRadius);\n"
"                        real rScaledRadiusJ = r+params2.y;\n"
"                        if (params1.x < rScaledRadiusJ) {\n"
"                            real l_ij = RECIP(max(params1.x, fabs(r-params2.y)));\n"
"                            real u_ij = RECIP(rScaledRadiusJ);\n"
"                            real l_ij2 = l_ij*l_ij;\n"
"                            real u_ij2 = u_ij*u_ij;\n"
"                            real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                            bornSum += l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                                (params2.y*params2.y*invR)*(l_ij2-u_ij2));\n"
"                            bornSum += (params1.x < params2.y-r ? 2.0f*(RECIP(params1.x)-l_ij) : 0);\n"
"                        }\n"
"                        real rScaledRadiusI = r+params1.y;\n"
"                        if (params2.x < rScaledRadiusI) {\n"
"                            real l_ij = RECIP(max(params2.x, fabs(r-params1.y)));\n"
"                            real u_ij = RECIP(rScaledRadiusI);\n"
"                            real l_ij2 = l_ij*l_ij;\n"
"                            real u_ij2 = u_ij*u_ij;\n"
"                            real ratio = LOG(u_ij * RECIP(l_ij));\n"
"                            real term = l_ij - u_ij + (0.50f*invR*ratio) + 0.25f*(r*(u_ij2-l_ij2) +\n"
"                                                (params1.y*params1.y*invR)*(l_ij2-u_ij2));\n"
"                            term += (params2.x < params1.y-r ? 2.0f*(RECIP(params2.x)-l_ij) : 0);\n"
"                            localData[tbx+tj].bornSum += term;\n"
"                        }\n"
"                    }\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"        \n"
"            // Write results.\n"
"\n"
"            atomicAdd(&global_bornSum[atom1], static_cast<unsigned long long>((long long) (bornSum*0x100000000)));\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int atom2 = atomIndices[threadIdx.x];\n"
"#else\n"
"            unsigned int atom2 = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            if (atom2 < PADDED_NUM_ATOMS)\n"
"                atomicAdd(&global_bornSum[atom2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].bornSum*0x100000000)));\n"
"        }\n"
"        pos++;\n"
"    }\n"
"}\n"
"\n"
"typedef struct {\n"
"    real x, y, z;\n"
"    real q;\n"
"    real fx, fy, fz, fw;\n"
"    real bornRadius;\n"
"} AtomData2;\n"
"\n"
"/**\n"
" * First part of computing the GBSA interaction.\n"
" */\n"
"\n"
"extern \"C\" __global__ void computeGBSAForce1(unsigned long long* __restrict__ forceBuffers, unsigned long long* __restrict__ global_bornForce,\n"
"        mixed* __restrict__ energyBuffer, const real4* __restrict__ posq, const real* __restrict__ charge, const real* __restrict__ global_bornRadii, bool needEnergy,\n"
"#ifdef USE_CUTOFF\n"
"        const int* __restrict__ tiles, const unsigned int* __restrict__ interactionCount, real4 periodicBoxSize, real4 invPeriodicBoxSize,\n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ, unsigned int maxTiles, const real4* __restrict__ blockCenter,\n"
"        const real4* __restrict__ blockSize, const unsigned int* __restrict__ interactingAtoms,\n"
"#else\n"
"        unsigned int numTiles,\n"
"#endif\n"
"        const ushort2* __restrict__ exclusionTiles) {\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE;\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1);\n"
"    const unsigned int tbx = threadIdx.x - tgx;\n"
"    mixed energy = 0;\n"
"    __shared__ AtomData2 localData[FORCE_WORK_GROUP_SIZE];\n"
"\n"
"    // First loop: process tiles that contain exclusions.\n"
"    \n"
"    const unsigned int firstExclusionTile = FIRST_EXCLUSION_TILE+warp*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    const unsigned int lastExclusionTile = FIRST_EXCLUSION_TILE+(warp+1)*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    for (int pos = firstExclusionTile; pos < lastExclusionTile; pos++) {\n"
"        const ushort2 tileIndices = exclusionTiles[pos];\n"
"        const unsigned int x = tileIndices.x;\n"
"        const unsigned int y = tileIndices.y;\n"
"        real4 force = make_real4(0);\n"
"        unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"        real4 posq1 = posq[atom1];\n"
"        real charge1 = charge[atom1];\n"
"        real bornRadius1 = global_bornRadii[atom1];\n"
"        if (x == y) {\n"
"            // This tile is on the diagonal.\n"
"\n"
"            localData[threadIdx.x].x = posq1.x;\n"
"            localData[threadIdx.x].y = posq1.y;\n"
"            localData[threadIdx.x].z = posq1.z;\n"
"            localData[threadIdx.x].q = charge1;\n"
"            localData[threadIdx.x].bornRadius = bornRadius1;\n"
"            for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                if (atom1 < NUM_ATOMS && y*TILE_SIZE+j < NUM_ATOMS) {\n"
"                    real3 pos2 = make_real3(localData[tbx+j].x, localData[tbx+j].y, localData[tbx+j].z);\n"
"                    real charge2 = localData[tbx+j].q;\n"
"                    real3 delta = make_real3(pos2.x-posq1.x, pos2.y-posq1.y, pos2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                    APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                    if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        real bornRadius2 = localData[tbx+j].bornRadius;\n"
"                        real alpha2_ij = bornRadius1*bornRadius2;\n"
"                        real D_ij = r2*RECIP(4.0f*alpha2_ij);\n"
"                        real expTerm = EXP(-D_ij);\n"
"                        real denominator2 = r2 + alpha2_ij*expTerm;\n"
"                        real denominator = SQRT(denominator2);\n"
"                        real scaledChargeProduct = PREFACTOR*charge1*charge2;\n"
"                        real tempEnergy = scaledChargeProduct*RECIP(denominator);\n"
"                        real Gpol = tempEnergy*RECIP(denominator2);\n"
"                        real dGpol_dalpha2_ij = -0.5f*Gpol*expTerm*(1.0f+D_ij);\n"
"                        real dEdR = Gpol*(1.0f - 0.25f*expTerm);\n"
"                        force.w += dGpol_dalpha2_ij*bornRadius2;\n"
"#ifdef USE_CUTOFF\n"
"                        if (atom1 != y*TILE_SIZE+j)\n"
"                            tempEnergy -= scaledChargeProduct/CUTOFF;\n"
"#endif\n"
"                        if (needEnergy)\n"
"                            energy += 0.5f*tempEnergy;\n"
"                        delta *= dEdR;\n"
"                        force.x -= delta.x;\n"
"                        force.y -= delta.y;\n"
"                        force.z -= delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                }\n"
"            }\n"
"        }\n"
"        else {\n"
"            // This is an off-diagonal tile.\n"
"\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"            real4 tempPosq = posq[j];\n"
"            localData[threadIdx.x].x = tempPosq.x;\n"
"            localData[threadIdx.x].y = tempPosq.y;\n"
"            localData[threadIdx.x].z = tempPosq.z;\n"
"            localData[threadIdx.x].q = charge[j];\n"
"            localData[threadIdx.x].bornRadius = global_bornRadii[j];\n"
"            localData[threadIdx.x].fx = 0.0f;\n"
"            localData[threadIdx.x].fy = 0.0f;\n"
"            localData[threadIdx.x].fz = 0.0f;\n"
"            localData[threadIdx.x].fw = 0.0f;\n"
"            unsigned int tj = tgx;\n"
"            for (j = 0; j < TILE_SIZE; j++) {\n"
"                if (atom1 < NUM_ATOMS && y*TILE_SIZE+tj < NUM_ATOMS) {\n"
"                    real3 pos2 = make_real3(localData[tbx+tj].x, localData[tbx+tj].y, localData[tbx+tj].z);\n"
"                    real charge2 = localData[tbx+tj].q;\n"
"                    real3 delta = make_real3(pos2.x-posq1.x, pos2.y-posq1.y, pos2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                    APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                    if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                        real invR = RSQRT(r2);\n"
"                        real r = r2*invR;\n"
"                        real bornRadius2 = localData[tbx+tj].bornRadius;\n"
"                        real alpha2_ij = bornRadius1*bornRadius2;\n"
"                        real D_ij = r2*RECIP(4.0f*alpha2_ij);\n"
"                        real expTerm = EXP(-D_ij);\n"
"                        real denominator2 = r2 + alpha2_ij*expTerm;\n"
"                        real denominator = SQRT(denominator2);\n"
"                        real scaledChargeProduct = PREFACTOR*charge1*charge2;\n"
"                        real tempEnergy = scaledChargeProduct*RECIP(denominator);\n"
"                        real Gpol = tempEnergy*RECIP(denominator2);\n"
"                        real dGpol_dalpha2_ij = -0.5f*Gpol*expTerm*(1.0f+D_ij);\n"
"                        real dEdR = Gpol*(1.0f - 0.25f*expTerm);\n"
"                        force.w += dGpol_dalpha2_ij*bornRadius2;\n"
"#ifdef USE_CUTOFF\n"
"                        tempEnergy -= scaledChargeProduct/CUTOFF;\n"
"#endif\n"
"                        if (needEnergy)\n"
"                            energy += tempEnergy;\n"
"                        delta *= dEdR;\n"
"                        force.x -= delta.x;\n"
"                        force.y -= delta.y;\n"
"                        force.z -= delta.z;\n"
"                        localData[tbx+tj].fx += delta.x;\n"
"                        localData[tbx+tj].fy += delta.y;\n"
"                        localData[tbx+tj].fz += delta.z;\n"
"                        localData[tbx+tj].fw += dGpol_dalpha2_ij*bornRadius1;\n"
"#ifdef USE_CUTOFF\n"
"                    }\n"
"#endif\n"
"                }\n"
"                tj = (tj + 1) & (TILE_SIZE - 1);\n"
"            }\n"
"        }\n"
"        \n"
"        // Write results.\n"
"        \n"
"        unsigned int offset = x*TILE_SIZE + tgx;\n"
"        atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"        atomicAdd(&global_bornForce[offset], static_cast<unsigned long long>((long long) (force.w*0x100000000)));\n"
"        if (x != y) {\n"
"            offset = y*TILE_SIZE + tgx;\n"
"            atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fx*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fy*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fz*0x100000000)));\n"
"            atomicAdd(&global_bornForce[offset], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fw*0x100000000)));\n"
"        }\n"
"    }\n"
"\n"
"    // Second loop: tiles without exclusions, either from the neighbor list (with cutoff) or just enumerating all\n"
"    // of them (no cutoff).\n"
"\n"
"#ifdef USE_CUTOFF\n"
"    unsigned int numTiles = interactionCount[0];\n"
"    if (numTiles > maxTiles)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    int pos = (int) (warp*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"    int end = (int) ((warp+1)*(numTiles > maxTiles ? NUM_BLOCKS*((long long)NUM_BLOCKS+1)/2 : (long)numTiles)/totalWarps);\n"
"#else\n"
"    int pos = (int) (warp*(long long)numTiles/totalWarps);\n"
"    int end = (int) ((warp+1)*(long long)numTiles/totalWarps);\n"
"#endif\n"
"    int skipBase = 0;\n"
"    int currentSkipIndex = tbx;\n"
"    __shared__ int atomIndices[FORCE_WORK_GROUP_SIZE];\n"
"    __shared__ volatile int skipTiles[FORCE_WORK_GROUP_SIZE];\n"
"    skipTiles[threadIdx.x] = -1;\n"
"\n"
"    while (pos < end) {\n"
"        real4 force = make_real4(0);\n"
"        bool includeTile = true;\n"
"\n"
"        // Extract the coordinates of this tile.\n"
"        \n"
"        int x, y;\n"
"        bool singlePeriodicCopy = false;\n"
"#ifdef USE_CUTOFF\n"
"        x = tiles[pos];\n"
"        real4 blockSizeX = blockSize[x];\n"
"        singlePeriodicCopy = (0.5f*periodicBoxSize.x-blockSizeX.x >= CUTOFF &&\n"
"                              0.5f*periodicBoxSize.y-blockSizeX.y >= CUTOFF &&\n"
"                              0.5f*periodicBoxSize.z-blockSizeX.z >= CUTOFF);\n"
"#else\n"
"        y = (int) floor(NUM_BLOCKS+0.5f-SQRT((NUM_BLOCKS+0.5f)*(NUM_BLOCKS+0.5f)-2*pos));\n"
"        x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        if (x < y || x >= NUM_BLOCKS) { // Occasionally happens due to roundoff error.\n"
"            y += (x < y ? -1 : 1);\n"
"            x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        }\n"
"\n"
"        // Skip over tiles that have exclusions, since they were already processed.\n"
"\n"
"        while (skipTiles[tbx+TILE_SIZE-1] < pos) {\n"
"            if (skipBase+tgx < NUM_TILES_WITH_EXCLUSIONS) {\n"
"                ushort2 tile = exclusionTiles[skipBase+tgx];\n"
"                skipTiles[threadIdx.x] = tile.x + tile.y*NUM_BLOCKS - tile.y*(tile.y+1)/2;\n"
"            }\n"
"            else\n"
"                skipTiles[threadIdx.x] = end;\n"
"            skipBase += TILE_SIZE;            \n"
"            currentSkipIndex = tbx;\n"
"        }\n"
"        while (skipTiles[currentSkipIndex] < pos)\n"
"            currentSkipIndex++;\n"
"        includeTile = (skipTiles[currentSkipIndex] != pos);\n"
"#endif\n"
"        if (includeTile) {\n"
"            unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"\n"
"            // Load atom data for this tile.\n"
"            \n"
"            real4 posq1 = posq[atom1];\n"
"            real charge1 = charge[atom1];\n"
"            real bornRadius1 = global_bornRadii[atom1];\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int j = interactingAtoms[pos*TILE_SIZE+tgx];\n"
"#else\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            atomIndices[threadIdx.x] = j;\n"
"            if (j < PADDED_NUM_ATOMS) {\n"
"                real4 tempPosq = posq[j];\n"
"                localData[threadIdx.x].x = tempPosq.x;\n"
"                localData[threadIdx.x].y = tempPosq.y;\n"
"                localData[threadIdx.x].z = tempPosq.z;\n"
"                localData[threadIdx.x].q = charge[j];\n"
"                localData[threadIdx.x].bornRadius = global_bornRadii[j];\n"
"                localData[threadIdx.x].fx = 0.0f;\n"
"                localData[threadIdx.x].fy = 0.0f;\n"
"                localData[threadIdx.x].fz = 0.0f;\n"
"                localData[threadIdx.x].fw = 0.0f;\n"
"            }\n"
"#ifdef USE_PERIODIC\n"
"            if (singlePeriodicCopy) {\n"
"                // The box is small enough that we can just translate all the atoms into a single periodic\n"
"                // box, then skip having to apply periodic boundary conditions later.\n"
"\n"
"                real4 blockCenterX = blockCenter[x];\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(posq1, blockCenterX)\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(localData[threadIdx.x], blockCenterX)\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = atomIndices[tbx+tj];\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                        real3 pos2 = make_real3(localData[tbx+tj].x, localData[tbx+tj].y, localData[tbx+tj].z);\n"
"                        real charge2 = localData[tbx+tj].q;\n"
"                        real3 delta = make_real3(pos2.x-posq1.x, pos2.y-posq1.y, pos2.z-posq1.z);\n"
"                        real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                        if (r2 < CUTOFF_SQUARED) {\n"
"                            real invR = RSQRT(r2);\n"
"                            real r = r2*invR;\n"
"                            real bornRadius2 = localData[tbx+tj].bornRadius;\n"
"                            real alpha2_ij = bornRadius1*bornRadius2;\n"
"                            real D_ij = r2*RECIP(4.0f*alpha2_ij);\n"
"                            real expTerm = EXP(-D_ij);\n"
"                            real denominator2 = r2 + alpha2_ij*expTerm;\n"
"                            real denominator = SQRT(denominator2);\n"
"                            real scaledChargeProduct = PREFACTOR*charge1*charge2;\n"
"                            real tempEnergy = scaledChargeProduct*RECIP(denominator);\n"
"                            real Gpol = tempEnergy*RECIP(denominator2);\n"
"                            real dGpol_dalpha2_ij = -0.5f*Gpol*expTerm*(1.0f+D_ij);\n"
"                            real dEdR = Gpol*(1.0f - 0.25f*expTerm);\n"
"                            force.w += dGpol_dalpha2_ij*bornRadius2;\n"
"#ifdef USE_CUTOFF\n"
"                            tempEnergy -= scaledChargeProduct/CUTOFF;\n"
"#endif\n"
"                            if (needEnergy)\n"
"                                energy += tempEnergy;\n"
"                            delta *= dEdR;\n"
"                            force.x -= delta.x;\n"
"                            force.y -= delta.y;\n"
"                            force.z -= delta.z;\n"
"                            localData[tbx+tj].fx += delta.x;\n"
"                            localData[tbx+tj].fy += delta.y;\n"
"                            localData[tbx+tj].fz += delta.z;\n"
"                            localData[tbx+tj].fw += dGpol_dalpha2_ij*bornRadius1;\n"
"                        }\n"
"                    }\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"            else\n"
"#endif\n"
"            {\n"
"                // We need to apply periodic boundary conditions separately for each interaction.\n"
"\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = atomIndices[tbx+tj];\n"
"                    if (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS) {\n"
"                        real3 pos2 = make_real3(localData[tbx+tj].x, localData[tbx+tj].y, localData[tbx+tj].z);\n"
"                        real charge2 = localData[tbx+tj].q;\n"
"                        real3 delta = make_real3(pos2.x-posq1.x, pos2.y-posq1.y, pos2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                        APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                        real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"#ifdef USE_CUTOFF\n"
"                        if (r2 < CUTOFF_SQUARED) {\n"
"#endif\n"
"                            real invR = RSQRT(r2);\n"
"                            real r = r2*invR;\n"
"                            real bornRadius2 = localData[tbx+tj].bornRadius;\n"
"                            real alpha2_ij = bornRadius1*bornRadius2;\n"
"                            real D_ij = r2*RECIP(4.0f*alpha2_ij);\n"
"                            real expTerm = EXP(-D_ij);\n"
"                            real denominator2 = r2 + alpha2_ij*expTerm;\n"
"                            real denominator = SQRT(denominator2);\n"
"                            real scaledChargeProduct = PREFACTOR*charge1*charge2;\n"
"                            real tempEnergy = scaledChargeProduct*RECIP(denominator);\n"
"                            real Gpol = tempEnergy*RECIP(denominator2);\n"
"                            real dGpol_dalpha2_ij = -0.5f*Gpol*expTerm*(1.0f+D_ij);\n"
"                            real dEdR = Gpol*(1.0f - 0.25f*expTerm);\n"
"                            force.w += dGpol_dalpha2_ij*bornRadius2;\n"
"#ifdef USE_CUTOFF\n"
"                            tempEnergy -= scaledChargeProduct/CUTOFF;\n"
"#endif\n"
"                            if (needEnergy)\n"
"                                energy += tempEnergy;\n"
"                            delta *= dEdR;\n"
"                            force.x -= delta.x;\n"
"                            force.y -= delta.y;\n"
"                            force.z -= delta.z;\n"
"                            localData[tbx+tj].fx += delta.x;\n"
"                            localData[tbx+tj].fy += delta.y;\n"
"                            localData[tbx+tj].fz += delta.z;\n"
"                            localData[tbx+tj].fw += dGpol_dalpha2_ij*bornRadius1;\n"
"#ifdef USE_CUTOFF\n"
"                        }\n"
"#endif\n"
"                    }\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"\n"
"            // Write results.\n"
"\n"
"            atomicAdd(&forceBuffers[atom1], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"            atomicAdd(&global_bornForce[atom1], static_cast<unsigned long long>((long long) (force.w*0x100000000)));\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int atom2 = atomIndices[threadIdx.x];\n"
"#else\n"
"            unsigned int atom2 = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            if (atom2 < PADDED_NUM_ATOMS) {\n"
"                atomicAdd(&forceBuffers[atom2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fx*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fy*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fz*0x100000000)));\n"
"                atomicAdd(&global_bornForce[atom2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fw*0x100000000)));\n"
"            }\n"
"        }\n"
"        pos++;\n"
"    }\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"}\n"
"";
const string CudaKernelSources::gbsaObc2 = "{\n"
"    real invRSquaredOver4 = 0.25f*invR*invR;\n"
"    real rScaledRadiusJ = r+OBC_PARAMS2.y;\n"
"    real rScaledRadiusI = r+OBC_PARAMS1.y;\n"
"    real l_ijJ = RECIP(max(OBC_PARAMS1.x, fabs(r-OBC_PARAMS2.y)));\n"
"    real l_ijI = RECIP(max(OBC_PARAMS2.x, fabs(r-OBC_PARAMS1.y)));\n"
"    real u_ijJ = RECIP(rScaledRadiusJ);\n"
"    real u_ijI = RECIP(rScaledRadiusI);\n"
"    real l_ij2J = l_ijJ*l_ijJ;\n"
"    real l_ij2I = l_ijI*l_ijI;\n"
"    real u_ij2J = u_ijJ*u_ijJ;\n"
"    real u_ij2I = u_ijI*u_ijI;\n"
"    real t1J = LOG(u_ijJ*RECIP(l_ijJ));\n"
"    real t1I = LOG(u_ijI*RECIP(l_ijI));\n"
"    real t2J = (l_ij2J-u_ij2J);\n"
"    real t2I = (l_ij2I-u_ij2I);\n"
"    real term1 = (0.5f*(0.25f+OBC_PARAMS2.y*OBC_PARAMS2.y*invRSquaredOver4)*t2J + t1J*invRSquaredOver4)*invR;\n"
"    real term2 = (0.5f*(0.25f+OBC_PARAMS1.y*OBC_PARAMS1.y*invRSquaredOver4)*t2I + t1I*invRSquaredOver4)*invR;\n"
"    real tempdEdR = (OBC_PARAMS1.x < rScaledRadiusJ ? BORN_FORCE1*term1/0x100000000 : 0);\n"
"    tempdEdR += (OBC_PARAMS2.x < rScaledRadiusI ? BORN_FORCE2*term2/0x100000000 : 0);\n"
"#ifdef USE_CUTOFF\n"
"    unsigned int includeInteraction = (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && atom1 != atom2 && r2 < CUTOFF_SQUARED);\n"
"#else\n"
"    unsigned int includeInteraction = (atom1 < NUM_ATOMS && atom2 < NUM_ATOMS && atom1 != atom2);\n"
"#endif\n"
"    dEdR += (includeInteraction ? tempdEdR : 0);\n"
"}\n"
"";
const string CudaKernelSources::harmonicAngleForce = "float2 angleParams = PARAMS[index];\n"
"real deltaIdeal = theta-angleParams.x;\n"
"energy += 0.5f*angleParams.y*deltaIdeal*deltaIdeal;\n"
"real dEdAngle = angleParams.y*deltaIdeal;\n"
"";
const string CudaKernelSources::harmonicBondForce = "float2 bondParams = PARAMS[index];\n"
"real deltaIdeal = r-bondParams.x;\n"
"energy += 0.5f * bondParams.y*deltaIdeal*deltaIdeal;\n"
"real dEdR = bondParams.y * deltaIdeal;\n"
"";
const string CudaKernelSources::integrationUtilities = "/**\n"
" * Generate random numbers\n"
" */\n"
"extern \"C\" __global__ void generateRandomNumbers(int numValues, float4* __restrict__ random, uint4* __restrict__ seed) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    uint4 state = seed[index];\n"
"    unsigned int carry = 0;\n"
"    while (index < numValues) {\n"
"        float4 value;\n"
"\n"
"        // Generate first two values.\n"
"\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        unsigned int k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        unsigned int m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x1 = (float)max(state.x + state.y + state.w, 0x00000001u) / (float)0xffffffff;\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        x1 = SQRT(-2.0f * LOG(x1));\n"
"        k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x2 = (float)(state.x + state.y + state.w) / (float)0xffffffff;\n"
"        value.x = x1 * COS(2.0f * 3.14159265f * x2);\n"
"        value.y = x1 * SIN(2.0f * 3.14159265f * x2);\n"
"\n"
"        // Generate next two values.\n"
"\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x3 = (float)max(state.x + state.y + state.w, 0x00000001u) / (float)0xffffffff;\n"
"        state.x = state.x * 69069 + 1;\n"
"        state.y ^= state.y << 13;\n"
"        state.y ^= state.y >> 17;\n"
"        state.y ^= state.y << 5;\n"
"        x3 = SQRT(-2.0f * LOG(x3));\n"
"        k = (state.z >> 2) + (state.w >> 3) + (carry >> 2);\n"
"        m = state.w + state.w + state.z + carry;\n"
"        state.z = state.w;\n"
"        state.w = m;\n"
"        carry = k >> 30;\n"
"        float x4 = (float)(state.x + state.y + state.w) / (float)0xffffffff;\n"
"        value.z = x3 * COS(2.0f * 3.14159265f * x4);\n"
"        value.w = x3 * SIN(2.0f * 3.14159265f * x4);\n"
"\n"
"        // Record the values.\n"
"\n"
"        random[index] = value;\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"    seed[blockIdx.x*blockDim.x+threadIdx.x] = state;\n"
"}\n"
"\n"
"/**\n"
" * Load the position of a particle.\n"
" */\n"
"inline __device__ mixed4 loadPos(const real4* __restrict__ posq, const real4* __restrict__ posqCorrection, int index) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"    real4 pos1 = posq[index];\n"
"    real4 pos2 = posqCorrection[index];\n"
"    return make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"    return posq[index];\n"
"#endif\n"
"}\n"
"\n"
"/**\n"
" * Store the position of a particle.\n"
" */\n"
"inline __device__ void storePos(real4* __restrict__ posq, real4* __restrict__ posqCorrection, int index, mixed4 pos) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"    posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"    posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"    posq[index] = pos;\n"
"#endif\n"
"}\n"
"\n"
"/**\n"
" * Enforce constraints on SHAKE clusters\n"
" */\n"
"extern \"C\" __global__ void applyShakeToPositions(int numClusters, mixed tol, const real4* __restrict__ oldPos, real4* __restrict__ posCorrection, mixed4* __restrict__ posDelta, const int4* __restrict__ clusterAtoms, const float4* __restrict__ clusterParams) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    while (index < numClusters) {\n"
"        // Load the data for this cluster.\n"
"\n"
"        int4 atoms = clusterAtoms[index];\n"
"        float4 params = clusterParams[index];\n"
"        mixed4 pos = loadPos(oldPos, posCorrection, atoms.x);\n"
"        mixed4 xpi = posDelta[atoms.x];\n"
"        mixed4 pos1 = loadPos(oldPos, posCorrection, atoms.y);\n"
"        mixed4 xpj1 = posDelta[atoms.y];\n"
"        mixed4 pos2 = make_mixed4(0);\n"
"        mixed4 xpj2 = make_mixed4(0);\n"
"        float invMassCentral = params.x;\n"
"        float avgMass = params.y;\n"
"        float d2 = params.z;\n"
"        float invMassPeripheral = params.w;\n"
"        if (atoms.z != -1) {\n"
"            pos2 = loadPos(oldPos, posCorrection, atoms.z);\n"
"            xpj2 = posDelta[atoms.z];\n"
"        }\n"
"        mixed4 pos3 = make_mixed4(0);\n"
"        mixed4 xpj3 = make_mixed4(0);\n"
"        if (atoms.w != -1) {\n"
"            pos3 = loadPos(oldPos, posCorrection, atoms.w);\n"
"            xpj3 = posDelta[atoms.w];\n"
"        }\n"
"\n"
"        // Precompute quantities.\n"
"\n"
"        mixed3 rij1 = make_mixed3(pos.x-pos1.x, pos.y-pos1.y, pos.z-pos1.z);\n"
"        mixed3 rij2 = make_mixed3(pos.x-pos2.x, pos.y-pos2.y, pos.z-pos2.z);\n"
"        mixed3 rij3 = make_mixed3(pos.x-pos3.x, pos.y-pos3.y, pos.z-pos3.z);\n"
"        mixed rij1sq = rij1.x*rij1.x + rij1.y*rij1.y + rij1.z*rij1.z;\n"
"        mixed rij2sq = rij2.x*rij2.x + rij2.y*rij2.y + rij2.z*rij2.z;\n"
"        mixed rij3sq = rij3.x*rij3.x + rij3.y*rij3.y + rij3.z*rij3.z;\n"
"        mixed ld1 = d2-rij1sq;\n"
"        mixed ld2 = d2-rij2sq;\n"
"        mixed ld3 = d2-rij3sq;\n"
"\n"
"        // Iterate until convergence.\n"
"\n"
"        bool converged = false;\n"
"        int iteration = 0;\n"
"        while (iteration < 15 && !converged) {\n"
"            converged = true;\n"
"            mixed3 rpij = make_mixed3(xpi.x-xpj1.x, xpi.y-xpj1.y, xpi.z-xpj1.z);\n"
"            mixed rpsqij = rpij.x*rpij.x + rpij.y*rpij.y + rpij.z*rpij.z;\n"
"            mixed rrpr = rij1.x*rpij.x + rij1.y*rpij.y + rij1.z*rpij.z;\n"
"            mixed diff = fabs(ld1-2.0f*rrpr-rpsqij) / (d2*tol);\n"
"            if (diff >= 1.0f) {\n"
"                mixed acor  = (ld1-2.0f*rrpr-rpsqij)*avgMass / (rrpr+rij1sq);\n"
"                mixed3 dr = rij1*acor;\n"
"                xpi.x += dr.x*invMassCentral;\n"
"                xpi.y += dr.y*invMassCentral;\n"
"                xpi.z += dr.z*invMassCentral;\n"
"                xpj1.x -= dr.x*invMassPeripheral;\n"
"                xpj1.y -= dr.y*invMassPeripheral;\n"
"                xpj1.z -= dr.z*invMassPeripheral;\n"
"                converged = false;\n"
"            }\n"
"            if (atoms.z != -1) {\n"
"                rpij = make_mixed3(xpi.x-xpj2.x, xpi.y-xpj2.y, xpi.z-xpj2.z);\n"
"                rpsqij = rpij.x*rpij.x + rpij.y*rpij.y + rpij.z*rpij.z;\n"
"                rrpr = rij2.x*rpij.x + rij2.y*rpij.y + rij2.z*rpij.z;\n"
"                diff = fabs(ld2-2.0f*rrpr-rpsqij) / (d2*tol);\n"
"                if (diff >= 1.0f) {\n"
"                    mixed acor  = (ld2 - 2.0f*rrpr - rpsqij)*avgMass / (rrpr + rij2sq);\n"
"                    mixed3 dr = rij2*acor;\n"
"                    xpi.x += dr.x*invMassCentral;\n"
"                    xpi.y += dr.y*invMassCentral;\n"
"                    xpi.z += dr.z*invMassCentral;\n"
"                    xpj2.x -= dr.x*invMassPeripheral;\n"
"                    xpj2.y -= dr.y*invMassPeripheral;\n"
"                    xpj2.z -= dr.z*invMassPeripheral;\n"
"                    converged = false;\n"
"                }\n"
"            }\n"
"            if (atoms.w != -1) {\n"
"                rpij = make_mixed3(xpi.x-xpj3.x, xpi.y-xpj3.y, xpi.z-xpj3.z);\n"
"                rpsqij = rpij.x*rpij.x + rpij.y*rpij.y + rpij.z*rpij.z;\n"
"                rrpr = rij3.x*rpij.x + rij3.y*rpij.y + rij3.z*rpij.z;\n"
"                diff = fabs(ld3 - 2.0f*rrpr - rpsqij) / (d2*tol);\n"
"                if (diff >= 1.0f) {\n"
"                    mixed acor  = (ld3-2.0f*rrpr-rpsqij)*avgMass / (rrpr+rij3sq);\n"
"                    mixed3 dr = rij3*acor;\n"
"                    xpi.x += dr.x*invMassCentral;\n"
"                    xpi.y += dr.y*invMassCentral;\n"
"                    xpi.z += dr.z*invMassCentral;\n"
"                    xpj3.x -= dr.x*invMassPeripheral;\n"
"                    xpj3.y -= dr.y*invMassPeripheral;\n"
"                    xpj3.z -= dr.z*invMassPeripheral;\n"
"                    converged = false;\n"
"                }\n"
"            }\n"
"            iteration++;\n"
"        }\n"
"\n"
"        // Record the new positions.\n"
"\n"
"        posDelta[atoms.x] = xpi;\n"
"        posDelta[atoms.y] = xpj1;\n"
"        if (atoms.z != -1)\n"
"            posDelta[atoms.z] = xpj2;\n"
"        if (atoms.w != -1)\n"
"            posDelta[atoms.w] = xpj3;\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Enforce velocity constraints on SHAKE clusters\n"
" */\n"
"extern \"C\" __global__ void applyShakeToVelocities(int numClusters, mixed tol, const real4* __restrict__ oldPos, real4* __restrict__ posCorrection, mixed4* __restrict__ posDelta, const int4* __restrict__ clusterAtoms, const float4* __restrict__ clusterParams) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    while (index < numClusters) {\n"
"        // Load the data for this cluster.\n"
"\n"
"        int4 atoms = clusterAtoms[index];\n"
"        float4 params = clusterParams[index];\n"
"        mixed4 pos = loadPos(oldPos, posCorrection, atoms.x);\n"
"        mixed4 xpi = posDelta[atoms.x];\n"
"        mixed4 pos1 = loadPos(oldPos, posCorrection, atoms.y);\n"
"        mixed4 xpj1 = posDelta[atoms.y];\n"
"        mixed4 pos2 = make_mixed4(0);\n"
"        mixed4 xpj2 = make_mixed4(0);\n"
"        float invMassCentral = params.x;\n"
"        float avgMass = params.y;\n"
"        float invMassPeripheral = params.w;\n"
"        if (atoms.z != -1) {\n"
"            pos2 = loadPos(oldPos, posCorrection, atoms.z);\n"
"            xpj2 = posDelta[atoms.z];\n"
"        }\n"
"        mixed4 pos3 = make_mixed4(0);\n"
"        mixed4 xpj3 = make_mixed4(0);\n"
"        if (atoms.w != -1) {\n"
"            pos3 = loadPos(oldPos, posCorrection, atoms.w);\n"
"            xpj3 = posDelta[atoms.w];\n"
"        }\n"
"\n"
"        // Precompute quantities.\n"
"\n"
"        mixed3 rij1 = make_mixed3(pos.x-pos1.x, pos.y-pos1.y, pos.z-pos1.z);\n"
"        mixed3 rij2 = make_mixed3(pos.x-pos2.x, pos.y-pos2.y, pos.z-pos2.z);\n"
"        mixed3 rij3 = make_mixed3(pos.x-pos3.x, pos.y-pos3.y, pos.z-pos3.z);\n"
"        mixed rij1sq = rij1.x*rij1.x + rij1.y*rij1.y + rij1.z*rij1.z;\n"
"        mixed rij2sq = rij2.x*rij2.x + rij2.y*rij2.y + rij2.z*rij2.z;\n"
"        mixed rij3sq = rij3.x*rij3.x + rij3.y*rij3.y + rij3.z*rij3.z;\n"
"\n"
"        // Iterate until convergence.\n"
"\n"
"        bool converged = false;\n"
"        int iteration = 0;\n"
"        while (iteration < 15 && !converged) {\n"
"            converged = true;\n"
"            mixed3 rpij = make_mixed3(xpi.x-xpj1.x, xpi.y-xpj1.y, xpi.z-xpj1.z);\n"
"            mixed rrpr = rpij.x*rij1.x + rpij.y*rij1.y + rpij.z*rij1.z;\n"
"            mixed delta = -2.0f*avgMass*rrpr/rij1sq;\n"
"            mixed3 dr = rij1*delta;\n"
"            xpi.x += dr.x*invMassCentral;\n"
"            xpi.y += dr.y*invMassCentral;\n"
"            xpi.z += dr.z*invMassCentral;\n"
"            xpj1.x -= dr.x*invMassPeripheral;\n"
"            xpj1.y -= dr.y*invMassPeripheral;\n"
"            xpj1.z -= dr.z*invMassPeripheral;\n"
"            if (fabs(delta) > tol)\n"
"                converged = false;\n"
"            if (atoms.z != -1) {\n"
"                rpij = make_mixed3(xpi.x-xpj2.x, xpi.y-xpj2.y, xpi.z-xpj2.z);\n"
"                rrpr = rpij.x*rij2.x + rpij.y*rij2.y + rpij.z*rij2.z;\n"
"                delta = -2.0f*avgMass*rrpr/rij2sq;\n"
"                dr = rij2*delta;\n"
"                xpi.x += dr.x*invMassCentral;\n"
"                xpi.y += dr.y*invMassCentral;\n"
"                xpi.z += dr.z*invMassCentral;\n"
"                xpj2.x -= dr.x*invMassPeripheral;\n"
"                xpj2.y -= dr.y*invMassPeripheral;\n"
"                xpj2.z -= dr.z*invMassPeripheral;\n"
"                if (fabs(delta) > tol)\n"
"                    converged = false;\n"
"            }\n"
"            if (atoms.w != -1) {\n"
"                rpij = make_mixed3(xpi.x-xpj3.x, xpi.y-xpj3.y, xpi.z-xpj3.z);\n"
"                rrpr = rpij.x*rij3.x + rpij.y*rij3.y + rpij.z*rij3.z;\n"
"                delta = -2.0f*avgMass*rrpr/rij3sq;\n"
"                dr = rij3*delta;\n"
"                xpi.x += dr.x*invMassCentral;\n"
"                xpi.y += dr.y*invMassCentral;\n"
"                xpi.z += dr.z*invMassCentral;\n"
"                xpj3.x -= dr.x*invMassPeripheral;\n"
"                xpj3.y -= dr.y*invMassPeripheral;\n"
"                xpj3.z -= dr.z*invMassPeripheral;\n"
"                if (fabs(delta) > tol)\n"
"                    converged = false;\n"
"            }\n"
"            iteration++;\n"
"        }\n"
"\n"
"        // Record the new positions.\n"
"\n"
"        posDelta[atoms.x] = xpi;\n"
"        posDelta[atoms.y] = xpj1;\n"
"        if (atoms.z != -1)\n"
"            posDelta[atoms.z] = xpj2;\n"
"        if (atoms.w != -1)\n"
"            posDelta[atoms.w] = xpj3;\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Enforce constraints on SETTLE clusters\n"
" */\n"
"extern \"C\" __global__ void applySettleToPositions(int numClusters, mixed tol, const real4* __restrict__ oldPos, real4* __restrict__ posCorrection, mixed4* __restrict__ posDelta, const mixed4* __restrict__ velm, const int4* __restrict__ clusterAtoms, const float2* __restrict__ clusterParams) {\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    while (index < numClusters) {\n"
"        // Load the data for this cluster.\n"
"\n"
"        int4 atoms = clusterAtoms[index];\n"
"        float2 params = clusterParams[index];\n"
"        mixed4 apos0 = loadPos(oldPos, posCorrection, atoms.x);\n"
"        mixed4 xp0 = posDelta[atoms.x];\n"
"        mixed4 apos1 = loadPos(oldPos, posCorrection, atoms.y);\n"
"        mixed4 xp1 = posDelta[atoms.y];\n"
"        mixed4 apos2 = loadPos(oldPos, posCorrection, atoms.z);\n"
"        mixed4 xp2 = posDelta[atoms.z];\n"
"        mixed m0 = 1/velm[atoms.x].w;\n"
"        mixed m1 = 1/velm[atoms.y].w;\n"
"        mixed m2 = 1/velm[atoms.z].w;\n"
"\n"
"        // Apply the SETTLE algorithm.\n"
"\n"
"        mixed xb0 = apos1.x-apos0.x;\n"
"        mixed yb0 = apos1.y-apos0.y;\n"
"        mixed zb0 = apos1.z-apos0.z;\n"
"        mixed xc0 = apos2.x-apos0.x;\n"
"        mixed yc0 = apos2.y-apos0.y;\n"
"        mixed zc0 = apos2.z-apos0.z;\n"
"\n"
"        mixed invTotalMass = 1/(m0+m1+m2);\n"
"        mixed xcom = (xp0.x*m0 + (xb0+xp1.x)*m1 + (xc0+xp2.x)*m2) * invTotalMass;\n"
"        mixed ycom = (xp0.y*m0 + (yb0+xp1.y)*m1 + (yc0+xp2.y)*m2) * invTotalMass;\n"
"        mixed zcom = (xp0.z*m0 + (zb0+xp1.z)*m1 + (zc0+xp2.z)*m2) * invTotalMass;\n"
"\n"
"        mixed xa1 = xp0.x - xcom;\n"
"        mixed ya1 = xp0.y - ycom;\n"
"        mixed za1 = xp0.z - zcom;\n"
"        mixed xb1 = xb0 + xp1.x - xcom;\n"
"        mixed yb1 = yb0 + xp1.y - ycom;\n"
"        mixed zb1 = zb0 + xp1.z - zcom;\n"
"        mixed xc1 = xc0 + xp2.x - xcom;\n"
"        mixed yc1 = yc0 + xp2.y - ycom;\n"
"        mixed zc1 = zc0 + xp2.z - zcom;\n"
"\n"
"        mixed xaksZd = yb0*zc0 - zb0*yc0;\n"
"        mixed yaksZd = zb0*xc0 - xb0*zc0;\n"
"        mixed zaksZd = xb0*yc0 - yb0*xc0;\n"
"        mixed xaksXd = ya1*zaksZd - za1*yaksZd;\n"
"        mixed yaksXd = za1*xaksZd - xa1*zaksZd;\n"
"        mixed zaksXd = xa1*yaksZd - ya1*xaksZd;\n"
"        mixed xaksYd = yaksZd*zaksXd - zaksZd*yaksXd;\n"
"        mixed yaksYd = zaksZd*xaksXd - xaksZd*zaksXd;\n"
"        mixed zaksYd = xaksZd*yaksXd - yaksZd*xaksXd;\n"
"\n"
"        mixed axlng = sqrt(xaksXd*xaksXd + yaksXd*yaksXd + zaksXd*zaksXd);\n"
"        mixed aylng = sqrt(xaksYd*xaksYd + yaksYd*yaksYd + zaksYd*zaksYd);\n"
"        mixed azlng = sqrt(xaksZd*xaksZd + yaksZd*yaksZd + zaksZd*zaksZd);\n"
"        mixed trns11 = xaksXd / axlng;\n"
"        mixed trns21 = yaksXd / axlng;\n"
"        mixed trns31 = zaksXd / axlng;\n"
"        mixed trns12 = xaksYd / aylng;\n"
"        mixed trns22 = yaksYd / aylng;\n"
"        mixed trns32 = zaksYd / aylng;\n"
"        mixed trns13 = xaksZd / azlng;\n"
"        mixed trns23 = yaksZd / azlng;\n"
"        mixed trns33 = zaksZd / azlng;\n"
"\n"
"        mixed xb0d = trns11*xb0 + trns21*yb0 + trns31*zb0;\n"
"        mixed yb0d = trns12*xb0 + trns22*yb0 + trns32*zb0;\n"
"        mixed xc0d = trns11*xc0 + trns21*yc0 + trns31*zc0;\n"
"        mixed yc0d = trns12*xc0 + trns22*yc0 + trns32*zc0;\n"
"        mixed za1d = trns13*xa1 + trns23*ya1 + trns33*za1;\n"
"        mixed xb1d = trns11*xb1 + trns21*yb1 + trns31*zb1;\n"
"        mixed yb1d = trns12*xb1 + trns22*yb1 + trns32*zb1;\n"
"        mixed zb1d = trns13*xb1 + trns23*yb1 + trns33*zb1;\n"
"        mixed xc1d = trns11*xc1 + trns21*yc1 + trns31*zc1;\n"
"        mixed yc1d = trns12*xc1 + trns22*yc1 + trns32*zc1;\n"
"        mixed zc1d = trns13*xc1 + trns23*yc1 + trns33*zc1;\n"
"\n"
"        //                                        --- Step2  A2' ---\n"
"\n"
"        float rc = 0.5f*params.y;\n"
"        mixed rb = sqrt(params.x*params.x-rc*rc);\n"
"        mixed ra = rb*(m1+m2)*invTotalMass;\n"
"        rb -= ra;\n"
"        mixed sinphi = za1d/ra;\n"
"        mixed cosphi = sqrt(1-sinphi*sinphi);\n"
"        mixed sinpsi = (zb1d-zc1d) / (2*rc*cosphi);\n"
"        mixed cospsi = sqrt(1-sinpsi*sinpsi);\n"
"\n"
"        mixed ya2d =   ra*cosphi;\n"
"        mixed xb2d = - rc*cospsi;\n"
"        mixed yb2d = - rb*cosphi - rc*sinpsi*sinphi;\n"
"        mixed yc2d = - rb*cosphi + rc*sinpsi*sinphi;\n"
"        mixed xb2d2 = xb2d*xb2d;\n"
"        mixed hh2 = 4.0f*xb2d2 + (yb2d-yc2d)*(yb2d-yc2d) + (zb1d-zc1d)*(zb1d-zc1d);\n"
"        mixed deltx = 2.0f*xb2d + sqrt(4.0f*xb2d2 - hh2 + params.y*params.y);\n"
"        xb2d -= deltx*0.5f;\n"
"\n"
"        //                                        --- Step3  al,be,ga ---\n"
"\n"
"        mixed alpha = (xb2d*(xb0d-xc0d) + yb0d*yb2d + yc0d*yc2d);\n"
"        mixed beta = (xb2d*(yc0d-yb0d) + xb0d*yb2d + xc0d*yc2d);\n"
"        mixed gamma = xb0d*yb1d - xb1d*yb0d + xc0d*yc1d - xc1d*yc0d;\n"
"\n"
"        mixed al2be2 = alpha*alpha + beta*beta;\n"
"        mixed sintheta = (alpha*gamma - beta*sqrt(al2be2 - gamma*gamma)) / al2be2;\n"
"\n"
"        //                                        --- Step4  A3' ---\n"
"\n"
"        mixed costheta = sqrt(1-sintheta*sintheta);\n"
"        mixed xa3d = - ya2d*sintheta;\n"
"        mixed ya3d =   ya2d*costheta;\n"
"        mixed za3d = za1d;\n"
"        mixed xb3d =   xb2d*costheta - yb2d*sintheta;\n"
"        mixed yb3d =   xb2d*sintheta + yb2d*costheta;\n"
"        mixed zb3d = zb1d;\n"
"        mixed xc3d = - xb2d*costheta - yc2d*sintheta;\n"
"        mixed yc3d = - xb2d*sintheta + yc2d*costheta;\n"
"        mixed zc3d = zc1d;\n"
"\n"
"        //                                        --- Step5  A3 ---\n"
"\n"
"        mixed xa3 = trns11*xa3d + trns12*ya3d + trns13*za3d;\n"
"        mixed ya3 = trns21*xa3d + trns22*ya3d + trns23*za3d;\n"
"        mixed za3 = trns31*xa3d + trns32*ya3d + trns33*za3d;\n"
"        mixed xb3 = trns11*xb3d + trns12*yb3d + trns13*zb3d;\n"
"        mixed yb3 = trns21*xb3d + trns22*yb3d + trns23*zb3d;\n"
"        mixed zb3 = trns31*xb3d + trns32*yb3d + trns33*zb3d;\n"
"        mixed xc3 = trns11*xc3d + trns12*yc3d + trns13*zc3d;\n"
"        mixed yc3 = trns21*xc3d + trns22*yc3d + trns23*zc3d;\n"
"        mixed zc3 = trns31*xc3d + trns32*yc3d + trns33*zc3d;\n"
"\n"
"        xp0.x = xcom + xa3;\n"
"        xp0.y = ycom + ya3;\n"
"        xp0.z = zcom + za3;\n"
"        xp1.x = xcom + xb3 - xb0;\n"
"        xp1.y = ycom + yb3 - yb0;\n"
"        xp1.z = zcom + zb3 - zb0;\n"
"        xp2.x = xcom + xc3 - xc0;\n"
"        xp2.y = ycom + yc3 - yc0;\n"
"        xp2.z = zcom + zc3 - zc0;\n"
"\n"
"        // Record the new positions.\n"
"\n"
"        posDelta[atoms.x] = xp0;\n"
"        posDelta[atoms.y] = xp1;\n"
"        posDelta[atoms.z] = xp2;\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Enforce velocity constraints on SETTLE clusters\n"
" */\n"
"extern \"C\" __global__ void applySettleToVelocities(int numClusters, mixed tol, const real4* __restrict__ oldPos, real4* __restrict__ posCorrection, mixed4* __restrict__ posDelta, mixed4* __restrict__ velm, const int4* __restrict__ clusterAtoms, const float2* __restrict__ clusterParams) {\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numClusters; index += blockDim.x*gridDim.x) {\n"
"        // Load the data for this cluster.\n"
"\n"
"        int4 atoms = clusterAtoms[index];\n"
"        mixed4 apos0 = loadPos(oldPos, posCorrection, atoms.x);\n"
"        mixed4 apos1 = loadPos(oldPos, posCorrection, atoms.y);\n"
"        mixed4 apos2 = loadPos(oldPos, posCorrection, atoms.z);\n"
"        mixed4 v0 = velm[atoms.x];\n"
"        mixed4 v1 = velm[atoms.y];\n"
"        mixed4 v2 = velm[atoms.z];\n"
"        \n"
"        // Compute intermediate quantities: the atom masses, the bond directions, the relative velocities,\n"
"        // and the angle cosines and sines.\n"
"        \n"
"        mixed mA = 1/v0.w;\n"
"        mixed mB = 1/v1.w;\n"
"        mixed mC = 1/v2.w;\n"
"        mixed3 eAB = make_mixed3(apos1.x-apos0.x, apos1.y-apos0.y, apos1.z-apos0.z);\n"
"        mixed3 eBC = make_mixed3(apos2.x-apos1.x, apos2.y-apos1.y, apos2.z-apos1.z);\n"
"        mixed3 eCA = make_mixed3(apos0.x-apos2.x, apos0.y-apos2.y, apos0.z-apos2.z);\n"
"        eAB *= RSQRT(eAB.x*eAB.x + eAB.y*eAB.y + eAB.z*eAB.z);\n"
"        eBC *= RSQRT(eBC.x*eBC.x + eBC.y*eBC.y + eBC.z*eBC.z);\n"
"        eCA *= RSQRT(eCA.x*eCA.x + eCA.y*eCA.y + eCA.z*eCA.z);\n"
"        mixed vAB = (v1.x-v0.x)*eAB.x + (v1.y-v0.y)*eAB.y + (v1.z-v0.z)*eAB.z;\n"
"        mixed vBC = (v2.x-v1.x)*eBC.x + (v2.y-v1.y)*eBC.y + (v2.z-v1.z)*eBC.z;\n"
"        mixed vCA = (v0.x-v2.x)*eCA.x + (v0.y-v2.y)*eCA.y + (v0.z-v2.z)*eCA.z;\n"
"        mixed cA = -(eAB.x*eCA.x + eAB.y*eCA.y + eAB.z*eCA.z);\n"
"        mixed cB = -(eAB.x*eBC.x + eAB.y*eBC.y + eAB.z*eBC.z);\n"
"        mixed cC = -(eBC.x*eCA.x + eBC.y*eCA.y + eBC.z*eCA.z);\n"
"        mixed s2A = 1-cA*cA;\n"
"        mixed s2B = 1-cB*cB;\n"
"        mixed s2C = 1-cC*cC;\n"
"        \n"
"        // Solve the equations.  These are different from those in the SETTLE paper (JCC 13(8), pp. 952-962, 1992), because\n"
"        // in going from equations B1 to B2, they make the assumption that mB=mC (but don't bother to mention they're\n"
"        // making that assumption).  We allow all three atoms to have different masses.\n"
"        \n"
"        mixed mABCinv = 1/(mA*mB*mC);\n"
"        mixed denom = (((s2A*mB+s2B*mA)*mC+(s2A*mB*mB+2*(cA*cB*cC+1)*mA*mB+s2B*mA*mA))*mC+s2C*mA*mB*(mA+mB))*mABCinv;\n"
"        mixed tab = ((cB*cC*mA-cA*mB-cA*mC)*vCA + (cA*cC*mB-cB*mC-cB*mA)*vBC + (s2C*mA*mA*mB*mB*mABCinv+(mA+mB+mC))*vAB)/denom;\n"
"        mixed tbc = ((cA*cB*mC-cC*mB-cC*mA)*vCA + (s2A*mB*mB*mC*mC*mABCinv+(mA+mB+mC))*vBC + (cA*cC*mB-cB*mA-cB*mC)*vAB)/denom;\n"
"        mixed tca = ((s2B*mA*mA*mC*mC*mABCinv+(mA+mB+mC))*vCA + (cA*cB*mC-cC*mB-cC*mA)*vBC + (cB*cC*mA-cA*mB-cA*mC)*vAB)/denom;\n"
"        v0.x += (tab*eAB.x - tca*eCA.x)*v0.w;\n"
"        v0.y += (tab*eAB.y - tca*eCA.y)*v0.w;\n"
"        v0.z += (tab*eAB.z - tca*eCA.z)*v0.w;\n"
"        v1.x += (tbc*eBC.x - tab*eAB.x)*v1.w;\n"
"        v1.y += (tbc*eBC.y - tab*eAB.y)*v1.w;\n"
"        v1.z += (tbc*eBC.z - tab*eAB.z)*v1.w;\n"
"        v2.x += (tca*eCA.x - tbc*eBC.x)*v2.w;\n"
"        v2.y += (tca*eCA.y - tbc*eBC.y)*v2.w;\n"
"        v2.z += (tca*eCA.z - tbc*eBC.z)*v2.w;\n"
"        velm[atoms.x] = v0;\n"
"        velm[atoms.y] = v1;\n"
"        velm[atoms.z] = v2;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Compute the direction each CCMA constraint is pointing in.  This is called once at the beginning of constraint evaluation.\n"
" */\n"
"extern \"C\" __global__ void computeCCMAConstraintDirections(const int2* __restrict__ constraintAtoms, mixed4* __restrict__ constraintDistance,\n"
"        const real4* __restrict__ atomPositions, const real4* __restrict__ posqCorrection, int* __restrict__ converged) {\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_CCMA_CONSTRAINTS; index += blockDim.x*gridDim.x) {\n"
"        // Compute the direction for this constraint.\n"
"\n"
"        int2 atoms = constraintAtoms[index];\n"
"        mixed4 dir = constraintDistance[index];\n"
"        mixed4 oldPos1 = loadPos(atomPositions, posqCorrection, atoms.x);\n"
"        mixed4 oldPos2 = loadPos(atomPositions, posqCorrection, atoms.y);\n"
"        dir.x = oldPos1.x-oldPos2.x;\n"
"        dir.y = oldPos1.y-oldPos2.y;\n"
"        dir.z = oldPos1.z-oldPos2.z;\n"
"        constraintDistance[index] = dir;\n"
"    }\n"
"    if (threadIdx.x == 0 && blockIdx.x == 0) {\n"
"        converged[0] = 1;\n"
"        converged[1] = 0;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Compute the force applied by each CCMA position constraint.\n"
" */\n"
"extern \"C\" __global__ void computeCCMAPositionConstraintForce(const int2* __restrict__ constraintAtoms, const mixed4* __restrict__ constraintDistance, const mixed4* __restrict__ atomPositions,\n"
"        const mixed* __restrict__ reducedMass, mixed* __restrict__ delta1, int* __restrict__ converged, int* __restrict__ hostConvergedFlag, mixed tol, int iteration) {\n"
"    __shared__ int groupConverged;\n"
"    if (converged[1-iteration%2]) {\n"
"        if (blockIdx.x == 0 && threadIdx.x == 0) {\n"
"            converged[iteration%2] = 1;\n"
"            hostConvergedFlag[0] = 1;\n"
"        }\n"
"        return; // The constraint iteration has already converged.\n"
"    }\n"
"    if (threadIdx.x == 0)\n"
"        groupConverged = 1;\n"
"    __syncthreads();\n"
"    mixed lowerTol = 1-2*tol+tol*tol;\n"
"    mixed upperTol = 1+2*tol+tol*tol;\n"
"    bool threadConverged = true;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_CCMA_CONSTRAINTS; index += blockDim.x*gridDim.x) {\n"
"        // Compute the force due to this constraint.\n"
"\n"
"        int2 atoms = constraintAtoms[index];\n"
"        mixed4 dir = constraintDistance[index];\n"
"        mixed4 rp_ij = atomPositions[atoms.x]-atomPositions[atoms.y];\n"
"        rp_ij.x += dir.x;\n"
"        rp_ij.y += dir.y;\n"
"        rp_ij.z += dir.z;\n"
"        mixed rrpr = rp_ij.x*dir.x + rp_ij.y*dir.y + rp_ij.z*dir.z;\n"
"        mixed d_ij2 = dir.x*dir.x + dir.y*dir.y + dir.z*dir.z;\n"
"        mixed rp2 = rp_ij.x*rp_ij.x + rp_ij.y*rp_ij.y + rp_ij.z*rp_ij.z;\n"
"        mixed dist2 = dir.w*dir.w;\n"
"        mixed diff = dist2 - rp2;\n"
"        delta1[index] = (rrpr > d_ij2*1e-6f ? reducedMass[index]*diff/rrpr : 0.0f);\n"
"        threadConverged &= (rp2 > lowerTol*dist2 && rp2 < upperTol*dist2);\n"
"    }\n"
"    if (groupConverged && !threadConverged)\n"
"        groupConverged = 0;\n"
"    __syncthreads();\n"
"    if (threadIdx.x == 0 && !groupConverged)\n"
"        converged[iteration%2] = 0;\n"
"}\n"
"\n"
"/**\n"
" * Compute the force applied by each CCMA velocity constraint.\n"
" */\n"
"extern \"C\" __global__ void computeCCMAVelocityConstraintForce(const int2* __restrict__ constraintAtoms, const mixed4* __restrict__ constraintDistance, const mixed4* __restrict__ atomPositions,\n"
"        const mixed* __restrict__ reducedMass, mixed* __restrict__ delta1, int* __restrict__ converged, int* __restrict__ hostConvergedFlag, mixed tol, int iteration) {\n"
"    __shared__ int groupConverged;\n"
"    if (converged[1-iteration%2]) {\n"
"        if (blockIdx.x == 0 && threadIdx.x == 0) {\n"
"            converged[iteration%2] = 1;\n"
"            hostConvergedFlag[0] = 1;\n"
"        }\n"
"        return; // The constraint iteration has already converged.\n"
"    }\n"
"    if (threadIdx.x == 0)\n"
"        groupConverged = 1;\n"
"    __syncthreads();\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_CCMA_CONSTRAINTS; index += blockDim.x*gridDim.x) {\n"
"        // Compute the force due to this constraint.\n"
"\n"
"        int2 atoms = constraintAtoms[index];\n"
"        mixed4 dir = constraintDistance[index];\n"
"        mixed4 rp_ij = atomPositions[atoms.x]-atomPositions[atoms.y];\n"
"        mixed rrpr = rp_ij.x*dir.x + rp_ij.y*dir.y + rp_ij.z*dir.z;\n"
"        mixed d_ij2 = dir.x*dir.x + dir.y*dir.y + dir.z*dir.z;\n"
"        delta1[index] = -2*reducedMass[index]*rrpr/d_ij2;\n"
"\n"
"        // See whether it has converged.\n"
"\n"
"        if (groupConverged && fabs(delta1[index]) > tol) {\n"
"            groupConverged = 0;\n"
"            converged[iteration%2] = 0;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Multiply the vector of CCMA constraint forces by the constraint matrix.\n"
" */\n"
"extern \"C\" __global__ void multiplyByCCMAConstraintMatrix(const mixed* __restrict__ delta1, mixed* __restrict__ delta2, const int* __restrict__ constraintMatrixColumn,\n"
"        const mixed* __restrict__ constraintMatrixValue, const int* __restrict__ converged, int iteration) {\n"
"    if (converged[iteration%2])\n"
"        return; // The constraint iteration has already converged.\n"
"\n"
"    // Multiply by the inverse constraint matrix.\n"
"\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_CCMA_CONSTRAINTS; index += blockDim.x*gridDim.x) {\n"
"        mixed sum = 0;\n"
"        for (int i = 0; ; i++) {\n"
"            int element = index+i*NUM_CCMA_CONSTRAINTS;\n"
"            int column = constraintMatrixColumn[element];\n"
"            if (column >= NUM_CCMA_CONSTRAINTS)\n"
"                break;\n"
"            sum += delta1[column]*constraintMatrixValue[element];\n"
"        }\n"
"        delta2[index] = sum;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Update the atom positions based on CCMA constraint forces.\n"
" */\n"
"extern \"C\" __global__ void updateCCMAAtomPositions(const int* __restrict__ numAtomConstraints, const int* __restrict__ atomConstraints, const mixed4* __restrict__ constraintDistance,\n"
"        mixed4* __restrict__ atomPositions, const mixed4* __restrict__ velm, const mixed* __restrict__ delta1, const mixed* __restrict__ delta2, int* __restrict__ converged, int iteration) {\n"
"    if (blockIdx.x == 0 && threadIdx.x == 0)\n"
"        converged[1-iteration%2] = 1;\n"
"    if (converged[iteration%2])\n"
"        return; // The constraint iteration has already converged.\n"
"    mixed damping = (iteration < 2 ? 0.5f : 1.0f);\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        // Compute the new position of this atom.\n"
"\n"
"        mixed4 atomPos = atomPositions[index];\n"
"        mixed invMass = velm[index].w;\n"
"        int num = numAtomConstraints[index];\n"
"        for (int i = 0; i < num; i++) {\n"
"            int constraint = atomConstraints[index+i*NUM_ATOMS];\n"
"            bool forward = (constraint > 0);\n"
"            constraint = (forward ? constraint-1 : -constraint-1);\n"
"            mixed constraintForce = damping*invMass*delta2[constraint];\n"
"            constraintForce = (forward ? constraintForce : -constraintForce);\n"
"            mixed4 dir = constraintDistance[constraint];\n"
"            atomPos.x += constraintForce*dir.x;\n"
"            atomPos.y += constraintForce*dir.y;\n"
"            atomPos.z += constraintForce*dir.z;\n"
"        }\n"
"        atomPositions[index] = atomPos;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Compute the positions of virtual sites\n"
" */\n"
"extern \"C\" __global__ void computeVirtualSites(real4* __restrict__ posq, real4* __restrict__ posqCorrection, const int4* __restrict__ avg2Atoms, const real2* __restrict__ avg2Weights,\n"
"        const int4* __restrict__ avg3Atoms, const real4* __restrict__ avg3Weights,\n"
"        const int4* __restrict__ outOfPlaneAtoms, const real4* __restrict__ outOfPlaneWeights,\n"
"        const int* __restrict__ localCoordsIndex, const int* __restrict__ localCoordsAtoms,\n"
"        const real* __restrict__ localCoordsWeights, const real4* __restrict__ localCoordsPos,\n"
"        const int* __restrict__ localCoordsStartIndex) {\n"
"    \n"
"    // Two particle average sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_2_AVERAGE; index += blockDim.x*gridDim.x) {\n"
"        int4 atoms = avg2Atoms[index];\n"
"        real2 weights = avg2Weights[index];\n"
"        mixed4 pos = loadPos(posq, posqCorrection, atoms.x);\n"
"        mixed4 pos1 = loadPos(posq, posqCorrection, atoms.y);\n"
"        mixed4 pos2 = loadPos(posq, posqCorrection, atoms.z);\n"
"        pos.x = pos1.x*weights.x + pos2.x*weights.y;\n"
"        pos.y = pos1.y*weights.x + pos2.y*weights.y;\n"
"        pos.z = pos1.z*weights.x + pos2.z*weights.y;\n"
"        storePos(posq, posqCorrection, atoms.x, pos);\n"
"    }\n"
"    \n"
"    // Three particle average sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_3_AVERAGE; index += blockDim.x*gridDim.x) {\n"
"        int4 atoms = avg3Atoms[index];\n"
"        real4 weights = avg3Weights[index];\n"
"        mixed4 pos = loadPos(posq, posqCorrection, atoms.x);\n"
"        mixed4 pos1 = loadPos(posq, posqCorrection, atoms.y);\n"
"        mixed4 pos2 = loadPos(posq, posqCorrection, atoms.z);\n"
"        mixed4 pos3 = loadPos(posq, posqCorrection, atoms.w);\n"
"        pos.x = pos1.x*weights.x + pos2.x*weights.y + pos3.x*weights.z;\n"
"        pos.y = pos1.y*weights.x + pos2.y*weights.y + pos3.y*weights.z;\n"
"        pos.z = pos1.z*weights.x + pos2.z*weights.y + pos3.z*weights.z;\n"
"        storePos(posq, posqCorrection, atoms.x, pos);\n"
"    }\n"
"    \n"
"    // Out of plane sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_OUT_OF_PLANE; index += blockDim.x*gridDim.x) {\n"
"        int4 atoms = outOfPlaneAtoms[index];\n"
"        real4 weights = outOfPlaneWeights[index];\n"
"        mixed4 pos = loadPos(posq, posqCorrection, atoms.x);\n"
"        mixed4 pos1 = loadPos(posq, posqCorrection, atoms.y);\n"
"        mixed4 pos2 = loadPos(posq, posqCorrection, atoms.z);\n"
"        mixed4 pos3 = loadPos(posq, posqCorrection, atoms.w);\n"
"        mixed4 v12 = pos2-pos1;\n"
"        mixed4 v13 = pos3-pos1;\n"
"        mixed3 cr = cross(v12, v13);\n"
"        pos.x = pos1.x + v12.x*weights.x + v13.x*weights.y + cr.x*weights.z;\n"
"        pos.y = pos1.y + v12.y*weights.x + v13.y*weights.y + cr.y*weights.z;\n"
"        pos.z = pos1.z + v12.z*weights.x + v13.z*weights.y + cr.z*weights.z;\n"
"        storePos(posq, posqCorrection, atoms.x, pos);\n"
"    }\n"
"    \n"
"    // Local coordinates sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_LOCAL_COORDS; index += blockDim.x*gridDim.x) {\n"
"        int siteAtomIndex = localCoordsIndex[index];\n"
"        int start = localCoordsStartIndex[index];\n"
"        int end = localCoordsStartIndex[index+1];\n"
"        mixed3 origin = make_mixed3(0), xdir = make_mixed3(0), ydir = make_mixed3(0);\n"
"        for (int j = start; j < end; j++) {\n"
"            mixed3 pos = trimTo3(loadPos(posq, posqCorrection, localCoordsAtoms[j]));\n"
"            origin += pos*localCoordsWeights[3*j];\n"
"            xdir += pos*localCoordsWeights[3*j+1];\n"
"            ydir += pos*localCoordsWeights[3*j+2];\n"
"        }\n"
"        mixed3 zdir = cross(xdir, ydir);\n"
"        mixed normXdir = sqrt(xdir.x*xdir.x+xdir.y*xdir.y+xdir.z*xdir.z);\n"
"        mixed normZdir = sqrt(zdir.x*zdir.x+zdir.y*zdir.y+zdir.z*zdir.z);\n"
"        mixed invNormXdir = (normXdir > 0 ? 1/normXdir : 0);\n"
"        mixed invNormZdir = (normZdir > 0 ? 1/normZdir : 0);\n"
"        xdir *= invNormXdir;\n"
"        zdir *= invNormZdir;\n"
"        ydir = cross(zdir, xdir);\n"
"        real4 localPosition_4 = localCoordsPos[index];\n"
"        mixed3 localPosition = make_mixed3(localPosition_4.x, localPosition_4.y, localPosition_4.z);\n"
"        mixed4 pos = loadPos(posq, posqCorrection, siteAtomIndex);\n"
"        pos.x = origin.x + xdir.x*localPosition.x + ydir.x*localPosition.y + zdir.x*localPosition.z;\n"
"        pos.y = origin.y + xdir.y*localPosition.x + ydir.y*localPosition.y + zdir.y*localPosition.z;\n"
"        pos.z = origin.z + xdir.z*localPosition.x + ydir.z*localPosition.y + zdir.z*localPosition.z;\n"
"        storePos(posq, posqCorrection, siteAtomIndex, pos);\n"
"    }\n"
"}\n"
"\n"
"inline __device__ real3 loadForce(int index, long long* __restrict__ force) {\n"
"    real scale = 1/((real) 0x100000000);\n"
"    return make_real3(scale*force[index], scale*force[index+PADDED_NUM_ATOMS], scale*force[index+PADDED_NUM_ATOMS*2]);\n"
"}\n"
"\n"
"inline __device__ void addForce(int index, long long* __restrict__ force, real3 value) {\n"
"    unsigned long long* f = (unsigned long long*) force;\n"
"    atomicAdd(&f[index], static_cast<unsigned long long>((long long) (value.x*0x100000000)));\n"
"    atomicAdd(&f[index+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (value.y*0x100000000)));\n"
"    atomicAdd(&f[index+PADDED_NUM_ATOMS*2], static_cast<unsigned long long>((long long) (value.z*0x100000000)));\n"
"}\n"
"\n"
"/**\n"
" * Distribute forces from virtual sites to the atoms they are based on.\n"
" */\n"
"extern \"C\" __global__ void distributeVirtualSiteForces(const real4* __restrict__ posq, const real4* __restrict__ posqCorrection, long long* __restrict__ force,\n"
"        const int4* __restrict__ avg2Atoms, const real2* __restrict__ avg2Weights,\n"
"        const int4* __restrict__ avg3Atoms, const real4* __restrict__ avg3Weights,\n"
"        const int4* __restrict__ outOfPlaneAtoms, const real4* __restrict__ outOfPlaneWeights,\n"
"        const int* __restrict__ localCoordsIndex, const int* __restrict__ localCoordsAtoms,\n"
"        const real* __restrict__ localCoordsWeights, const real4* __restrict__ localCoordsPos,\n"
"        const int* __restrict__ localCoordsStartIndex) {\n"
"    \n"
"    // Two particle average sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_2_AVERAGE; index += blockDim.x*gridDim.x) {\n"
"        int4 atoms = avg2Atoms[index];\n"
"        real2 weights = avg2Weights[index];\n"
"        real3 f = loadForce(atoms.x, force);\n"
"        addForce(atoms.y, force, f*weights.x);\n"
"        addForce(atoms.z, force, f*weights.y);\n"
"    }\n"
"    \n"
"    // Three particle average sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_3_AVERAGE; index += blockDim.x*gridDim.x) {\n"
"        int4 atoms = avg3Atoms[index];\n"
"        real4 weights = avg3Weights[index];\n"
"        real3 f = loadForce(atoms.x, force);\n"
"        addForce(atoms.y, force, f*weights.x);\n"
"        addForce(atoms.z, force, f*weights.y);\n"
"        addForce(atoms.w, force, f*weights.z);\n"
"    }\n"
"    \n"
"    // Out of plane sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_OUT_OF_PLANE; index += blockDim.x*gridDim.x) {\n"
"        int4 atoms = outOfPlaneAtoms[index];\n"
"        real4 weights = outOfPlaneWeights[index];\n"
"        mixed4 pos1 = loadPos(posq, posqCorrection, atoms.y);\n"
"        mixed4 pos2 = loadPos(posq, posqCorrection, atoms.z);\n"
"        mixed4 pos3 = loadPos(posq, posqCorrection, atoms.w);\n"
"        mixed4 v12 = pos2-pos1;\n"
"        mixed4 v13 = pos3-pos1;\n"
"        real3 f = loadForce(atoms.x, force);\n"
"        real3 fp2 = make_real3((real) (weights.x*f.x - weights.z*v13.z*f.y + weights.z*v13.y*f.z),\n"
"                   (real) (weights.z*v13.z*f.x + weights.x*f.y - weights.z*v13.x*f.z),\n"
"                   (real) (-weights.z*v13.y*f.x + weights.z*v13.x*f.y + weights.x*f.z));\n"
"        real3 fp3 = make_real3((real) (weights.y*f.x + weights.z*v12.z*f.y - weights.z*v12.y*f.z),\n"
"                   (real) (-weights.z*v12.z*f.x + weights.y*f.y + weights.z*v12.x*f.z),\n"
"                   (real) (weights.z*v12.y*f.x - weights.z*v12.x*f.y + weights.y*f.z));\n"
"        addForce(atoms.y, force, f-fp2-fp3);\n"
"        addForce(atoms.z, force, fp2);\n"
"        addForce(atoms.w, force, fp3);\n"
"    }\n"
"    \n"
"    // Local coordinates sites.\n"
"    \n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_LOCAL_COORDS; index += blockDim.x*gridDim.x) {\n"
"        int siteAtomIndex = localCoordsIndex[index];\n"
"        int start = localCoordsStartIndex[index];\n"
"        int end = localCoordsStartIndex[index+1];\n"
"        mixed3 origin = make_mixed3(0), xdir = make_mixed3(0), ydir = make_mixed3(0);\n"
"        for (int j = start; j < end; j++) {\n"
"            mixed3 pos = trimTo3(loadPos(posq, posqCorrection, localCoordsAtoms[j]));\n"
"            origin += pos*localCoordsWeights[3*j];\n"
"            xdir += pos*localCoordsWeights[3*j+1];\n"
"            ydir += pos*localCoordsWeights[3*j+2];\n"
"        }\n"
"        mixed3 zdir = cross(xdir, ydir);\n"
"        mixed normXdir = sqrt(xdir.x*xdir.x+xdir.y*xdir.y+xdir.z*xdir.z);\n"
"        mixed normZdir = sqrt(zdir.x*zdir.x+zdir.y*zdir.y+zdir.z*zdir.z);\n"
"        mixed invNormXdir = (normXdir > 0 ? 1/normXdir : 0);\n"
"        mixed invNormZdir = (normZdir > 0 ? 1/normZdir : 0);\n"
"        mixed3 dx = xdir*invNormXdir;\n"
"        mixed3 dz = zdir*invNormZdir;\n"
"        mixed3 dy = cross(dz, dx);\n"
"        real4 localPosition_4 = localCoordsPos[index];\n"
"        mixed3 localPosition = make_mixed3(localPosition_4.x, localPosition_4.y, localPosition_4.z);\n"
"\n"
"        // The derivatives for this case are very complicated.  They were computed with SymPy then simplified by hand.\n"
"\n"
"        real3 f = loadForce(siteAtomIndex, force);\n"
"        mixed3 fp1 = localPosition*f.x;\n"
"        mixed3 fp2 = localPosition*f.y;\n"
"        mixed3 fp3 = localPosition*f.z;\n"
"        for (int j = start; j < end; j++) {\n"
"            real originWeight = localCoordsWeights[3*j];\n"
"            real wx = localCoordsWeights[3*j+1];\n"
"            real wy = localCoordsWeights[3*j+2];\n"
"            mixed wxScaled = wx*invNormXdir;\n"
"            mixed t1 = (wx*ydir.x-wy*xdir.x)*invNormZdir;\n"
"            mixed t2 = (wx*ydir.y-wy*xdir.y)*invNormZdir;\n"
"            mixed t3 = (wx*ydir.z-wy*xdir.z)*invNormZdir;\n"
"            mixed sx = t3*dz.y-t2*dz.z;\n"
"            mixed sy = t1*dz.z-t3*dz.x;\n"
"            mixed sz = t2*dz.x-t1*dz.y;\n"
"            real3 fresult = make_real3(0);\n"
"            fresult.x += fp1.x*wxScaled*(1-dx.x*dx.x) + fp1.z*(dz.x*sx   ) + fp1.y*((-dx.x*dy.x     )*wxScaled + dy.x*sx - dx.y*t2 - dx.z*t3) + f.x*originWeight;\n"
"            fresult.y += fp1.x*wxScaled*( -dx.x*dx.y) + fp1.z*(dz.x*sy+t3) + fp1.y*((-dx.y*dy.x-dz.z)*wxScaled + dy.x*sy + dx.y*t1);\n"
"            fresult.z += fp1.x*wxScaled*( -dx.x*dx.z) + fp1.z*(dz.x*sz-t2) + fp1.y*((-dx.z*dy.x+dz.y)*wxScaled + dy.x*sz + dx.z*t1);\n"
"            fresult.x += fp2.x*wxScaled*( -dx.y*dx.x) + fp2.z*(dz.y*sx-t3) - fp2.y*(( dx.x*dy.y-dz.z)*wxScaled - dy.y*sx - dx.x*t2);\n"
"            fresult.y += fp2.x*wxScaled*(1-dx.y*dx.y) + fp2.z*(dz.y*sy   ) - fp2.y*(( dx.y*dy.y     )*wxScaled - dy.y*sy + dx.x*t1 + dx.z*t3) + f.y*originWeight;\n"
"            fresult.z += fp2.x*wxScaled*( -dx.y*dx.z) + fp2.z*(dz.y*sz+t1) - fp2.y*(( dx.z*dy.y+dz.x)*wxScaled - dy.y*sz - dx.z*t2);\n"
"            fresult.x += fp3.x*wxScaled*( -dx.z*dx.x) + fp3.z*(dz.z*sx+t2) + fp3.y*((-dx.x*dy.z-dz.y)*wxScaled + dy.z*sx + dx.x*t3);\n"
"            fresult.y += fp3.x*wxScaled*( -dx.z*dx.y) + fp3.z*(dz.z*sy-t1) + fp3.y*((-dx.y*dy.z+dz.x)*wxScaled + dy.z*sy + dx.y*t3);\n"
"            fresult.z += fp3.x*wxScaled*(1-dx.z*dx.z) + fp3.z*(dz.z*sz   ) + fp3.y*((-dx.z*dy.z     )*wxScaled + dy.z*sz - dx.x*t1 - dx.y*t2) + f.z*originWeight;\n"
"            addForce(localCoordsAtoms[j], force, fresult);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Apply a time shift to the velocities before computing kinetic energy.\n"
" */\n"
"extern \"C\" __global__ void timeShiftVelocities(mixed4* __restrict__ velm, const long long* __restrict__ force, real timeShift) {\n"
"    const mixed scale = timeShift/(mixed) 0x100000000;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < NUM_ATOMS; index += blockDim.x*gridDim.x) {\n"
"        mixed4 velocity = velm[index];\n"
"        if (velocity.w != 0.0) {\n"
"            velocity.x += scale*force[index]*velocity.w;\n"
"            velocity.y += scale*force[index+PADDED_NUM_ATOMS]*velocity.w;\n"
"            velocity.z += scale*force[index+PADDED_NUM_ATOMS*2]*velocity.w;\n"
"            velm[index] = velocity;\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::langevin = "enum {VelScale, ForceScale, NoiseScale, MaxParams};\n"
"\n"
"/**\n"
" * Perform the first step of Langevin integration.\n"
" */\n"
"\n"
"extern \"C\" __global__ void integrateLangevinPart1(int numAtoms, int paddedNumAtoms, mixed4* __restrict__ velm, const long long* __restrict__ force, mixed4* __restrict__ posDelta,\n"
"        const mixed* __restrict__ paramBuffer, const mixed2* __restrict__ dt, const float4* __restrict__ random, unsigned int randomIndex) {\n"
"    mixed vscale = paramBuffer[VelScale];\n"
"    mixed fscale = paramBuffer[ForceScale]/(mixed) 0x100000000;\n"
"    mixed noisescale = paramBuffer[NoiseScale];\n"
"    mixed stepSize = dt[0].y;\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    randomIndex += index;\n"
"    while (index < numAtoms) {\n"
"        mixed4 velocity = velm[index];\n"
"        if (velocity.w != 0) {\n"
"            mixed sqrtInvMass = SQRT(velocity.w);\n"
"            velocity.x = vscale*velocity.x + fscale*velocity.w*force[index] + noisescale*sqrtInvMass*random[randomIndex].x;\n"
"            velocity.y = vscale*velocity.y + fscale*velocity.w*force[index+paddedNumAtoms] + noisescale*sqrtInvMass*random[randomIndex].y;\n"
"            velocity.z = vscale*velocity.z + fscale*velocity.w*force[index+paddedNumAtoms*2] + noisescale*sqrtInvMass*random[randomIndex].z;\n"
"            velm[index] = velocity;\n"
"            posDelta[index] = make_mixed4(stepSize*velocity.x, stepSize*velocity.y, stepSize*velocity.z, 0);\n"
"        }\n"
"        randomIndex += blockDim.x*gridDim.x;\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Perform the second step of Langevin integration.\n"
" */\n"
"\n"
"extern \"C\" __global__ void integrateLangevinPart2(int numAtoms, real4* __restrict__ posq, real4* __restrict__ posqCorrection, const mixed4* __restrict__ posDelta, mixed4* __restrict__ velm, const mixed2* __restrict__ dt) {\n"
"#if __CUDA_ARCH__ >= 130\n"
"    double invStepSize = 1.0/dt[0].y;\n"
"#else\n"
"    float invStepSize = 1.0f/dt[0].y;\n"
"    float correction = (1.0f-invStepSize*dt[0].y)/dt[0].y;\n"
"#endif\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    while (index < numAtoms) {\n"
"        mixed4 vel = velm[index];\n"
"        if (vel.w != 0) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"            real4 pos1 = posq[index];\n"
"            real4 pos2 = posqCorrection[index];\n"
"            mixed4 pos = make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"            real4 pos = posq[index];\n"
"#endif\n"
"            mixed4 delta = posDelta[index];\n"
"            pos.x += delta.x;\n"
"            pos.y += delta.y;\n"
"            pos.z += delta.z;\n"
"#if __CUDA_ARCH__ >= 130\n"
"            vel.x = (mixed) (invStepSize*delta.x);\n"
"            vel.y = (mixed) (invStepSize*delta.y);\n"
"            vel.z = (mixed) (invStepSize*delta.z);\n"
"#else\n"
"            vel.x = invStepSize*delta.x + correction*delta.x;\n"
"            vel.y = invStepSize*delta.y + correction*delta.x;\n"
"            vel.z = invStepSize*delta.z + correction*delta.x;\n"
"#endif\n"
"#ifdef USE_MIXED_PRECISION\n"
"            posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"            posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"            posq[index] = pos;\n"
"#endif\n"
"            velm[index] = vel;\n"
"        }\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Select the step size to use for the next step.\n"
" */\n"
"\n"
"extern \"C\" __global__ void selectLangevinStepSize(int numAtoms, int paddedNumAtoms, mixed maxStepSize, mixed errorTol, mixed friction, mixed kT, mixed2* __restrict__ dt,\n"
"        const mixed4* __restrict__ velm, const long long* __restrict__ force, mixed* __restrict__ paramBuffer) {\n"
"    // Calculate the error.\n"
"\n"
"    extern __shared__ mixed params[];\n"
"    mixed* error = &params[MaxParams];\n"
"    mixed err = 0;\n"
"    unsigned int index = threadIdx.x;\n"
"    const mixed scale = RECIP((mixed) 0x100000000);\n"
"    while (index < numAtoms) {\n"
"        mixed3 f = make_mixed3(scale*force[index], scale*force[index+paddedNumAtoms], scale*force[index+paddedNumAtoms*2]);\n"
"        mixed invMass = velm[index].w;\n"
"        err += (f.x*f.x + f.y*f.y + f.z*f.z)*invMass*invMass;\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"    error[threadIdx.x] = err;\n"
"    __syncthreads();\n"
"\n"
"    // Sum the errors from all threads.\n"
"\n"
"    for (unsigned int offset = 1; offset < blockDim.x; offset *= 2) {\n"
"        if (threadIdx.x+offset < blockDim.x && (threadIdx.x&(2*offset-1)) == 0)\n"
"            error[threadIdx.x] += error[threadIdx.x+offset];\n"
"        __syncthreads();\n"
"    }\n"
"    if (blockIdx.x*blockDim.x+threadIdx.x == 0) {\n"
"        // Select the new step size.\n"
"\n"
"        mixed totalError = SQRT(error[0]/(numAtoms*3));\n"
"        mixed newStepSize = SQRT(errorTol/totalError);\n"
"        mixed oldStepSize = dt[0].y;\n"
"        if (oldStepSize > 0.0f)\n"
"            newStepSize = min(newStepSize, oldStepSize*2.0f); // For safety, limit how quickly dt can increase.\n"
"        if (newStepSize > oldStepSize && newStepSize < 1.1f*oldStepSize)\n"
"            newStepSize = oldStepSize; // Keeping dt constant between steps improves the behavior of the integrator.\n"
"        if (newStepSize > maxStepSize)\n"
"            newStepSize = maxStepSize;\n"
"        dt[0].y = newStepSize;\n"
"\n"
"        // Recalculate the integration parameters.\n"
"\n"
"        mixed vscale = exp(-newStepSize*friction);\n"
"        mixed fscale = (friction == 0 ? newStepSize : (1-vscale)/friction);\n"
"        mixed noisescale = sqrt(kT*(1-vscale*vscale));\n"
"        params[VelScale] = vscale;\n"
"        params[ForceScale] = fscale;\n"
"        params[NoiseScale] = noisescale;\n"
"    }\n"
"    __syncthreads();\n"
"    if (threadIdx.x < MaxParams)\n"
"        paramBuffer[threadIdx.x] = params[threadIdx.x];\n"
"}\n"
"";
const string CudaKernelSources::monteCarloBarostat = "/**\n"
" * Scale the particle positions with each axis independent\n"
" */\n"
"\n"
"extern \"C\" __global__ void scalePositions(float scaleX, float scaleY, float scaleZ, int numMolecules, real4 periodicBoxSize,\n"
"        real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ, real4* __restrict__ posq,\n"
"        const int* __restrict__ moleculeAtoms, const int* __restrict__ moleculeStartIndex) {\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numMolecules; index += blockDim.x*gridDim.x) {\n"
"        int first = moleculeStartIndex[index];\n"
"        int last = moleculeStartIndex[index+1];\n"
"        int numAtoms = last-first;\n"
"\n"
"        // Find the center of each molecule.\n"
"\n"
"        real3 center = make_real3(0, 0, 0);\n"
"        for (int atom = first; atom < last; atom++) {\n"
"            real4 pos = posq[moleculeAtoms[atom]];\n"
"            center.x += pos.x;\n"
"            center.y += pos.y;\n"
"            center.z += pos.z;\n"
"        }\n"
"        real invNumAtoms = RECIP(numAtoms);\n"
"        center.x *= invNumAtoms;\n"
"        center.y *= invNumAtoms;\n"
"        center.z *= invNumAtoms;\n"
"\n"
"        // Move it into the first periodic box.\n"
"\n"
"        real3 oldCenter = center;\n"
"        APPLY_PERIODIC_TO_POS(center)\n"
"        real3 delta = make_real3(oldCenter.x-center.x, oldCenter.y-center.y, oldCenter.z-center.z);\n"
"\n"
"        // Now scale the position of the molecule center.\n"
"\n"
"        delta.x = center.x*(scaleX-1)-delta.x;\n"
"        delta.y = center.y*(scaleY-1)-delta.y;\n"
"        delta.z = center.z*(scaleZ-1)-delta.z;\n"
"        for (int atom = first; atom < last; atom++) {\n"
"            real4 pos = posq[moleculeAtoms[atom]];\n"
"            pos.x += delta.x;\n"
"            pos.y += delta.y;\n"
"            pos.z += delta.z;\n"
"            posq[moleculeAtoms[atom]] = pos;\n"
"        }\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::nonbonded = "#define WARPS_PER_GROUP (THREAD_BLOCK_SIZE/TILE_SIZE)\n"
"\n"
"#ifndef ENABLE_SHUFFLE\n"
"typedef struct {\n"
"    real x, y, z;\n"
"    real q;\n"
"    real fx, fy, fz;\n"
"    ATOM_PARAMETER_DATA\n"
"#ifndef PARAMETER_SIZE_IS_EVEN\n"
"    real padding;\n"
"#endif\n"
"} AtomData;\n"
"#endif\n"
"\n"
"#ifdef ENABLE_SHUFFLE\n"
"//support for 64 bit shuffles\n"
"static __inline__ __device__ float real_shfl(float var, int srcLane) {\n"
"    return SHFL(var, srcLane);\n"
"}\n"
"\n"
"static __inline__ __device__ double real_shfl(double var, int srcLane) {\n"
"    int hi, lo;\n"
"    asm volatile(\"mov.b64 { %0, %1 }, %2;\" : \"=r\"(lo), \"=r\"(hi) : \"d\"(var));\n"
"    hi = SHFL(hi, srcLane);\n"
"    lo = SHFL(lo, srcLane);\n"
"    return __hiloint2double( hi, lo );\n"
"}\n"
"\n"
"static __inline__ __device__ long long real_shfl(long long var, int srcLane) {\n"
"    int hi, lo;\n"
"    asm volatile(\"mov.b64 { %0, %1 }, %2;\" : \"=r\"(lo), \"=r\"(hi) : \"l\"(var));\n"
"    hi = SHFL(hi, srcLane);\n"
"    lo = SHFL(lo, srcLane);\n"
"    // unforunately there isn't an __nv_hiloint2long(hi,lo) intrinsic cast\n"
"    int2 fuse; fuse.x = lo; fuse.y = hi;\n"
"    return *reinterpret_cast<long long*>(&fuse);\n"
"}\n"
"#endif\n"
"\n"
"/**\n"
" * Compute nonbonded interactions. The kernel is separated into two parts,\n"
" * tiles with exclusions and tiles without exclusions. It relies heavily on \n"
" * implicit warp-level synchronization. A tile is defined by two atom blocks \n"
" * each of warpsize. Each warp computes a range of tiles.\n"
" * \n"
" * Tiles with exclusions compute the entire set of interactions across\n"
" * atom blocks, equal to warpsize*warpsize. In order to avoid access conflicts \n"
" * the forces are computed and accumulated diagonally in the manner shown below\n"
" * where, suppose\n"
" *\n"
" * [a-h] comprise atom block 1, [i-p] comprise atom block 2\n"
" *\n"
" * 1 denotes the first set of calculations within the warp\n"
" * 2 denotes the second set of calculations within the warp\n"
" * ... etc.\n"
" * \n"
" *        threads\n"
" *     0 1 2 3 4 5 6 7\n"
" *         atom1 \n"
" * L    a b c d e f g h \n"
" * o  i 1 2 3 4 5 6 7 8\n"
" * c  j 8 1 2 3 4 5 6 7\n"
" * a  k 7 8 1 2 3 4 5 6\n"
" * l  l 6 7 8 1 2 3 4 5\n"
" * D  m 5 6 7 8 1 2 3 4 \n"
" * a  n 4 5 6 7 8 1 2 3\n"
" * t  o 3 4 5 6 7 8 1 2\n"
" * a  p 2 3 4 5 6 7 8 1\n"
" *\n"
" * Tiles without exclusions read off directly from the neighbourlist interactingAtoms\n"
" * and follows the same force accumulation method. If more there are more interactingTiles\n"
" * than the size of the neighbourlist initially allocated, the neighbourlist is rebuilt\n"
" * and the full tileset is computed. This should happen on the first step, and very rarely \n"
" * afterwards.\n"
" *\n"
" * On CUDA devices that support the shuffle intrinsic, on diagonal exclusion tiles use\n"
" * __shfl to broadcast. For all other types of tiles __shfl is used to pass around the \n"
" * forces, positions, and parameters when computing the forces. \n"
" *\n"
" * [out]forceBuffers    - forces on each atom to eventually be accumulated\n"
" * [out]energyBuffer    - energyBuffer to eventually be accumulated\n"
" * [in]posq             - x,y,z,charge \n"
" * [in]exclusions       - 1024-bit flags denoting atom-atom exclusions for each tile\n"
" * [in]exclusionTiles   - x,y denotes the indices of tiles that have an exclusion\n"
" * [in]startTileIndex   - index into first tile to be processed\n"
" * [in]numTileIndices   - number of tiles this context is responsible for processing\n"
" * [in]int tiles        - the atom block for each tile\n"
" * [in]interactionCount - total number of tiles that have an interaction\n"
" * [in]maxTiles         - stores the size of the neighbourlist in case it needs \n"
" *                      - to be expanded\n"
" * [in]periodicBoxSize  - size of the Periodic Box, last dimension (w) not used\n"
" * [in]invPeriodicBox   - inverse of the periodicBoxSize, pre-computed for speed\n"
" * [in]blockCenter      - the center of each block in euclidean coordinates\n"
" * [in]blockSize        - size of the each block, radiating from the center\n"
" *                      - x is half the distance of total length\n"
" *                      - y is half the distance of total width\n"
" *                      - z is half the distance of total height\n"
" *                      - w is not used\n"
" * [in]interactingAtoms - a list of interactions within a given tile     \n"
" *\n"
" */\n"
"extern \"C\" __global__ void computeNonbonded(\n"
"        unsigned long long* __restrict__ forceBuffers, mixed* __restrict__ energyBuffer, const real4* __restrict__ posq, const tileflags* __restrict__ exclusions,\n"
"        const ushort2* __restrict__ exclusionTiles, unsigned int startTileIndex, unsigned int numTileIndices\n"
"#ifdef USE_CUTOFF\n"
"        , const int* __restrict__ tiles, const unsigned int* __restrict__ interactionCount, real4 periodicBoxSize, real4 invPeriodicBoxSize, \n"
"        real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ, unsigned int maxTiles, const real4* __restrict__ blockCenter,\n"
"        const real4* __restrict__ blockSize, const unsigned int* __restrict__ interactingAtoms, unsigned int maxSinglePairs,\n"
"        const int2* __restrict__ singlePairs\n"
"#endif\n"
"        PARAMETER_ARGUMENTS) {\n"
"    const unsigned int totalWarps = (blockDim.x*gridDim.x)/TILE_SIZE;\n"
"    const unsigned int warp = (blockIdx.x*blockDim.x+threadIdx.x)/TILE_SIZE; // global warpIndex\n"
"    const unsigned int tgx = threadIdx.x & (TILE_SIZE-1); // index within the warp\n"
"    const unsigned int tbx = threadIdx.x - tgx;           // block warpIndex\n"
"    mixed energy = 0;\n"
"    INIT_DERIVATIVES\n"
"    // used shared memory if the device cannot shuffle\n"
"#ifndef ENABLE_SHUFFLE\n"
"    __shared__ AtomData localData[THREAD_BLOCK_SIZE];\n"
"#endif\n"
"\n"
"    // First loop: process tiles that contain exclusions.\n"
"\n"
"    const unsigned int firstExclusionTile = FIRST_EXCLUSION_TILE+warp*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    const unsigned int lastExclusionTile = FIRST_EXCLUSION_TILE+(warp+1)*(LAST_EXCLUSION_TILE-FIRST_EXCLUSION_TILE)/totalWarps;\n"
"    for (int pos = firstExclusionTile; pos < lastExclusionTile; pos++) {\n"
"        const ushort2 tileIndices = exclusionTiles[pos];\n"
"        const unsigned int x = tileIndices.x;\n"
"        const unsigned int y = tileIndices.y;\n"
"        real3 force = make_real3(0);\n"
"        unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"        real4 posq1 = posq[atom1];\n"
"        LOAD_ATOM1_PARAMETERS\n"
"#ifdef USE_EXCLUSIONS\n"
"        tileflags excl = exclusions[pos*TILE_SIZE+tgx];\n"
"#endif\n"
"        const bool hasExclusions = true;\n"
"        if (x == y) {\n"
"            // This tile is on the diagonal.\n"
"#ifdef ENABLE_SHUFFLE\n"
"            real4 shflPosq = posq1;\n"
"#else\n"
"            localData[threadIdx.x].x = posq1.x;\n"
"            localData[threadIdx.x].y = posq1.y;\n"
"            localData[threadIdx.x].z = posq1.z;\n"
"            localData[threadIdx.x].q = posq1.w;\n"
"            LOAD_LOCAL_PARAMETERS_FROM_1\n"
"#endif\n"
"\n"
"            // we do not need to fetch parameters from global since this is a symmetric tile\n"
"            // instead we can broadcast the values using shuffle\n"
"            for (unsigned int j = 0; j < TILE_SIZE; j++) {\n"
"                int atom2 = tbx+j;\n"
"                real4 posq2;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                BROADCAST_WARP_DATA\n"
"#else   \n"
"                posq2 = make_real4(localData[atom2].x, localData[atom2].y, localData[atom2].z, localData[atom2].q);\n"
"#endif\n"
"                real3 delta = make_real3(posq2.x-posq1.x, posq2.y-posq1.y, posq2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                real invR = RSQRT(r2);\n"
"                real r = r2*invR;\n"
"                LOAD_ATOM2_PARAMETERS\n"
"                atom2 = y*TILE_SIZE+j;\n"
"#ifdef USE_SYMMETRIC\n"
"                real dEdR = 0.0f;\n"
"#else\n"
"                real3 dEdR1 = make_real3(0);\n"
"                real3 dEdR2 = make_real3(0);\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                bool isExcluded = (atom1 >= NUM_ATOMS || atom2 >= NUM_ATOMS || !(excl & 0x1));\n"
"#endif\n"
"                real tempEnergy = 0.0f;\n"
"                const real interactionScale = 0.5f;\n"
"                COMPUTE_INTERACTION\n"
"                energy += 0.5f*tempEnergy;\n"
"#ifdef INCLUDE_FORCES\n"
"#ifdef USE_SYMMETRIC\n"
"                force.x -= delta.x*dEdR;\n"
"                force.y -= delta.y*dEdR;\n"
"                force.z -= delta.z*dEdR;\n"
"#else\n"
"                force.x -= dEdR1.x;\n"
"                force.y -= dEdR1.y;\n"
"                force.z -= dEdR1.z;\n"
"#endif\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                excl >>= 1;\n"
"#endif\n"
"            }\n"
"        }\n"
"        else {\n"
"            // This is an off-diagonal tile.\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"            real4 shflPosq = posq[j];\n"
"#ifdef ENABLE_SHUFFLE\n"
"            real3 shflForce;\n"
"            shflForce.x = 0.0f;\n"
"            shflForce.y = 0.0f;\n"
"            shflForce.z = 0.0f;\n"
"#else\n"
"            localData[threadIdx.x].x = shflPosq.x;\n"
"            localData[threadIdx.x].y = shflPosq.y;\n"
"            localData[threadIdx.x].z = shflPosq.z;\n"
"            localData[threadIdx.x].q = shflPosq.w;\n"
"            localData[threadIdx.x].fx = 0.0f;\n"
"            localData[threadIdx.x].fy = 0.0f;\n"
"            localData[threadIdx.x].fz = 0.0f;\n"
"#endif\n"
"            DECLARE_LOCAL_PARAMETERS\n"
"            LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"#ifdef USE_EXCLUSIONS\n"
"            excl = (excl >> tgx) | (excl << (TILE_SIZE - tgx));\n"
"#endif\n"
"            unsigned int tj = tgx;\n"
"            for (j = 0; j < TILE_SIZE; j++) {\n"
"                int atom2 = tbx+tj;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                real4 posq2 = shflPosq;\n"
"#else\n"
"                real4 posq2 = make_real4(localData[atom2].x, localData[atom2].y, localData[atom2].z, localData[atom2].q);\n"
"#endif\n"
"                real3 delta = make_real3(posq2.x-posq1.x, posq2.y-posq1.y, posq2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                real invR = RSQRT(r2);\n"
"                real r = r2*invR;\n"
"                LOAD_ATOM2_PARAMETERS\n"
"                atom2 = y*TILE_SIZE+tj;\n"
"#ifdef USE_SYMMETRIC\n"
"                real dEdR = 0.0f;\n"
"#else\n"
"                real3 dEdR1 = make_real3(0);\n"
"                real3 dEdR2 = make_real3(0);\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                bool isExcluded = (atom1 >= NUM_ATOMS || atom2 >= NUM_ATOMS || !(excl & 0x1));\n"
"#endif\n"
"                real tempEnergy = 0.0f;\n"
"                const real interactionScale = 1.0f;\n"
"                COMPUTE_INTERACTION\n"
"                energy += tempEnergy;\n"
"#ifdef INCLUDE_FORCES\n"
"#ifdef USE_SYMMETRIC\n"
"                delta *= dEdR;\n"
"                force.x -= delta.x;\n"
"                force.y -= delta.y;\n"
"                force.z -= delta.z;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                shflForce.x += delta.x;\n"
"                shflForce.y += delta.y;\n"
"                shflForce.z += delta.z;\n"
"\n"
"#else\n"
"                localData[tbx+tj].fx += delta.x;\n"
"                localData[tbx+tj].fy += delta.y;\n"
"                localData[tbx+tj].fz += delta.z;\n"
"#endif\n"
"#else // !USE_SYMMETRIC\n"
"                force.x -= dEdR1.x;\n"
"                force.y -= dEdR1.y;\n"
"                force.z -= dEdR1.z;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                shflForce.x += dEdR2.x;\n"
"                shflForce.y += dEdR2.y;\n"
"                shflForce.z += dEdR2.z;\n"
"#else\n"
"                localData[tbx+tj].fx += dEdR2.x;\n"
"                localData[tbx+tj].fy += dEdR2.y;\n"
"                localData[tbx+tj].fz += dEdR2.z;\n"
"#endif \n"
"#endif // end USE_SYMMETRIC\n"
"#endif\n"
"#ifdef ENABLE_SHUFFLE\n"
"                SHUFFLE_WARP_DATA\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                excl >>= 1;\n"
"#endif\n"
"                // cycles the indices\n"
"                // 0 1 2 3 4 5 6 7 -> 1 2 3 4 5 6 7 0\n"
"                tj = (tj + 1) & (TILE_SIZE - 1);\n"
"            }\n"
"            const unsigned int offset = y*TILE_SIZE + tgx;\n"
"            // write results for off diagonal tiles\n"
"#ifdef INCLUDE_FORCES\n"
"#ifdef ENABLE_SHUFFLE\n"
"            atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (shflForce.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (shflForce.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (shflForce.z*0x100000000)));\n"
"#else\n"
"            atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fx*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fy*0x100000000)));\n"
"            atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fz*0x100000000)));\n"
"#endif\n"
"#endif\n"
"        }\n"
"        // Write results for on and off diagonal tiles\n"
"#ifdef INCLUDE_FORCES\n"
"        const unsigned int offset = x*TILE_SIZE + tgx;\n"
"        atomicAdd(&forceBuffers[offset], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[offset+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[offset+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"#endif\n"
"    }\n"
"\n"
"    // Second loop: tiles without exclusions, either from the neighbor list (with cutoff) or just enumerating all\n"
"    // of them (no cutoff).\n"
"\n"
"#ifdef USE_CUTOFF\n"
"    const unsigned int numTiles = interactionCount[0];\n"
"    if (numTiles > maxTiles)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    int pos = (int) (numTiles > maxTiles ? startTileIndex+warp*(long long)numTileIndices/totalWarps : warp*(long long)numTiles/totalWarps);\n"
"    int end = (int) (numTiles > maxTiles ? startTileIndex+(warp+1)*(long long)numTileIndices/totalWarps : (warp+1)*(long long)numTiles/totalWarps);\n"
"#else\n"
"    const unsigned int numTiles = numTileIndices;\n"
"    int pos = (int) (startTileIndex+warp*(long long)numTiles/totalWarps);\n"
"    int end = (int) (startTileIndex+(warp+1)*(long long)numTiles/totalWarps);\n"
"#endif\n"
"    int skipBase = 0;\n"
"    int currentSkipIndex = tbx;\n"
"    // atomIndices can probably be shuffled as well\n"
"    // but it probably wouldn't make things any faster\n"
"    __shared__ int atomIndices[THREAD_BLOCK_SIZE];\n"
"    __shared__ volatile int skipTiles[THREAD_BLOCK_SIZE];\n"
"    skipTiles[threadIdx.x] = -1;\n"
"    \n"
"    while (pos < end) {\n"
"        const bool hasExclusions = false;\n"
"        real3 force = make_real3(0);\n"
"        bool includeTile = true;\n"
"\n"
"        // Extract the coordinates of this tile.\n"
"        int x, y;\n"
"        bool singlePeriodicCopy = false;\n"
"#ifdef USE_CUTOFF\n"
"        x = tiles[pos];\n"
"        real4 blockSizeX = blockSize[x];\n"
"        singlePeriodicCopy = (0.5f*periodicBoxSize.x-blockSizeX.x >= MAX_CUTOFF &&\n"
"                              0.5f*periodicBoxSize.y-blockSizeX.y >= MAX_CUTOFF &&\n"
"                              0.5f*periodicBoxSize.z-blockSizeX.z >= MAX_CUTOFF);\n"
"#else\n"
"        y = (int) floor(NUM_BLOCKS+0.5f-SQRT((NUM_BLOCKS+0.5f)*(NUM_BLOCKS+0.5f)-2*pos));\n"
"        x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        if (x < y || x >= NUM_BLOCKS) { // Occasionally happens due to roundoff error.\n"
"            y += (x < y ? -1 : 1);\n"
"            x = (pos-y*NUM_BLOCKS+y*(y+1)/2);\n"
"        }\n"
"\n"
"        // Skip over tiles that have exclusions, since they were already processed.\n"
"\n"
"        while (skipTiles[tbx+TILE_SIZE-1] < pos) {\n"
"            if (skipBase+tgx < NUM_TILES_WITH_EXCLUSIONS) {\n"
"                ushort2 tile = exclusionTiles[skipBase+tgx];\n"
"                skipTiles[threadIdx.x] = tile.x + tile.y*NUM_BLOCKS - tile.y*(tile.y+1)/2;\n"
"            }\n"
"            else\n"
"                skipTiles[threadIdx.x] = end;\n"
"            skipBase += TILE_SIZE;            \n"
"            currentSkipIndex = tbx;\n"
"        }\n"
"        while (skipTiles[currentSkipIndex] < pos)\n"
"            currentSkipIndex++;\n"
"        includeTile = (skipTiles[currentSkipIndex] != pos);\n"
"#endif\n"
"        if (includeTile) {\n"
"            unsigned int atom1 = x*TILE_SIZE + tgx;\n"
"            // Load atom data for this tile.\n"
"            real4 posq1 = posq[atom1];\n"
"            LOAD_ATOM1_PARAMETERS\n"
"            //const unsigned int localAtomIndex = threadIdx.x;\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int j = interactingAtoms[pos*TILE_SIZE+tgx];\n"
"#else\n"
"            unsigned int j = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            atomIndices[threadIdx.x] = j;\n"
"#ifdef ENABLE_SHUFFLE\n"
"            DECLARE_LOCAL_PARAMETERS\n"
"            real4 shflPosq;\n"
"            real3 shflForce;\n"
"            shflForce.x = 0.0f;\n"
"            shflForce.y = 0.0f;\n"
"            shflForce.z = 0.0f;\n"
"#endif\n"
"            if (j < PADDED_NUM_ATOMS) {\n"
"                // Load position of atom j from from global memory\n"
"#ifdef ENABLE_SHUFFLE\n"
"                shflPosq = posq[j];\n"
"#else\n"
"                localData[threadIdx.x].x = posq[j].x;\n"
"                localData[threadIdx.x].y = posq[j].y;\n"
"                localData[threadIdx.x].z = posq[j].z;\n"
"                localData[threadIdx.x].q = posq[j].w;\n"
"                localData[threadIdx.x].fx = 0.0f;\n"
"                localData[threadIdx.x].fy = 0.0f;\n"
"                localData[threadIdx.x].fz = 0.0f;\n"
"#endif                \n"
"                LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"            }\n"
"            else {\n"
"#ifdef ENABLE_SHUFFLE\n"
"                shflPosq = make_real4(0, 0, 0, 0);\n"
"#else\n"
"                localData[threadIdx.x].x = 0;\n"
"                localData[threadIdx.x].y = 0;\n"
"                localData[threadIdx.x].z = 0;\n"
"#endif\n"
"            }\n"
"#ifdef USE_PERIODIC\n"
"            if (singlePeriodicCopy) {\n"
"                // The box is small enough that we can just translate all the atoms into a single periodic\n"
"                // box, then skip having to apply periodic boundary conditions later.\n"
"                real4 blockCenterX = blockCenter[x];\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(posq1, blockCenterX)\n"
"#ifdef ENABLE_SHUFFLE\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(shflPosq, blockCenterX)\n"
"#else\n"
"                APPLY_PERIODIC_TO_POS_WITH_CENTER(localData[threadIdx.x], blockCenterX)\n"
"#endif\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = tbx+tj;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    real4 posq2 = shflPosq; \n"
"#else\n"
"                    real4 posq2 = make_real4(localData[atom2].x, localData[atom2].y, localData[atom2].z, localData[atom2].q);\n"
"#endif\n"
"                    real3 delta = make_real3(posq2.x-posq1.x, posq2.y-posq1.y, posq2.z-posq1.z);\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    atom2 = atomIndices[tbx+tj];\n"
"#ifdef USE_SYMMETRIC\n"
"                    real dEdR = 0.0f;\n"
"#else\n"
"                    real3 dEdR1 = make_real3(0);\n"
"                    real3 dEdR2 = make_real3(0);\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                    bool isExcluded = (atom1 >= NUM_ATOMS || atom2 >= NUM_ATOMS);\n"
"#endif\n"
"                    real tempEnergy = 0.0f;\n"
"                    const real interactionScale = 1.0f;\n"
"                    COMPUTE_INTERACTION\n"
"                    energy += tempEnergy;\n"
"#ifdef INCLUDE_FORCES\n"
"#ifdef USE_SYMMETRIC\n"
"                    delta *= dEdR;\n"
"                    force.x -= delta.x;\n"
"                    force.y -= delta.y;\n"
"                    force.z -= delta.z;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    shflForce.x += delta.x;\n"
"                    shflForce.y += delta.y;\n"
"                    shflForce.z += delta.z;\n"
"\n"
"#else\n"
"                    localData[tbx+tj].fx += delta.x;\n"
"                    localData[tbx+tj].fy += delta.y;\n"
"                    localData[tbx+tj].fz += delta.z;\n"
"#endif\n"
"#else // !USE_SYMMETRIC\n"
"                    force.x -= dEdR1.x;\n"
"                    force.y -= dEdR1.y;\n"
"                    force.z -= dEdR1.z;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    shflForce.x += dEdR2.x;\n"
"                    shflForce.y += dEdR2.y;\n"
"                    shflForce.z += dEdR2.z;\n"
"#else\n"
"                    localData[tbx+tj].fx += dEdR2.x;\n"
"                    localData[tbx+tj].fy += dEdR2.y;\n"
"                    localData[tbx+tj].fz += dEdR2.z;\n"
"#endif \n"
"#endif // end USE_SYMMETRIC\n"
"#endif\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    SHUFFLE_WARP_DATA\n"
"#endif\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"            else\n"
"#endif\n"
"            {\n"
"                // We need to apply periodic boundary conditions separately for each interaction.\n"
"                unsigned int tj = tgx;\n"
"                for (j = 0; j < TILE_SIZE; j++) {\n"
"                    int atom2 = tbx+tj;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    real4 posq2 = shflPosq;\n"
"#else\n"
"                    real4 posq2 = make_real4(localData[atom2].x, localData[atom2].y, localData[atom2].z, localData[atom2].q);\n"
"#endif\n"
"                    real3 delta = make_real3(posq2.x-posq1.x, posq2.y-posq1.y, posq2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"                    APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"                    real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"                    real invR = RSQRT(r2);\n"
"                    real r = r2*invR;\n"
"                    LOAD_ATOM2_PARAMETERS\n"
"                    atom2 = atomIndices[tbx+tj];\n"
"#ifdef USE_SYMMETRIC\n"
"                    real dEdR = 0.0f;\n"
"#else\n"
"                    real3 dEdR1 = make_real3(0);\n"
"                    real3 dEdR2 = make_real3(0);\n"
"#endif\n"
"#ifdef USE_EXCLUSIONS\n"
"                    bool isExcluded = (atom1 >= NUM_ATOMS || atom2 >= NUM_ATOMS);\n"
"#endif\n"
"                    real tempEnergy = 0.0f;\n"
"                    const real interactionScale = 1.0f;\n"
"                    COMPUTE_INTERACTION\n"
"                    energy += tempEnergy;\n"
"#ifdef INCLUDE_FORCES\n"
"#ifdef USE_SYMMETRIC\n"
"                    delta *= dEdR;\n"
"                    force.x -= delta.x;\n"
"                    force.y -= delta.y;\n"
"                    force.z -= delta.z;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    shflForce.x += delta.x;\n"
"                    shflForce.y += delta.y;\n"
"                    shflForce.z += delta.z;\n"
"\n"
"#else\n"
"                    localData[tbx+tj].fx += delta.x;\n"
"                    localData[tbx+tj].fy += delta.y;\n"
"                    localData[tbx+tj].fz += delta.z;\n"
"#endif\n"
"#else // !USE_SYMMETRIC\n"
"                    force.x -= dEdR1.x;\n"
"                    force.y -= dEdR1.y;\n"
"                    force.z -= dEdR1.z;\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    shflForce.x += dEdR2.x;\n"
"                    shflForce.y += dEdR2.y;\n"
"                    shflForce.z += dEdR2.z;\n"
"#else\n"
"                    localData[tbx+tj].fx += dEdR2.x;\n"
"                    localData[tbx+tj].fy += dEdR2.y;\n"
"                    localData[tbx+tj].fz += dEdR2.z;\n"
"#endif \n"
"#endif // end USE_SYMMETRIC\n"
"#endif\n"
"#ifdef ENABLE_SHUFFLE\n"
"                    SHUFFLE_WARP_DATA\n"
"#endif\n"
"                    tj = (tj + 1) & (TILE_SIZE - 1);\n"
"                }\n"
"            }\n"
"\n"
"            // Write results.\n"
"#ifdef INCLUDE_FORCES\n"
"            atomicAdd(&forceBuffers[atom1], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"            atomicAdd(&forceBuffers[atom1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"#ifdef USE_CUTOFF\n"
"            unsigned int atom2 = atomIndices[threadIdx.x];\n"
"#else\n"
"            unsigned int atom2 = y*TILE_SIZE + tgx;\n"
"#endif\n"
"            if (atom2 < PADDED_NUM_ATOMS) {\n"
"#ifdef ENABLE_SHUFFLE\n"
"                atomicAdd(&forceBuffers[atom2], static_cast<unsigned long long>((long long) (shflForce.x*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (shflForce.y*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (shflForce.z*0x100000000)));\n"
"#else\n"
"                atomicAdd(&forceBuffers[atom2], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fx*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fy*0x100000000)));\n"
"                atomicAdd(&forceBuffers[atom2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (localData[threadIdx.x].fz*0x100000000)));\n"
"#endif\n"
"            }\n"
"#endif\n"
"        }\n"
"        pos++;\n"
"    }\n"
"    \n"
"    // Third loop: single pairs that aren't part of a tile.\n"
"    \n"
"#if USE_CUTOFF\n"
"    const unsigned int numPairs = interactionCount[1];\n"
"    if (numPairs > maxSinglePairs)\n"
"        return; // There wasn't enough memory for the neighbor list.\n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < numPairs; i += blockDim.x*gridDim.x) {\n"
"        int2 pair = singlePairs[i];\n"
"        int atom1 = pair.x;\n"
"        int atom2 = pair.y;\n"
"        real4 posq1 = posq[atom1];\n"
"        real4 posq2 = posq[atom2];\n"
"        LOAD_ATOM1_PARAMETERS\n"
"        int j = atom2;\n"
"atom2 = threadIdx.x;\n"
"        DECLARE_LOCAL_PARAMETERS\n"
"        LOAD_LOCAL_PARAMETERS_FROM_GLOBAL\n"
"        LOAD_ATOM2_PARAMETERS\n"
"atom2 = pair.y;\n"
"        real3 delta = make_real3(posq2.x-posq1.x, posq2.y-posq1.y, posq2.z-posq1.z);\n"
"#ifdef USE_PERIODIC\n"
"        APPLY_PERIODIC_TO_DELTA(delta)\n"
"#endif\n"
"        real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"        real invR = RSQRT(r2);\n"
"        real r = r2*invR;\n"
"#ifdef USE_SYMMETRIC\n"
"        real dEdR = 0.0f;\n"
"#else\n"
"        real3 dEdR1 = make_real3(0);\n"
"        real3 dEdR2 = make_real3(0);\n"
"#endif\n"
"        bool hasExclusions = false;\n"
"        bool isExcluded = false;\n"
"        real tempEnergy = 0.0f;\n"
"        const real interactionScale = 1.0f;\n"
"        COMPUTE_INTERACTION\n"
"        energy += tempEnergy;\n"
"#ifdef INCLUDE_FORCES\n"
"#ifdef USE_SYMMETRIC\n"
"        real3 dEdR1 = delta*dEdR;\n"
"        real3 dEdR2 = -dEdR1;\n"
"#endif\n"
"        atomicAdd(&forceBuffers[atom1], static_cast<unsigned long long>((long long) (-dEdR1.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom1+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (-dEdR1.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom1+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (-dEdR1.z*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom2], static_cast<unsigned long long>((long long) (-dEdR2.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom2+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (-dEdR2.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom2+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (-dEdR2.z*0x100000000)));\n"
"#endif\n"
"    }\n"
"#endif\n"
"#ifdef INCLUDE_ENERGY\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += energy;\n"
"#endif\n"
"    SAVE_DERIVATIVES\n"
"}";
const string CudaKernelSources::nonbondedExceptions = "float4 exceptionParams = PARAMS[index];\n"
"real3 delta = make_real3(pos2.x-pos1.x, pos2.y-pos1.y, pos2.z-pos1.z);\n"
"real r2 = delta.x*delta.x + delta.y*delta.y + delta.z*delta.z;\n"
"real invR = RSQRT(r2);\n"
"real sig2 = invR*exceptionParams.y;\n"
"sig2 *= sig2;\n"
"real sig6 = sig2*sig2*sig2;\n"
"real dEdR = exceptionParams.z*(12.0f*sig6-6.0f)*sig6;\n"
"real tempEnergy = exceptionParams.z*(sig6-1.0f)*sig6;\n"
"dEdR += exceptionParams.x*invR;\n"
"dEdR *= invR*invR;\n"
"tempEnergy += exceptionParams.x*invR;\n"
"energy += tempEnergy;\n"
"delta *= dEdR;\n"
"real3 force1 = -delta;\n"
"real3 force2 = delta;\n"
"";
const string CudaKernelSources::parallel = "/**\n"
" * Sum the forces computed by different contexts.\n"
" */\n"
"\n"
"extern \"C\" __global__ void sumForces(long long* __restrict__ force, long long* __restrict__ buffer, int bufferSize, int numBuffers) {\n"
"    int totalSize = bufferSize*numBuffers;\n"
"    for (int index = blockDim.x*blockIdx.x+threadIdx.x; index < bufferSize; index += blockDim.x*gridDim.x) {\n"
"        long long sum = force[index];\n"
"        for (int i = index; i < totalSize; i += bufferSize)\n"
"            sum += buffer[i];\n"
"        force[index] = sum;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::periodicTorsionForce = "float4 torsionParams = PARAMS[index];\n"
"real deltaAngle = torsionParams.z*theta-torsionParams.y;\n"
"energy += torsionParams.x*(1.0f+COS(deltaAngle));\n"
"real sinDeltaAngle = SIN(deltaAngle);\n"
"real dEdAngle = -torsionParams.x*torsionParams.z*sinDeltaAngle;\n"
"";
const string CudaKernelSources::pme = "extern \"C\" __global__ void findAtomGridIndex(const real4* __restrict__ posq, int2* __restrict__ pmeAtomGridIndex,\n"
"            real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"            real3 recipBoxVecX, real3 recipBoxVecY, real3 recipBoxVecZ) {\n"
"    // Compute the index of the grid point each atom is associated with.\n"
"    \n"
"    for (int atom = blockIdx.x*blockDim.x+threadIdx.x; atom < NUM_ATOMS; atom += blockDim.x*gridDim.x) {\n"
"        real4 pos = posq[atom];\n"
"        APPLY_PERIODIC_TO_POS(pos)\n"
"        real3 t = make_real3(pos.x*recipBoxVecX.x+pos.y*recipBoxVecY.x+pos.z*recipBoxVecZ.x,\n"
"                             pos.y*recipBoxVecY.y+pos.z*recipBoxVecZ.y,\n"
"                             pos.z*recipBoxVecZ.z);\n"
"        t.x = (t.x-floor(t.x))*GRID_SIZE_X;\n"
"        t.y = (t.y-floor(t.y))*GRID_SIZE_Y;\n"
"        t.z = (t.z-floor(t.z))*GRID_SIZE_Z;\n"
"        int3 gridIndex = make_int3(((int) t.x) % GRID_SIZE_X,\n"
"                                   ((int) t.y) % GRID_SIZE_Y,\n"
"                                   ((int) t.z) % GRID_SIZE_Z);\n"
"        pmeAtomGridIndex[atom] = make_int2(atom, gridIndex.x*GRID_SIZE_Y*GRID_SIZE_Z+gridIndex.y*GRID_SIZE_Z+gridIndex.z);\n"
"    }\n"
"}\n"
"\n"
"extern \"C\" __global__ void gridSpreadCharge(const real4* __restrict__ posq, real* __restrict__ originalPmeGrid,\n"
"        real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        real3 recipBoxVecX, real3 recipBoxVecY, real3 recipBoxVecZ, const int2* __restrict__ pmeAtomGridIndex\n"
"#ifdef USE_LJPME\n"
"        , const float2* __restrict__ sigmaEpsilon\n"
"#else\n"
"        , const real* __restrict__ charges\n"
"#endif\n"
"        ) {\n"
"    real3 data[PME_ORDER];\n"
"    const real scale = RECIP(PME_ORDER-1);\n"
"    \n"
"    // Process the atoms in spatially sorted order.  This improves efficiency when writing\n"
"    // the grid values.\n"
"    \n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < NUM_ATOMS; i += blockDim.x*gridDim.x) {\n"
"        int atom = pmeAtomGridIndex[i].x;\n"
"        real4 pos = posq[atom];\n"
"#ifdef USE_LJPME\n"
"        const float2 sigEps = sigmaEpsilon[atom];\n"
"        const real charge = 8*sigEps.x*sigEps.x*sigEps.x*sigEps.y;\n"
"#else\n"
"        const real charge = CHARGE;\n"
"#endif\n"
"        if (charge == 0)\n"
"            continue;\n"
"        APPLY_PERIODIC_TO_POS(pos)\n"
"        real3 t = make_real3(pos.x*recipBoxVecX.x+pos.y*recipBoxVecY.x+pos.z*recipBoxVecZ.x,\n"
"                             pos.y*recipBoxVecY.y+pos.z*recipBoxVecZ.y,\n"
"                             pos.z*recipBoxVecZ.z);\n"
"        t.x = (t.x-floor(t.x))*GRID_SIZE_X;\n"
"        t.y = (t.y-floor(t.y))*GRID_SIZE_Y;\n"
"        t.z = (t.z-floor(t.z))*GRID_SIZE_Z;\n"
"        int3 gridIndex = make_int3(((int) t.x) % GRID_SIZE_X,\n"
"                                   ((int) t.y) % GRID_SIZE_Y,\n"
"                                   ((int) t.z) % GRID_SIZE_Z);\n"
"\n"
"        // Since we need the full set of thetas, it's faster to compute them here than load them\n"
"        // from global memory.\n"
"        \n"
"        real3 dr = make_real3(t.x-(int) t.x, t.y-(int) t.y, t.z-(int) t.z);\n"
"        data[PME_ORDER-1] = make_real3(0);\n"
"        data[1] = dr;\n"
"        data[0] = make_real3(1)-dr;\n"
"        for (int j = 3; j < PME_ORDER; j++) {\n"
"            real div = RECIP(j-1);\n"
"            data[j-1] = div*dr*data[j-2];\n"
"            for (int k = 1; k < (j-1); k++)\n"
"                data[j-k-1] = div*((dr+make_real3(k))*data[j-k-2] + (make_real3(j-k)-dr)*data[j-k-1]);\n"
"            data[0] = div*(make_real3(1)-dr)*data[0];\n"
"        }\n"
"        data[PME_ORDER-1] = scale*dr*data[PME_ORDER-2];\n"
"        for (int j = 1; j < (PME_ORDER-1); j++)\n"
"            data[PME_ORDER-j-1] = scale*((dr+make_real3(j))*data[PME_ORDER-j-2] + (make_real3(PME_ORDER-j)-dr)*data[PME_ORDER-j-1]);\n"
"        data[0] = scale*(make_real3(1)-dr)*data[0];\n"
"        \n"
"        // Spread the charge from this atom onto each grid point.\n"
"        \n"
"        for (int ix = 0; ix < PME_ORDER; ix++) {\n"
"            int xbase = gridIndex.x+ix;\n"
"            xbase -= (xbase >= GRID_SIZE_X ? GRID_SIZE_X : 0);\n"
"            xbase = xbase*GRID_SIZE_Y*GRID_SIZE_Z;\n"
"            real dx = data[ix].x;\n"
"            \n"
"            for (int iy = 0; iy < PME_ORDER; iy++) {\n"
"                int ybase = gridIndex.y+iy;\n"
"                ybase -= (ybase >= GRID_SIZE_Y ? GRID_SIZE_Y : 0);\n"
"                ybase = xbase + ybase*GRID_SIZE_Z;\n"
"                real dy = data[iy].y;\n"
"                \n"
"                for (int iz = 0; iz < PME_ORDER; iz++) {\n"
"                    int zindex = gridIndex.z+iz;\n"
"                    zindex -= (zindex >= GRID_SIZE_Z ? GRID_SIZE_Z : 0);\n"
"                    int index = ybase + zindex;\n"
"\n"
"                    real add = charge*dx*dy*data[iz].z;\n"
"#ifdef USE_DOUBLE_PRECISION\n"
"                    unsigned long long * ulonglong_p = (unsigned long long *) originalPmeGrid;\n"
"                    atomicAdd(&ulonglong_p[index],  static_cast<unsigned long long>((long long) (add*0x100000000)));\n"
"#elif __CUDA_ARCH__ < 200 || defined(USE_DETERMINISTIC_FORCES)\n"
"                    unsigned long long * ulonglong_p = (unsigned long long *) originalPmeGrid;\n"
"                    int gridIndex = index;\n"
"                    gridIndex = (gridIndex%2 == 0 ? gridIndex/2 : (gridIndex+GRID_SIZE_X*GRID_SIZE_Y*GRID_SIZE_Z)/2);\n"
"                    atomicAdd(&ulonglong_p[gridIndex],  static_cast<unsigned long long>((long long) (add*0x100000000)));\n"
"#else\n"
"                    atomicAdd(&originalPmeGrid[index], add*EPSILON_FACTOR);\n"
"#endif\n"
"                }\n"
"            }\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"extern \"C\" __global__ void finishSpreadCharge(long long* __restrict__ originalPmeGrid) {\n"
"    real* floatGrid = (real*) originalPmeGrid;\n"
"    const unsigned int gridSize = GRID_SIZE_X*GRID_SIZE_Y*GRID_SIZE_Z;\n"
"    real scale = EPSILON_FACTOR/(real) 0x100000000;\n"
"#ifdef USE_DOUBLE_PRECISION\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x)\n"
"        floatGrid[index] = scale*originalPmeGrid[index];\n"
"#else\n"
"    for (int index = 2*(blockIdx.x*blockDim.x+threadIdx.x); index < gridSize; index += 2*blockDim.x*gridDim.x) {\n"
"        floatGrid[index] = scale*originalPmeGrid[index/2];\n"
"        if (index+1 < gridSize)\n"
"            floatGrid[index+1] = scale*originalPmeGrid[(index+gridSize+1)/2];\n"
"    }\n"
"#endif\n"
"}\n"
"\n"
"// convolutes on the halfcomplex_pmeGrid, which is of size NX*NY*(NZ/2+1) as F(Q) is conjugate symmetric\n"
"extern \"C\" __global__ void \n"
"reciprocalConvolution(real2* __restrict__ halfcomplex_pmeGrid, mixed* __restrict__ energyBuffer, \n"
"                      const real* __restrict__ pmeBsplineModuliX, const real* __restrict__ pmeBsplineModuliY, const real* __restrict__ pmeBsplineModuliZ, \n"
"                      real4 periodicBoxSize, real3 recipBoxVecX, real3 recipBoxVecY, real3 recipBoxVecZ) {\n"
"    // R2C stores into a half complex matrix where the last dimension is cut by half\n"
"    const unsigned int gridSize = GRID_SIZE_X*GRID_SIZE_Y*(GRID_SIZE_Z/2+1);\n"
"#ifdef USE_LJPME\n"
"    const real recipScaleFactor = -2*M_PI*SQRT(M_PI)*RECIP(6*periodicBoxSize.x*periodicBoxSize.y*periodicBoxSize.z);\n"
"    real bfac = M_PI / EWALD_ALPHA;\n"
"    real fac1 = 2*M_PI*M_PI*M_PI*SQRT(M_PI);\n"
"    real fac2 = EWALD_ALPHA*EWALD_ALPHA*EWALD_ALPHA;\n"
"    real fac3 = -2*EWALD_ALPHA*M_PI*M_PI;\n"
"#else\n"
"    const real recipScaleFactor = RECIP(M_PI*periodicBoxSize.x*periodicBoxSize.y*periodicBoxSize.z);\n"
"#endif\n"
"\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x) {\n"
"        // real indices\n"
"        int kx = index/(GRID_SIZE_Y*(GRID_SIZE_Z/2+1));\n"
"        int remainder = index-kx*GRID_SIZE_Y*(GRID_SIZE_Z/2+1);\n"
"        int ky = remainder/(GRID_SIZE_Z/2+1);\n"
"        int kz = remainder-ky*(GRID_SIZE_Z/2+1);\n"
"        int mx = (kx < (GRID_SIZE_X+1)/2) ? kx : (kx-GRID_SIZE_X);\n"
"        int my = (ky < (GRID_SIZE_Y+1)/2) ? ky : (ky-GRID_SIZE_Y);\n"
"        int mz = (kz < (GRID_SIZE_Z+1)/2) ? kz : (kz-GRID_SIZE_Z);\n"
"        real mhx = mx*recipBoxVecX.x;\n"
"        real mhy = mx*recipBoxVecY.x+my*recipBoxVecY.y;\n"
"        real mhz = mx*recipBoxVecZ.x+my*recipBoxVecZ.y+mz*recipBoxVecZ.z;\n"
"        real bx = pmeBsplineModuliX[kx];\n"
"        real by = pmeBsplineModuliY[ky];\n"
"        real bz = pmeBsplineModuliZ[kz];\n"
"        real2 grid = halfcomplex_pmeGrid[index];\n"
"        real m2 = mhx*mhx+mhy*mhy+mhz*mhz;\n"
"#ifdef USE_LJPME\n"
"        real denom = recipScaleFactor/(bx*by*bz);\n"
"        real m = SQRT(m2);\n"
"        real m3 = m*m2;\n"
"        real b = bfac*m;\n"
"        real expfac = -b*b;\n"
"        real expterm = EXP(expfac);\n"
"        real erfcterm = ERFC(b);\n"
"        real eterm = (fac1*erfcterm*m3 + expterm*(fac2 + fac3*m2)) * denom;\n"
"        halfcomplex_pmeGrid[index] = make_real2(grid.x*eterm, grid.y*eterm);\n"
"#else\n"
"        real denom = m2*bx*by*bz;\n"
"        real eterm = recipScaleFactor*EXP(-RECIP_EXP_FACTOR*m2)/denom;\n"
"        if (kx != 0 || ky != 0 || kz != 0) {\n"
"            halfcomplex_pmeGrid[index] = make_real2(grid.x*eterm, grid.y*eterm);\n"
"        }\n"
"#endif\n"
"    }\n"
"}\n"
"\n"
"\n"
"extern \"C\" __global__ void\n"
"gridEvaluateEnergy(real2* __restrict__ halfcomplex_pmeGrid, mixed* __restrict__ energyBuffer,\n"
"                      const real* __restrict__ pmeBsplineModuliX, const real* __restrict__ pmeBsplineModuliY, const real* __restrict__ pmeBsplineModuliZ,\n"
"                      real4 periodicBoxSize, real3 recipBoxVecX, real3 recipBoxVecY, real3 recipBoxVecZ) {\n"
"    // R2C stores into a half complex matrix where the last dimension is cut by half\n"
"    const unsigned int gridSize = GRID_SIZE_X*GRID_SIZE_Y*GRID_SIZE_Z;\n"
" #ifdef USE_LJPME\n"
"    const real recipScaleFactor = -2*M_PI*SQRT(M_PI)*RECIP(6*periodicBoxSize.x*periodicBoxSize.y*periodicBoxSize.z);\n"
"    real bfac = M_PI / EWALD_ALPHA;\n"
"    real fac1 = 2*M_PI*M_PI*M_PI*SQRT(M_PI);\n"
"    real fac2 = EWALD_ALPHA*EWALD_ALPHA*EWALD_ALPHA;\n"
"    real fac3 = -2*EWALD_ALPHA*M_PI*M_PI;\n"
"#else\n"
"    const real recipScaleFactor = RECIP(M_PI*periodicBoxSize.x*periodicBoxSize.y*periodicBoxSize.z);\n"
"#endif\n"
"\n"
"    mixed energy = 0;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < gridSize; index += blockDim.x*gridDim.x) {\n"
"        // real indices\n"
"        int kx = index/(GRID_SIZE_Y*(GRID_SIZE_Z));\n"
"        int remainder = index-kx*GRID_SIZE_Y*(GRID_SIZE_Z);\n"
"        int ky = remainder/(GRID_SIZE_Z);\n"
"        int kz = remainder-ky*(GRID_SIZE_Z);\n"
"        int mx = (kx < (GRID_SIZE_X+1)/2) ? kx : (kx-GRID_SIZE_X);\n"
"        int my = (ky < (GRID_SIZE_Y+1)/2) ? ky : (ky-GRID_SIZE_Y);\n"
"        int mz = (kz < (GRID_SIZE_Z+1)/2) ? kz : (kz-GRID_SIZE_Z);\n"
"        real mhx = mx*recipBoxVecX.x;\n"
"        real mhy = mx*recipBoxVecY.x+my*recipBoxVecY.y;\n"
"        real mhz = mx*recipBoxVecZ.x+my*recipBoxVecZ.y+mz*recipBoxVecZ.z;\n"
"        real m2 = mhx*mhx+mhy*mhy+mhz*mhz;\n"
"        real bx = pmeBsplineModuliX[kx];\n"
"        real by = pmeBsplineModuliY[ky];\n"
"        real bz = pmeBsplineModuliZ[kz];\n"
"#ifdef USE_LJPME\n"
"        real denom = recipScaleFactor/(bx*by*bz);\n"
"        real m = SQRT(m2);\n"
"        real m3 = m*m2;\n"
"        real b = bfac*m;\n"
"        real expfac = -b*b;\n"
"        real expterm = EXP(expfac);\n"
"        real erfcterm = ERFC(b);\n"
"        real eterm = (fac1*erfcterm*m3 + expterm*(fac2 + fac3*m2)) * denom;\n"
"#else\n"
"        real denom = m2*bx*by*bz;\n"
"        real eterm = recipScaleFactor*EXP(-RECIP_EXP_FACTOR*m2)/denom;\n"
"#endif\n"
"\n"
"        if (kz >= (GRID_SIZE_Z/2+1)) {\n"
"            kx = ((kx == 0) ? kx : GRID_SIZE_X-kx);\n"
"            ky = ((ky == 0) ? ky : GRID_SIZE_Y-ky);\n"
"            kz = GRID_SIZE_Z-kz;\n"
"        } \n"
"        int indexInHalfComplexGrid = kz + ky*(GRID_SIZE_Z/2+1)+kx*(GRID_SIZE_Y*(GRID_SIZE_Z/2+1));\n"
"        real2 grid = halfcomplex_pmeGrid[indexInHalfComplexGrid];\n"
"#ifndef USE_LJPME\n"
"        if (kx != 0 || ky != 0 || kz != 0)\n"
"#endif\n"
"            energy += eterm*(grid.x*grid.x + grid.y*grid.y);\n"
"    }\n"
"#if defined(USE_PME_STREAM) && !defined(USE_LJPME)\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] = 0.5f*energy;\n"
"#else\n"
"    energyBuffer[blockIdx.x*blockDim.x+threadIdx.x] += 0.5f*energy;\n"
"#endif\n"
"}\n"
"\n"
"extern \"C\" __global__\n"
"void gridInterpolateForce(const real4* __restrict__ posq, unsigned long long* __restrict__ forceBuffers, const real* __restrict__ originalPmeGrid,\n"
"        real4 periodicBoxSize, real4 invPeriodicBoxSize, real4 periodicBoxVecX, real4 periodicBoxVecY, real4 periodicBoxVecZ,\n"
"        real3 recipBoxVecX, real3 recipBoxVecY, real3 recipBoxVecZ, const int2* __restrict__ pmeAtomGridIndex\n"
"#ifdef USE_LJPME\n"
"        , const float2* __restrict__ sigmaEpsilon\n"
"#else\n"
"        , const real* __restrict__ charges\n"
"#endif\n"
"        ) {\n"
"    real3 data[PME_ORDER];\n"
"    real3 ddata[PME_ORDER];\n"
"    const real scale = RECIP(PME_ORDER-1);\n"
"    \n"
"    // Process the atoms in spatially sorted order.  This improves cache performance when loading\n"
"    // the grid values.\n"
"    \n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < NUM_ATOMS; i += blockDim.x*gridDim.x) {\n"
"        int atom = pmeAtomGridIndex[i].x;\n"
"        real3 force = make_real3(0);\n"
"        real4 pos = posq[atom];\n"
"        APPLY_PERIODIC_TO_POS(pos)\n"
"        real3 t = make_real3(pos.x*recipBoxVecX.x+pos.y*recipBoxVecY.x+pos.z*recipBoxVecZ.x,\n"
"                             pos.y*recipBoxVecY.y+pos.z*recipBoxVecZ.y,\n"
"                             pos.z*recipBoxVecZ.z);\n"
"        t.x = (t.x-floor(t.x))*GRID_SIZE_X;\n"
"        t.y = (t.y-floor(t.y))*GRID_SIZE_Y;\n"
"        t.z = (t.z-floor(t.z))*GRID_SIZE_Z;\n"
"        int3 gridIndex = make_int3(((int) t.x) % GRID_SIZE_X,\n"
"                                   ((int) t.y) % GRID_SIZE_Y,\n"
"                                   ((int) t.z) % GRID_SIZE_Z);\n"
"\n"
"        // Since we need the full set of thetas, it's faster to compute them here than load them\n"
"        // from global memory.\n"
"        \n"
"        real3 dr = make_real3(t.x-(int) t.x, t.y-(int) t.y, t.z-(int) t.z);\n"
"        data[PME_ORDER-1] = make_real3(0);\n"
"        data[1] = dr;\n"
"        data[0] = make_real3(1)-dr;\n"
"        for (int j = 3; j < PME_ORDER; j++) {\n"
"            real div = RECIP(j-1);\n"
"            data[j-1] = div*dr*data[j-2];\n"
"            for (int k = 1; k < (j-1); k++)\n"
"                data[j-k-1] = div*((dr+make_real3(k))*data[j-k-2] + (make_real3(j-k)-dr)*data[j-k-1]);\n"
"            data[0] = div*(make_real3(1)-dr)*data[0];\n"
"        }\n"
"        ddata[0] = -data[0];\n"
"        for (int j = 1; j < PME_ORDER; j++)\n"
"            ddata[j] = data[j-1]-data[j];\n"
"        data[PME_ORDER-1] = scale*dr*data[PME_ORDER-2];\n"
"        for (int j = 1; j < (PME_ORDER-1); j++)\n"
"            data[PME_ORDER-j-1] = scale*((dr+make_real3(j))*data[PME_ORDER-j-2] + (make_real3(PME_ORDER-j)-dr)*data[PME_ORDER-j-1]);\n"
"        data[0] = scale*(make_real3(1)-dr)*data[0];\n"
"        \n"
"        // Compute the force on this atom.\n"
"         \n"
"        for (int ix = 0; ix < PME_ORDER; ix++) {\n"
"            int xbase = gridIndex.x+ix;\n"
"            xbase -= (xbase >= GRID_SIZE_X ? GRID_SIZE_X : 0);\n"
"            xbase = xbase*GRID_SIZE_Y*GRID_SIZE_Z;\n"
"            real dx = data[ix].x;\n"
"            real ddx = ddata[ix].x;\n"
"            \n"
"            for (int iy = 0; iy < PME_ORDER; iy++) {\n"
"                int ybase = gridIndex.y+iy;\n"
"                ybase -= (ybase >= GRID_SIZE_Y ? GRID_SIZE_Y : 0);\n"
"                ybase = xbase + ybase*GRID_SIZE_Z;\n"
"                real dy = data[iy].y;\n"
"                real ddy = ddata[iy].y;\n"
"                \n"
"                for (int iz = 0; iz < PME_ORDER; iz++) {\n"
"                    int zindex = gridIndex.z+iz;\n"
"                    zindex -= (zindex >= GRID_SIZE_Z ? GRID_SIZE_Z : 0);\n"
"                    int index = ybase + zindex;\n"
"                    real gridvalue = originalPmeGrid[index];\n"
"                    force.x += ddx*dy*data[iz].z*gridvalue;\n"
"                    force.y += dx*ddy*data[iz].z*gridvalue;\n"
"                    force.z += dx*dy*ddata[iz].z*gridvalue;\n"
"                }\n"
"            }\n"
"        }\n"
"#ifdef USE_LJPME\n"
"        const float2 sigEps = sigmaEpsilon[atom];\n"
"        real q = 8*sigEps.x*sigEps.x*sigEps.x*sigEps.y;\n"
"#else\n"
"        real q = CHARGE*EPSILON_FACTOR;\n"
"#endif\n"
"        real forceX = -q*(force.x*GRID_SIZE_X*recipBoxVecX.x);\n"
"        real forceY = -q*(force.x*GRID_SIZE_X*recipBoxVecY.x+force.y*GRID_SIZE_Y*recipBoxVecY.y);\n"
"        real forceZ = -q*(force.x*GRID_SIZE_X*recipBoxVecZ.x+force.y*GRID_SIZE_Y*recipBoxVecZ.y+force.z*GRID_SIZE_Z*recipBoxVecZ.z);\n"
"        atomicAdd(&forceBuffers[atom], static_cast<unsigned long long>((long long) (forceX*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom+PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (forceY*0x100000000)));\n"
"        atomicAdd(&forceBuffers[atom+2*PADDED_NUM_ATOMS], static_cast<unsigned long long>((long long) (forceZ*0x100000000)));\n"
"    }\n"
"}\n"
"\n"
"extern \"C\" __global__\n"
"void addForces(const real4* __restrict__ forces, unsigned long long* __restrict__ forceBuffers) {\n"
"    for (int atom = blockIdx.x*blockDim.x+threadIdx.x; atom < NUM_ATOMS; atom += blockDim.x*gridDim.x) {\n"
"        real4 f = forces[atom];\n"
"        forceBuffers[atom] += static_cast<unsigned long long>((long long) (f.x*0x100000000));\n"
"        forceBuffers[atom+PADDED_NUM_ATOMS] += static_cast<unsigned long long>((long long) (f.y*0x100000000));\n"
"        forceBuffers[atom+2*PADDED_NUM_ATOMS] += static_cast<unsigned long long>((long long) (f.z*0x100000000));\n"
"    }\n"
"}\n"
"\n"
"extern \"C\" __global__\n"
"void addEnergy(const mixed* __restrict__ pmeEnergyBuffer, mixed* __restrict__ energyBuffer, int bufferSize) {\n"
"    for (int i = blockIdx.x*blockDim.x+threadIdx.x; i < bufferSize; i += blockDim.x*gridDim.x)\n"
"        energyBuffer[i] += pmeEnergyBuffer[i];\n"
"}\n"
"";
const string CudaKernelSources::rbTorsionForce = "float4 torsionParams1 = PARAMS1[index];\n"
"float2 torsionParams2 = PARAMS2[index];\n"
"if (theta < 0)\n"
"    theta += PI;\n"
"else\n"
"    theta -= PI;\n"
"cosangle = -cosangle;\n"
"real cosFactor = cosangle;\n"
"real dEdAngle = -torsionParams1.y;\n"
"real rbEnergy = torsionParams1.x;\n"
"rbEnergy += torsionParams1.y*cosFactor;\n"
"dEdAngle -= 2.0f*torsionParams1.z*cosFactor;\n"
"cosFactor *= cosangle;\n"
"dEdAngle -= 3.0f*torsionParams1.w*cosFactor;\n"
"rbEnergy += torsionParams1.z*cosFactor;\n"
"cosFactor *= cosangle;\n"
"dEdAngle -= 4.0f*torsionParams2.x*cosFactor;\n"
"rbEnergy += torsionParams1.w*cosFactor;\n"
"cosFactor *= cosangle;\n"
"dEdAngle -= 5.0f*torsionParams2.y*cosFactor;\n"
"rbEnergy += torsionParams2.x*cosFactor;\n"
"rbEnergy += torsionParams2.y*cosFactor*cosangle;\n"
"energy += rbEnergy;\n"
"dEdAngle *= SIN(theta);\n"
"";
const string CudaKernelSources::removeCM = "/**\n"
" * Calculate the center of mass momentum.\n"
" */\n"
"\n"
"extern \"C\" __global__ void calcCenterOfMassMomentum(int numAtoms, const mixed4* __restrict__ velm, float4* __restrict__ cmMomentum) {\n"
"    extern __shared__ volatile float3 temp[];\n"
"    float3 cm = make_float3(0, 0, 0);\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed4 velocity = velm[index];\n"
"        if (velocity.w != 0) {\n"
"            mixed mass = RECIP(velocity.w);\n"
"            cm.x += (float) (velocity.x*mass);\n"
"            cm.y += (float) (velocity.y*mass);\n"
"            cm.z += (float) (velocity.z*mass);\n"
"        }\n"
"    }\n"
"\n"
"    // Sum the threads in this group.\n"
"\n"
"    int thread = threadIdx.x;\n"
"    temp[thread].x = cm.x;\n"
"    temp[thread].y = cm.y;\n"
"    temp[thread].z = cm.z;\n"
"    __syncthreads();\n"
"    if (thread < 32) {\n"
"        temp[thread].x += temp[thread+32].x;\n"
"        temp[thread].y += temp[thread+32].y;\n"
"        temp[thread].z += temp[thread+32].z;\n"
"        if (thread < 16) {\n"
"            temp[thread].x += temp[thread+16].x;\n"
"            temp[thread].y += temp[thread+16].y;\n"
"            temp[thread].z += temp[thread+16].z;\n"
"        }\n"
"        if (thread < 8) {\n"
"            temp[thread].x += temp[thread+8].x;\n"
"            temp[thread].y += temp[thread+8].y;\n"
"            temp[thread].z += temp[thread+8].z;\n"
"        }\n"
"        if (thread < 4) {\n"
"            temp[thread].x += temp[thread+4].x;\n"
"            temp[thread].y += temp[thread+4].y;\n"
"            temp[thread].z += temp[thread+4].z;\n"
"        }\n"
"        if (thread < 2) {\n"
"            temp[thread].x += temp[thread+2].x;\n"
"            temp[thread].y += temp[thread+2].y;\n"
"            temp[thread].z += temp[thread+2].z;\n"
"        }\n"
"    }\n"
"    if (thread == 0) {\n"
"        float3 sum = make_float3(temp[thread].x+temp[thread+1].x, temp[thread].y+temp[thread+1].y, temp[thread].z+temp[thread+1].z);\n"
"        cmMomentum[blockIdx.x] = make_float4(sum.x, sum.y, sum.z, 0.0f);\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Remove center of mass motion.\n"
" */\n"
"\n"
"extern \"C\" __global__ void removeCenterOfMassMomentum(unsigned int numAtoms, mixed4* __restrict__ velm, const float4* __restrict__ cmMomentum) {\n"
"    // First sum all of the momenta that were calculated by individual groups.\n"
"\n"
"    extern volatile float3 temp[];\n"
"    float3 cm = make_float3(0, 0, 0);\n"
"    for (unsigned int index = threadIdx.x; index < gridDim.x; index += blockDim.x) {\n"
"        float4 momentum = cmMomentum[index];\n"
"        cm.x += momentum.x;\n"
"        cm.y += momentum.y;\n"
"        cm.z += momentum.z;\n"
"    }\n"
"    int thread = threadIdx.x;\n"
"    temp[thread].x = cm.x;\n"
"    temp[thread].y = cm.y;\n"
"    temp[thread].z = cm.z;\n"
"    __syncthreads();\n"
"    if (thread < 32) {\n"
"        temp[thread].x += temp[thread+32].x;\n"
"        temp[thread].y += temp[thread+32].y;\n"
"        temp[thread].z += temp[thread+32].z;\n"
"        if (thread < 16) {\n"
"            temp[thread].x += temp[thread+16].x;\n"
"            temp[thread].y += temp[thread+16].y;\n"
"            temp[thread].z += temp[thread+16].z;\n"
"        }\n"
"        if (thread < 8) {\n"
"            temp[thread].x += temp[thread+8].x;\n"
"            temp[thread].y += temp[thread+8].y;\n"
"            temp[thread].z += temp[thread+8].z;\n"
"        }\n"
"        if (thread < 4) {\n"
"            temp[thread].x += temp[thread+4].x;\n"
"            temp[thread].y += temp[thread+4].y;\n"
"            temp[thread].z += temp[thread+4].z;\n"
"        }\n"
"        if (thread < 2) {\n"
"            temp[thread].x += temp[thread+2].x;\n"
"            temp[thread].y += temp[thread+2].y;\n"
"            temp[thread].z += temp[thread+2].z;\n"
"        }\n"
"    }\n"
"    __syncthreads();\n"
"    cm = make_float3(INVERSE_TOTAL_MASS*(temp[0].x+temp[1].x), INVERSE_TOTAL_MASS*(temp[0].y+temp[1].y), INVERSE_TOTAL_MASS*(temp[0].z+temp[1].z));\n"
"\n"
"    // Now remove the center of mass velocity from each atom.\n"
"\n"
"    for (unsigned int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed4 velocity = velm[index];\n"
"        velocity.x -= cm.x;\n"
"        velocity.y -= cm.y;\n"
"        velocity.z -= cm.z;\n"
"        velm[index] = velocity;\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::rmsd = "// This file contains kernels to compute the RMSD and its gradient using the algorithm described\n"
"// in Coutsias et al, \"Using quaternions to calculate RMSD\" (doi: 10.1002/jcc.20110).\n"
"\n"
"/**\n"
" * Sum a value over all threads.\n"
" */\n"
"__device__ real reduceValue(real value, volatile real* temp) {\n"
"    const int thread = threadIdx.x;\n"
"    __syncthreads();\n"
"    temp[thread] = value;\n"
"    __syncthreads();\n"
"    for (uint step = 1; step < 32; step *= 2) {\n"
"        if (thread+step < blockDim.x && thread%(2*step) == 0)\n"
"            temp[thread] = temp[thread] + temp[thread+step];\n"
"        SYNC_WARPS\n"
"    }\n"
"    for (uint step = 32; step < blockDim.x; step *= 2) {\n"
"        if (thread+step < blockDim.x && thread%(2*step) == 0)\n"
"            temp[thread] = temp[thread] + temp[thread+step];\n"
"        __syncthreads();\n"
"    }\n"
"    return temp[0];\n"
"}\n"
"\n"
"/**\n"
" * Perform the first step of computing the RMSD.  This is executed as a single work group.\n"
" */\n"
"extern \"C\" __global__ void computeRMSDPart1(int numParticles, const real4* __restrict__ posq, const real4* __restrict__ referencePos,\n"
"         const int* __restrict__ particles, real* buffer) {\n"
"    extern __shared__ volatile real temp[];\n"
"\n"
"    // Compute the center of the particle positions.\n"
"    \n"
"    real3 center = make_real3(0);\n"
"    for (int i = threadIdx.x; i < numParticles; i += blockDim.x)\n"
"        center += trimTo3(posq[particles[i]]);\n"
"    center.x = reduceValue(center.x, temp)/numParticles;\n"
"    center.y = reduceValue(center.y, temp)/numParticles;\n"
"    center.z = reduceValue(center.z, temp)/numParticles;\n"
"    \n"
"    // Compute the correlation matrix.\n"
"    \n"
"    real R[3][3] = {{0, 0, 0}, {0, 0, 0}, {0, 0, 0}};\n"
"    real sum = 0;\n"
"    for (int i = threadIdx.x; i < numParticles; i += blockDim.x) {\n"
"        int index = particles[i];\n"
"        real3 pos = trimTo3(posq[index]) - center;\n"
"        real3 refPos = trimTo3(referencePos[index]);\n"
"        R[0][0] += pos.x*refPos.x;\n"
"        R[0][1] += pos.x*refPos.y;\n"
"        R[0][2] += pos.x*refPos.z;\n"
"        R[1][0] += pos.y*refPos.x;\n"
"        R[1][1] += pos.y*refPos.y;\n"
"        R[1][2] += pos.y*refPos.z;\n"
"        R[2][0] += pos.z*refPos.x;\n"
"        R[2][1] += pos.z*refPos.y;\n"
"        R[2][2] += pos.z*refPos.z;\n"
"        sum += dot(pos, pos);\n"
"    }\n"
"    for (int i = 0; i < 3; i++)\n"
"        for (int j = 0; j < 3; j++)\n"
"            R[i][j] = reduceValue(R[i][j], temp);\n"
"    sum = reduceValue(sum, temp);\n"
"\n"
"    // Copy everything into the output buffer to send back to the host.\n"
"    \n"
"    if (threadIdx.x == 0) {\n"
"        for (int i = 0; i < 3; i++)\n"
"            for (int j = 0; j < 3; j++)\n"
"                buffer[3*i+j] = R[i][j];\n"
"        buffer[9] = sum;\n"
"        buffer[10] = center.x;\n"
"        buffer[11] = center.y;\n"
"        buffer[12] = center.z;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Apply forces based on the RMSD.\n"
" */\n"
"extern \"C\" __global__ void computeRMSDForces(int numParticles, int paddedNumAtoms, const real4* __restrict__ posq, const real4* __restrict__ referencePos,\n"
"         const int* __restrict__ particles, const real* buffer, unsigned long long* __restrict__ forceBuffers) {\n"
"    real3 center = make_real3(buffer[10], buffer[11], buffer[12]);\n"
"    real scale = 1 / (real) (buffer[9]*numParticles);\n"
"    for (int i = blockDim.x*blockIdx.x+threadIdx.x; i < numParticles; i += blockDim.x*gridDim.x) {\n"
"        int index = particles[i];\n"
"        real3 pos = trimTo3(posq[index]) - center;\n"
"        real3 refPos = trimTo3(referencePos[index]);\n"
"        real3 rotatedRef = make_real3(buffer[0]*refPos.x + buffer[3]*refPos.y + buffer[6]*refPos.z,\n"
"                                      buffer[1]*refPos.x + buffer[4]*refPos.y + buffer[7]*refPos.z,\n"
"                                      buffer[2]*refPos.x + buffer[5]*refPos.y + buffer[8]*refPos.z);\n"
"        real3 force = (rotatedRef-pos)*scale;\n"
"        atomicAdd(&forceBuffers[index], static_cast<unsigned long long>((long long) (force.x*0x100000000)));\n"
"        atomicAdd(&forceBuffers[index+paddedNumAtoms], static_cast<unsigned long long>((long long) (force.y*0x100000000)));\n"
"        atomicAdd(&forceBuffers[index+2*paddedNumAtoms], static_cast<unsigned long long>((long long) (force.z*0x100000000)));\n"
"    }\n"
"}\n"
"";
const string CudaKernelSources::sort = "__device__ KEY_TYPE getValue(DATA_TYPE value) {\n"
"    return SORT_KEY;\n"
"}\n"
"\n"
"extern \"C\" {\n"
"\n"
"/**\n"
" * Sort a list that is short enough to entirely fit in local memory.  This is executed as\n"
" * a single thread block.\n"
" */\n"
"__global__ void sortShortList(DATA_TYPE* __restrict__ data, unsigned int length) {\n"
"    // Load the data into local memory.\n"
"    \n"
"    extern __shared__ DATA_TYPE dataBuffer[];\n"
"    for (int index = threadIdx.x; index < length; index += blockDim.x)\n"
"        dataBuffer[index] = data[index];\n"
"    __syncthreads();\n"
"\n"
"    // Perform a bitonic sort in local memory.\n"
"\n"
"    for (unsigned int k = 2; k < 2*length; k *= 2) {\n"
"        for (unsigned int j = k/2; j > 0; j /= 2) {\n"
"            for (unsigned int i = threadIdx.x; i < length; i += blockDim.x) {\n"
"                int ixj = i^j;\n"
"                if (ixj > i && ixj < length) {\n"
"                    DATA_TYPE value1 = dataBuffer[i];\n"
"                    DATA_TYPE value2 = dataBuffer[ixj];\n"
"                    bool ascending = ((i&k) == 0);\n"
"                    for (unsigned int mask = k*2; mask < 2*length; mask *= 2)\n"
"                        ascending = ((i&mask) == 0 ? !ascending : ascending);\n"
"                    KEY_TYPE lowKey  = (ascending ? getValue(value1) : getValue(value2));\n"
"                    KEY_TYPE highKey = (ascending ? getValue(value2) : getValue(value1));\n"
"                    if (lowKey > highKey) {\n"
"                        dataBuffer[i] = value2;\n"
"                        dataBuffer[ixj] = value1;\n"
"                    }\n"
"                }\n"
"            }\n"
"            __syncthreads();\n"
"        }\n"
"    }\n"
"\n"
"    // Write the data back to global memory.\n"
"\n"
"    for (int index = threadIdx.x; index < length; index += blockDim.x)\n"
"        data[index] = dataBuffer[index];\n"
"}\n"
"\n"
"/**\n"
" * An alternate kernel for sorting short lists.  In this version every thread does a full\n"
" * scan through the data to select the destination for one element.  This involves more\n"
" * work, but also parallelizes much better.\n"
" */\n"
"__global__ void sortShortList2(const DATA_TYPE* __restrict__ dataIn, DATA_TYPE* __restrict__ dataOut, unsigned int length) {\n"
"    __shared__ DATA_TYPE dataBuffer[64];\n"
"    int globalId = blockDim.x*blockIdx.x+threadIdx.x;\n"
"    DATA_TYPE value = dataIn[globalId < length ? globalId : 0];\n"
"    KEY_TYPE key = getValue(value);\n"
"    int count = 0;\n"
"    for (int blockStart = 0; blockStart < length; blockStart += blockDim.x) {\n"
"        int numInBlock = min(blockDim.x, length-blockStart);\n"
"        __syncthreads();\n"
"        if (threadIdx.x < numInBlock)\n"
"            dataBuffer[threadIdx.x] = dataIn[blockStart+threadIdx.x];\n"
"        __syncthreads();\n"
"        for (int i = 0; i < numInBlock; i++) {\n"
"            KEY_TYPE otherKey = getValue(dataBuffer[i]);\n"
"            if (otherKey < key || (otherKey == key && blockStart+i < globalId))\n"
"                count++;\n"
"        }\n"
"    }\n"
"    if (globalId < length)\n"
"        dataOut[count] = value;\n"
"}\n"
"\n"
"/**\n"
" * Calculate the minimum and maximum value in the array to be sorted.  This kernel\n"
" * is executed as a single work group.\n"
" */\n"
"__global__ void computeRange(const DATA_TYPE* __restrict__ data, unsigned int length, KEY_TYPE* __restrict__ range,\n"
"        unsigned int numBuckets, unsigned int* __restrict__ bucketOffset) {\n"
"    extern __shared__ KEY_TYPE minBuffer[];\n"
"    KEY_TYPE* maxBuffer = minBuffer+blockDim.x;\n"
"    KEY_TYPE minimum = MAX_KEY;\n"
"    KEY_TYPE maximum = MIN_KEY;\n"
"\n"
"    // Each thread calculates the range of a subset of values.\n"
"\n"
"    for (unsigned int index = threadIdx.x; index < length; index += blockDim.x) {\n"
"        KEY_TYPE value = getValue(data[index]);\n"
"        minimum = min(minimum, value);\n"
"        maximum = max(maximum, value);\n"
"    }\n"
"\n"
"    // Now reduce them.\n"
"\n"
"    minBuffer[threadIdx.x] = minimum;\n"
"    maxBuffer[threadIdx.x] = maximum;\n"
"    __syncthreads();\n"
"    for (unsigned int step = 1; step < blockDim.x; step *= 2) {\n"
"        if (threadIdx.x+step < blockDim.x && threadIdx.x%(2*step) == 0) {\n"
"            minBuffer[threadIdx.x] = min(minBuffer[threadIdx.x], minBuffer[threadIdx.x+step]);\n"
"            maxBuffer[threadIdx.x] = max(maxBuffer[threadIdx.x], maxBuffer[threadIdx.x+step]);\n"
"        }\n"
"        __syncthreads();\n"
"    }\n"
"    minimum = minBuffer[0];\n"
"    maximum = maxBuffer[0];\n"
"    if (threadIdx.x == 0) {\n"
"        range[0] = minimum;\n"
"        range[1] = maximum;\n"
"    }\n"
"    \n"
"    // Clear the bucket counters in preparation for the next kernel.\n"
"\n"
"    for (unsigned int index = threadIdx.x; index < numBuckets; index += blockDim.x)\n"
"        bucketOffset[index] = 0;\n"
"}\n"
"\n"
"/**\n"
" * Assign elements to buckets.\n"
" */\n"
"__global__ void assignElementsToBuckets(const DATA_TYPE* __restrict__ data, unsigned int length, unsigned int numBuckets, const KEY_TYPE* __restrict__ range,\n"
"        unsigned int* __restrict__ bucketOffset, unsigned int* __restrict__ bucketOfElement, unsigned int* __restrict__ offsetInBucket) {\n"
"    float minValue = (float) (range[0]);\n"
"    float maxValue = (float) (range[1]);\n"
"    float bucketWidth = (maxValue-minValue)/numBuckets;\n"
"    for (unsigned int index = blockDim.x*blockIdx.x+threadIdx.x; index < length; index += blockDim.x*gridDim.x) {\n"
"        float key = (float) getValue(data[index]);\n"
"        unsigned int bucketIndex = min((unsigned int) ((key-minValue)/bucketWidth), numBuckets-1);\n"
"        offsetInBucket[index] = atomicAdd(&bucketOffset[bucketIndex], 1);\n"
"        bucketOfElement[index] = bucketIndex;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Sum the bucket sizes to compute the start position of each bucket.  This kernel\n"
" * is executed as a single work group.\n"
" */\n"
"__global__ void computeBucketPositions(unsigned int numBuckets, unsigned int* __restrict__ bucketOffset) {\n"
"    extern __shared__ unsigned int posBuffer[];\n"
"    unsigned int globalOffset = 0;\n"
"    for (unsigned int startBucket = 0; startBucket < numBuckets; startBucket += blockDim.x) {\n"
"        // Load the bucket sizes into local memory.\n"
"\n"
"        unsigned int globalIndex = startBucket+threadIdx.x;\n"
"        __syncthreads();\n"
"        posBuffer[threadIdx.x] = (globalIndex < numBuckets ? bucketOffset[globalIndex] : 0);\n"
"        __syncthreads();\n"
"\n"
"        // Perform a parallel prefix sum.\n"
"\n"
"        for (unsigned int step = 1; step < blockDim.x; step *= 2) {\n"
"            unsigned int add = (threadIdx.x >= step ? posBuffer[threadIdx.x-step] : 0);\n"
"            __syncthreads();\n"
"            posBuffer[threadIdx.x] += add;\n"
"            __syncthreads();\n"
"        }\n"
"\n"
"        // Write the results back to global memory.\n"
"\n"
"        if (globalIndex < numBuckets)\n"
"            bucketOffset[globalIndex] = posBuffer[threadIdx.x]+globalOffset;\n"
"        globalOffset += posBuffer[blockDim.x-1];\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Copy the input data into the buckets for sorting.\n"
" */\n"
"__global__ void copyDataToBuckets(const DATA_TYPE* __restrict__ data, DATA_TYPE* __restrict__ buckets, unsigned int length, const unsigned int* __restrict__ bucketOffset, const unsigned int* __restrict__ bucketOfElement, const unsigned int* __restrict__ offsetInBucket) {\n"
"    for (unsigned int index = blockDim.x*blockIdx.x+threadIdx.x; index < length; index += blockDim.x*gridDim.x) {\n"
"        DATA_TYPE element = data[index];\n"
"        unsigned int bucketIndex = bucketOfElement[index];\n"
"        unsigned int offset = (bucketIndex == 0 ? 0 : bucketOffset[bucketIndex-1]);\n"
"        buckets[offset+offsetInBucket[index]] = element;\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Sort the data in each bucket.\n"
" */\n"
"__global__ void sortBuckets(DATA_TYPE* __restrict__ data, const DATA_TYPE* __restrict__ buckets, unsigned int numBuckets, const unsigned int* __restrict__ bucketOffset) {\n"
"    extern __shared__ DATA_TYPE dataBuffer[];\n"
"    for (unsigned int index = blockIdx.x; index < numBuckets; index += gridDim.x) {\n"
"        unsigned int startIndex = (index == 0 ? 0 : bucketOffset[index-1]);\n"
"        unsigned int endIndex = bucketOffset[index];\n"
"        unsigned int length = endIndex-startIndex;\n"
"        if (length <= blockDim.x) {\n"
"            // Load the data into local memory.\n"
"\n"
"            if (threadIdx.x < length)\n"
"                dataBuffer[threadIdx.x] = buckets[startIndex+threadIdx.x];\n"
"            else\n"
"                dataBuffer[threadIdx.x] = MAX_VALUE;\n"
"            __syncthreads();\n"
"\n"
"            // Perform a bitonic sort in local memory.\n"
"\n"
"            for (unsigned int k = 2; k <= blockDim.x; k *= 2) {\n"
"                for (unsigned int j = k/2; j > 0; j /= 2) {\n"
"                    int ixj = threadIdx.x^j;\n"
"                    if (ixj > threadIdx.x) {\n"
"                        DATA_TYPE value1 = dataBuffer[threadIdx.x];\n"
"                        DATA_TYPE value2 = dataBuffer[ixj];\n"
"                        bool ascending = (threadIdx.x&k) == 0;\n"
"                        KEY_TYPE lowKey = (ascending ? getValue(value1) : getValue(value2));\n"
"                        KEY_TYPE highKey = (ascending ? getValue(value2) : getValue(value1));\n"
"                        if (lowKey > highKey) {\n"
"                            dataBuffer[threadIdx.x] = value2;\n"
"                            dataBuffer[ixj] = value1;\n"
"                        }\n"
"                    }\n"
"                    __syncthreads();\n"
"                }\n"
"            }\n"
"\n"
"            // Write the data to the sorted array.\n"
"\n"
"            if (threadIdx.x < length)\n"
"                data[startIndex+threadIdx.x] = dataBuffer[threadIdx.x];\n"
"        }\n"
"        else {\n"
"            // Copy the bucket data over to the output array.\n"
"\n"
"            for (unsigned int i = threadIdx.x; i < length; i += blockDim.x)\n"
"                data[startIndex+i] = buckets[startIndex+i];\n"
"            __threadfence_block();\n"
"            __syncthreads();\n"
"\n"
"            // Perform a bitonic sort in global memory.\n"
"\n"
"            for (unsigned int k = 2; k < 2*length; k *= 2) {\n"
"                for (unsigned int j = k/2; j > 0; j /= 2) {\n"
"                    for (unsigned int i = threadIdx.x; i < length; i += blockDim.x) {\n"
"                        int ixj = i^j;\n"
"                        if (ixj > i && ixj < length) {\n"
"                            DATA_TYPE value1 = data[startIndex+i];\n"
"                            DATA_TYPE value2 = data[startIndex+ixj];\n"
"                            bool ascending = ((i&k) == 0);\n"
"                            for (unsigned int mask = k*2; mask < 2*length; mask *= 2)\n"
"                                ascending = ((i&mask) == 0 ? !ascending : ascending);\n"
"                            KEY_TYPE lowKey  = (ascending ? getValue(value1) : getValue(value2));\n"
"                            KEY_TYPE highKey = (ascending ? getValue(value2) : getValue(value1));\n"
"                            if (lowKey > highKey) {\n"
"                                data[startIndex+i] = value2;\n"
"                                data[startIndex+ixj] = value1;\n"
"                            }\n"
"                        }\n"
"                    }\n"
"                    __threadfence_block();\n"
"                    __syncthreads();\n"
"                }\n"
"            }\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"}";
const string CudaKernelSources::torsionForce = "const real PI = (real) 3.14159265358979323846;\n"
"real3 v0 = make_real3(pos1.x-pos2.x, pos1.y-pos2.y, pos1.z-pos2.z);\n"
"real3 v1 = make_real3(pos3.x-pos2.x, pos3.y-pos2.y, pos3.z-pos2.z);\n"
"real3 v2 = make_real3(pos3.x-pos4.x, pos3.y-pos4.y, pos3.z-pos4.z);\n"
"#if APPLY_PERIODIC\n"
"APPLY_PERIODIC_TO_DELTA(v0)\n"
"APPLY_PERIODIC_TO_DELTA(v1)\n"
"APPLY_PERIODIC_TO_DELTA(v2)\n"
"#endif\n"
"real3 cp0 = cross(v0, v1);\n"
"real3 cp1 = cross(v1, v2);\n"
"real cosangle = dot(normalize(cp0), normalize(cp1));\n"
"real theta;\n"
"if (cosangle > 0.99f || cosangle < -0.99f) {\n"
"    // We're close to the singularity in acos(), so take the cross product and use asin() instead.\n"
"\n"
"    real3 cross_prod = cross(cp0, cp1);\n"
"    real scale = dot(cp0, cp0)*dot(cp1, cp1);\n"
"    theta = ASIN(SQRT(dot(cross_prod, cross_prod)/scale));\n"
"    if (cosangle < 0)\n"
"        theta = PI-theta;\n"
"}\n"
"else\n"
"   theta = ACOS(cosangle);\n"
"theta = (dot(v0, cp1) >= 0 ? theta : -theta);\n"
"COMPUTE_FORCE\n"
"real normCross1 = dot(cp0, cp0);\n"
"real normSqrBC = dot(v1, v1);\n"
"real normBC = SQRT(normSqrBC);\n"
"real normCross2 = dot(cp1, cp1);\n"
"real dp = RECIP(normSqrBC);\n"
"real4 ff = make_real4((-dEdAngle*normBC)/normCross1, dot(v0, v1)*dp, dot(v2, v1)*dp, (dEdAngle*normBC)/normCross2);\n"
"real3 force1 = ff.x*cp0;\n"
"real3 force4 = ff.w*cp1;\n"
"real3 s = ff.y*force1 - ff.z*force4;\n"
"real3 force2 = s-force1;\n"
"real3 force3 = -s-force4;\n"
"";
const string CudaKernelSources::utilities = "extern \"C\" {\n"
"\n"
"/**\n"
" * This is called by the various functions below to clear a buffer.\n"
" */\n"
"__device__ void clearSingleBuffer(int* __restrict__ buffer, int size) {\n"
"    int index = blockDim.x*blockIdx.x+threadIdx.x;\n"
"    int4* buffer4 = (int4*) buffer;\n"
"    int sizeDiv4 = size/4;\n"
"    while (index < sizeDiv4) {\n"
"        buffer4[index] = make_int4(0);\n"
"        index += blockDim.x*gridDim.x;\n"
"    }\n"
"    if (blockDim.x*blockIdx.x+threadIdx.x == 0)\n"
"        for (int i = sizeDiv4*4; i < size; i++)\n"
"            buffer[i] = 0;\n"
"}\n"
"\n"
"/**\n"
" * Fill a buffer with 0.\n"
" */\n"
"__global__ void clearBuffer(int* __restrict__ buffer, int size) {\n"
"    clearSingleBuffer(buffer, size);\n"
"}\n"
"\n"
"/**\n"
" * Fill two buffers with 0.\n"
" */\n"
"__global__ void clearTwoBuffers(int* __restrict__ buffer1, int size1, int* __restrict__ buffer2, int size2) {\n"
"    clearSingleBuffer(buffer1, size1);\n"
"    clearSingleBuffer(buffer2, size2);\n"
"}\n"
"\n"
"/**\n"
" * Fill three buffers with 0.\n"
" */\n"
"__global__ void clearThreeBuffers(int* __restrict__ buffer1, int size1, int* __restrict__ buffer2, int size2, int* __restrict__ buffer3, int size3) {\n"
"    clearSingleBuffer(buffer1, size1);\n"
"    clearSingleBuffer(buffer2, size2);\n"
"    clearSingleBuffer(buffer3, size3);\n"
"}\n"
"\n"
"/**\n"
" * Fill four buffers with 0.\n"
" */\n"
"__global__ void clearFourBuffers(int* __restrict__ buffer1, int size1, int* __restrict__ buffer2, int size2, int* __restrict__ buffer3, int size3, int* __restrict__ buffer4, int size4) {\n"
"    clearSingleBuffer(buffer1, size1);\n"
"    clearSingleBuffer(buffer2, size2);\n"
"    clearSingleBuffer(buffer3, size3);\n"
"    clearSingleBuffer(buffer4, size4);\n"
"}\n"
"\n"
"/**\n"
" * Fill five buffers with 0.\n"
" */\n"
"__global__ void clearFiveBuffers(int* __restrict__ buffer1, int size1, int* __restrict__ buffer2, int size2, int* __restrict__ buffer3, int size3, int* __restrict__ buffer4, int size4, int* __restrict__ buffer5, int size5) {\n"
"    clearSingleBuffer(buffer1, size1);\n"
"    clearSingleBuffer(buffer2, size2);\n"
"    clearSingleBuffer(buffer3, size3);\n"
"    clearSingleBuffer(buffer4, size4);\n"
"    clearSingleBuffer(buffer5, size5);\n"
"}\n"
"\n"
"/**\n"
" * Fill six buffers with 0.\n"
" */\n"
"__global__ void clearSixBuffers(int* __restrict__ buffer1, int size1, int* __restrict__ buffer2, int size2, int* __restrict__ buffer3, int size3, int* __restrict__ buffer4, int size4, int* __restrict__ buffer5, int size5, int* __restrict__ buffer6, int size6) {\n"
"    clearSingleBuffer(buffer1, size1);\n"
"    clearSingleBuffer(buffer2, size2);\n"
"    clearSingleBuffer(buffer3, size3);\n"
"    clearSingleBuffer(buffer4, size4);\n"
"    clearSingleBuffer(buffer5, size5);\n"
"    clearSingleBuffer(buffer6, size6);\n"
"}\n"
"\n"
"/**\n"
" * Sum the energy buffer.\n"
" */\n"
"__global__ void reduceEnergy(const mixed* __restrict__ energyBuffer, mixed* __restrict__ result, int bufferSize, int workGroupSize) {\n"
"    extern __shared__ mixed tempBuffer[];\n"
"    const unsigned int thread = threadIdx.x;\n"
"    mixed sum = 0;\n"
"    for (unsigned int index = thread; index < bufferSize; index += blockDim.x)\n"
"        sum += energyBuffer[index];\n"
"    tempBuffer[thread] = sum;\n"
"    for (int i = 1; i < workGroupSize; i *= 2) {\n"
"        __syncthreads();\n"
"        if (thread%(i*2) == 0 && thread+i < workGroupSize)\n"
"            tempBuffer[thread] += tempBuffer[thread+i];\n"
"    }\n"
"    if (thread == 0)\n"
"        *result = tempBuffer[0];\n"
"}\n"
"\n"
"/**\n"
" * Record the atomic charges into the posq array.\n"
" */\n"
"__global__ void setCharges(real* __restrict__ charges, real4* __restrict__ posq, int* __restrict__ atomOrder, int numAtoms) {\n"
"    for (int i = blockDim.x*blockIdx.x+threadIdx.x; i < numAtoms; i += blockDim.x*gridDim.x)\n"
"        posq[i].w = charges[atomOrder[i]];\n"
"}\n"
"}";
const string CudaKernelSources::vectorOps = "/**\n"
" * This file defines vector operations to simplify code elsewhere.\n"
" */\n"
"\n"
"// Versions of make_x() that take a single value and set all components to that.\n"
"\n"
"inline __device__ int2 make_int2(int a) {\n"
"    return make_int2(a, a);\n"
"}\n"
"\n"
"inline __device__ int3 make_int3(int a) {\n"
"    return make_int3(a, a, a);\n"
"}\n"
"\n"
"inline __device__ int4 make_int4(int a) {\n"
"    return make_int4(a, a, a, a);\n"
"}\n"
"\n"
"inline __device__ float2 make_float2(float a) {\n"
"    return make_float2(a, a);\n"
"}\n"
"\n"
"inline __device__ float3 make_float3(float a) {\n"
"    return make_float3(a, a, a);\n"
"}\n"
"\n"
"inline __device__ float4 make_float4(float a) {\n"
"    return make_float4(a, a, a, a);\n"
"}\n"
"\n"
"inline __device__ double2 make_double2(double a) {\n"
"    return make_double2(a, a);\n"
"}\n"
"\n"
"inline __device__ double3 make_double3(double a) {\n"
"    return make_double3(a, a, a);\n"
"}\n"
"\n"
"inline __device__ double4 make_double4(double a) {\n"
"    return make_double4(a, a, a, a);\n"
"}\n"
"\n"
"// Negate a vector.\n"
"\n"
"inline __device__ int2 operator-(int2 a) {\n"
"    return make_int2(-a.x, -a.y);\n"
"}\n"
"\n"
"inline __device__ int3 operator-(int3 a) {\n"
"    return make_int3(-a.x, -a.y, -a.z);\n"
"}\n"
"\n"
"inline __device__ int4 operator-(int4 a) {\n"
"    return make_int4(-a.x, -a.y, -a.z, -a.w);\n"
"}\n"
"\n"
"inline __device__ float2 operator-(float2 a) {\n"
"    return make_float2(-a.x, -a.y);\n"
"}\n"
"\n"
"inline __device__ float3 operator-(float3 a) {\n"
"    return make_float3(-a.x, -a.y, -a.z);\n"
"}\n"
"\n"
"inline __device__ float4 operator-(float4 a) {\n"
"    return make_float4(-a.x, -a.y, -a.z, -a.w);\n"
"}\n"
"\n"
"inline __device__ double2 operator-(double2 a) {\n"
"    return make_double2(-a.x, -a.y);\n"
"}\n"
"\n"
"inline __device__ double3 operator-(double3 a) {\n"
"    return make_double3(-a.x, -a.y, -a.z);\n"
"}\n"
"\n"
"inline __device__ double4 operator-(double4 a) {\n"
"    return make_double4(-a.x, -a.y, -a.z, -a.w);\n"
"}\n"
"\n"
"// Add two vectors.\n"
"\n"
"inline __device__ int2 operator+(int2 a, int2 b) {\n"
"    return make_int2(a.x+b.x, a.y+b.y);\n"
"}\n"
"\n"
"inline __device__ int3 operator+(int3 a, int3 b) {\n"
"    return make_int3(a.x+b.x, a.y+b.y, a.z+b.z);\n"
"}\n"
"\n"
"inline __device__ int4 operator+(int4 a, int4 b) {\n"
"    return make_int4(a.x+b.x, a.y+b.y, a.z+b.z, a.w+b.w);\n"
"}\n"
"\n"
"inline __device__ float2 operator+(float2 a, float2 b) {\n"
"    return make_float2(a.x+b.x, a.y+b.y);\n"
"}\n"
"\n"
"inline __device__ float3 operator+(float3 a, float3 b) {\n"
"    return make_float3(a.x+b.x, a.y+b.y, a.z+b.z);\n"
"}\n"
"\n"
"inline __device__ float4 operator+(float4 a, float4 b) {\n"
"    return make_float4(a.x+b.x, a.y+b.y, a.z+b.z, a.w+b.w);\n"
"}\n"
"\n"
"inline __device__ double2 operator+(double2 a, double2 b) {\n"
"    return make_double2(a.x+b.x, a.y+b.y);\n"
"}\n"
"\n"
"inline __device__ double3 operator+(double3 a, double3 b) {\n"
"    return make_double3(a.x+b.x, a.y+b.y, a.z+b.z);\n"
"}\n"
"\n"
"inline __device__ double4 operator+(double4 a, double4 b) {\n"
"    return make_double4(a.x+b.x, a.y+b.y, a.z+b.z, a.w+b.w);\n"
"}\n"
"\n"
"// Subtract two vectors.\n"
"\n"
"inline __device__ int2 operator-(int2 a, int2 b) {\n"
"    return make_int2(a.x-b.x, a.y-b.y);\n"
"}\n"
"\n"
"inline __device__ int3 operator-(int3 a, int3 b) {\n"
"    return make_int3(a.x-b.x, a.y-b.y, a.z-b.z);\n"
"}\n"
"\n"
"inline __device__ int4 operator-(int4 a, int4 b) {\n"
"    return make_int4(a.x-b.x, a.y-b.y, a.z-b.z, a.w-b.w);\n"
"}\n"
"\n"
"inline __device__ float2 operator-(float2 a, float2 b) {\n"
"    return make_float2(a.x-b.x, a.y-b.y);\n"
"}\n"
"\n"
"inline __device__ float3 operator-(float3 a, float3 b) {\n"
"    return make_float3(a.x-b.x, a.y-b.y, a.z-b.z);\n"
"}\n"
"\n"
"inline __device__ float4 operator-(float4 a, float4 b) {\n"
"    return make_float4(a.x-b.x, a.y-b.y, a.z-b.z, a.w-b.w);\n"
"}\n"
"\n"
"inline __device__ double2 operator-(double2 a, double2 b) {\n"
"    return make_double2(a.x-b.x, a.y-b.y);\n"
"}\n"
"\n"
"inline __device__ double3 operator-(double3 a, double3 b) {\n"
"    return make_double3(a.x-b.x, a.y-b.y, a.z-b.z);\n"
"}\n"
"\n"
"inline __device__ double4 operator-(double4 a, double4 b) {\n"
"    return make_double4(a.x-b.x, a.y-b.y, a.z-b.z, a.w-b.w);\n"
"}\n"
"\n"
"// Multiply two vectors.\n"
"\n"
"inline __device__ int2 operator*(int2 a, int2 b) {\n"
"    return make_int2(a.x*b.x, a.y*b.y);\n"
"}\n"
"\n"
"inline __device__ int3 operator*(int3 a, int3 b) {\n"
"    return make_int3(a.x*b.x, a.y*b.y, a.z*b.z);\n"
"}\n"
"\n"
"inline __device__ int4 operator*(int4 a, int4 b) {\n"
"    return make_int4(a.x*b.x, a.y*b.y, a.z*b.z, a.w*b.w);\n"
"}\n"
"\n"
"inline __device__ float2 operator*(float2 a, float2 b) {\n"
"    return make_float2(a.x*b.x, a.y*b.y);\n"
"}\n"
"\n"
"inline __device__ float3 operator*(float3 a, float3 b) {\n"
"    return make_float3(a.x*b.x, a.y*b.y, a.z*b.z);\n"
"}\n"
"\n"
"inline __device__ float4 operator*(float4 a, float4 b) {\n"
"    return make_float4(a.x*b.x, a.y*b.y, a.z*b.z, a.w*b.w);\n"
"}\n"
"\n"
"inline __device__ double2 operator*(double2 a, double2 b) {\n"
"    return make_double2(a.x*b.x, a.y*b.y);\n"
"}\n"
"\n"
"inline __device__ double3 operator*(double3 a, double3 b) {\n"
"    return make_double3(a.x*b.x, a.y*b.y, a.z*b.z);\n"
"}\n"
"\n"
"inline __device__ double4 operator*(double4 a, double4 b) {\n"
"    return make_double4(a.x*b.x, a.y*b.y, a.z*b.z, a.w*b.w);\n"
"}\n"
"\n"
"// Divide two vectors.\n"
"\n"
"inline __device__ int2 operator/(int2 a, int2 b) {\n"
"    return make_int2(a.x/b.x, a.y/b.y);\n"
"}\n"
"\n"
"inline __device__ int3 operator/(int3 a, int3 b) {\n"
"    return make_int3(a.x/b.x, a.y/b.y, a.z/b.z);\n"
"}\n"
"\n"
"inline __device__ int4 operator/(int4 a, int4 b) {\n"
"    return make_int4(a.x/b.x, a.y/b.y, a.z/b.z, a.w/b.w);\n"
"}\n"
"\n"
"inline __device__ float2 operator/(float2 a, float2 b) {\n"
"    return make_float2(a.x/b.x, a.y/b.y);\n"
"}\n"
"\n"
"inline __device__ float3 operator/(float3 a, float3 b) {\n"
"    return make_float3(a.x/b.x, a.y/b.y, a.z/b.z);\n"
"}\n"
"\n"
"inline __device__ float4 operator/(float4 a, float4 b) {\n"
"    return make_float4(a.x/b.x, a.y/b.y, a.z/b.z, a.w/b.w);\n"
"}\n"
"\n"
"inline __device__ double2 operator/(double2 a, double2 b) {\n"
"    return make_double2(a.x/b.x, a.y/b.y);\n"
"}\n"
"\n"
"inline __device__ double3 operator/(double3 a, double3 b) {\n"
"    return make_double3(a.x/b.x, a.y/b.y, a.z/b.z);\n"
"}\n"
"\n"
"inline __device__ double4 operator/(double4 a, double4 b) {\n"
"    return make_double4(a.x/b.x, a.y/b.y, a.z/b.z, a.w/b.w);\n"
"}\n"
"\n"
"// += operator\n"
"\n"
"inline __device__ void operator+=(int2& a, int2 b) {\n"
"    a.x += b.x; a.y += b.y;\n"
"}\n"
"\n"
"inline __device__ void operator+=(int3& a, int3 b) {\n"
"    a.x += b.x; a.y += b.y; a.z += b.z;\n"
"}\n"
"\n"
"inline __device__ void operator+=(int4& a, int4 b) {\n"
"    a.x += b.x; a.y += b.y; a.z += b.z; a.w += b.w;\n"
"}\n"
"\n"
"inline __device__ void operator+=(float2& a, float2 b) {\n"
"    a.x += b.x; a.y += b.y;\n"
"}\n"
"\n"
"inline __device__ void operator+=(float3& a, float3 b) {\n"
"    a.x += b.x; a.y += b.y; a.z += b.z;\n"
"}\n"
"\n"
"inline __device__ void operator+=(float4& a, float4 b) {\n"
"    a.x += b.x; a.y += b.y; a.z += b.z; a.w += b.w;\n"
"}\n"
"\n"
"inline __device__ void operator+=(double2& a, double2 b) {\n"
"    a.x += b.x; a.y += b.y;\n"
"}\n"
"\n"
"inline __device__ void operator+=(double3& a, double3 b) {\n"
"    a.x += b.x; a.y += b.y; a.z += b.z;\n"
"}\n"
"\n"
"inline __device__ void operator+=(double4& a, double4 b) {\n"
"    a.x += b.x; a.y += b.y; a.z += b.z; a.w += b.w;\n"
"}\n"
"\n"
"// -= operator\n"
"\n"
"inline __device__ void operator-=(int2& a, int2 b) {\n"
"    a.x -= b.x; a.y -= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator-=(int3& a, int3 b) {\n"
"    a.x -= b.x; a.y -= b.y; a.z -= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator-=(int4& a, int4 b) {\n"
"    a.x -= b.x; a.y -= b.y; a.z -= b.z; a.w -= b.w;\n"
"}\n"
"\n"
"inline __device__ void operator-=(float2& a, float2 b) {\n"
"    a.x -= b.x; a.y -= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator-=(float3& a, float3 b) {\n"
"    a.x -= b.x; a.y -= b.y; a.z -= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator-=(float4& a, float4 b) {\n"
"    a.x -= b.x; a.y -= b.y; a.z -= b.z; a.w -= b.w;\n"
"}\n"
"\n"
"inline __device__ void operator-=(double2& a, double2 b) {\n"
"    a.x -= b.x; a.y -= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator-=(double3& a, double3 b) {\n"
"    a.x -= b.x; a.y -= b.y; a.z -= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator-=(double4& a, double4 b) {\n"
"    a.x -= b.x; a.y -= b.y; a.z -= b.z; a.w -= b.w;\n"
"}\n"
"\n"
"// *= operator\n"
"\n"
"inline __device__ void operator*=(int2& a, int2 b) {\n"
"    a.x *= b.x; a.y *= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator*=(int3& a, int3 b) {\n"
"    a.x *= b.x; a.y *= b.y; a.z *= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator*=(int4& a, int4 b) {\n"
"    a.x *= b.x; a.y *= b.y; a.z *= b.z; a.w *= b.w;\n"
"}\n"
"\n"
"inline __device__ void operator*=(float2& a, float2 b) {\n"
"    a.x *= b.x; a.y *= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator*=(float3& a, float3 b) {\n"
"    a.x *= b.x; a.y *= b.y; a.z *= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator*=(float4& a, float4 b) {\n"
"    a.x *= b.x; a.y *= b.y; a.z *= b.z; a.w *= b.w;\n"
"}\n"
"\n"
"inline __device__ void operator*=(double2& a, double2 b) {\n"
"    a.x *= b.x; a.y *= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator*=(double3& a, double3 b) {\n"
"    a.x *= b.x; a.y *= b.y; a.z *= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator*=(double4& a, double4 b) {\n"
"    a.x *= b.x; a.y *= b.y; a.z *= b.z; a.w *= b.w;\n"
"}\n"
"\n"
"// /= operator\n"
"\n"
"inline __device__ void operator/=(int2& a, int2 b) {\n"
"    a.x /= b.x; a.y /= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator/=(int3& a, int3 b) {\n"
"    a.x /= b.x; a.y /= b.y; a.z /= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator/=(int4& a, int4 b) {\n"
"    a.x /= b.x; a.y /= b.y; a.z /= b.z; a.w /= b.w;\n"
"}\n"
"\n"
"inline __device__ void operator/=(float2& a, float2 b) {\n"
"    a.x /= b.x; a.y /= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator/=(float3& a, float3 b) {\n"
"    a.x /= b.x; a.y /= b.y; a.z /= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator/=(float4& a, float4 b) {\n"
"    a.x /= b.x; a.y /= b.y; a.z /= b.z; a.w /= b.w;\n"
"}\n"
"\n"
"inline __device__ void operator/=(double2& a, double2 b) {\n"
"    a.x /= b.x; a.y /= b.y;\n"
"}\n"
"\n"
"inline __device__ void operator/=(double3& a, double3 b) {\n"
"    a.x /= b.x; a.y /= b.y; a.z /= b.z;\n"
"}\n"
"\n"
"inline __device__ void operator/=(double4& a, double4 b) {\n"
"    a.x /= b.x; a.y /= b.y; a.z /= b.z; a.w /= b.w;\n"
"}\n"
"\n"
"// Multiply a vector by a constant.\n"
"\n"
"inline __device__ int2 operator*(int2 a, int b) {\n"
"    return make_int2(a.x*b, a.y*b);\n"
"}\n"
"\n"
"inline __device__ int3 operator*(int3 a, int b) {\n"
"    return make_int3(a.x*b, a.y*b, a.z*b);\n"
"}\n"
"\n"
"inline __device__ int4 operator*(int4 a, int b) {\n"
"    return make_int4(a.x*b, a.y*b, a.z*b, a.w*b);\n"
"}\n"
"\n"
"inline __device__ int2 operator*(int a, int2 b) {\n"
"    return make_int2(a*b.x, a*b.y);\n"
"}\n"
"\n"
"inline __device__ int3 operator*(int a, int3 b) {\n"
"    return make_int3(a*b.x, a*b.y, a*b.z);\n"
"}\n"
"\n"
"inline __device__ int4 operator*(int a, int4 b) {\n"
"    return make_int4(a*b.x, a*b.y, a*b.z, a*b.w);\n"
"}\n"
"\n"
"inline __device__ float2 operator*(float2 a, float b) {\n"
"    return make_float2(a.x*b, a.y*b);\n"
"}\n"
"\n"
"inline __device__ float3 operator*(float3 a, float b) {\n"
"    return make_float3(a.x*b, a.y*b, a.z*b);\n"
"}\n"
"\n"
"inline __device__ float4 operator*(float4 a, float b) {\n"
"    return make_float4(a.x*b, a.y*b, a.z*b, a.w*b);\n"
"}\n"
"\n"
"inline __device__ float2 operator*(float a, float2 b) {\n"
"    return make_float2(a*b.x, a*b.y);\n"
"}\n"
"\n"
"inline __device__ float3 operator*(float a, float3 b) {\n"
"    return make_float3(a*b.x, a*b.y, a*b.z);\n"
"}\n"
"\n"
"inline __device__ float4 operator*(float a, float4 b) {\n"
"    return make_float4(a*b.x, a*b.y, a*b.z, a*b.w);\n"
"}\n"
"\n"
"inline __device__ double2 operator*(double2 a, double b) {\n"
"    return make_double2(a.x*b, a.y*b);\n"
"}\n"
"\n"
"inline __device__ double3 operator*(double3 a, double b) {\n"
"    return make_double3(a.x*b, a.y*b, a.z*b);\n"
"}\n"
"\n"
"inline __device__ double4 operator*(double4 a, double b) {\n"
"    return make_double4(a.x*b, a.y*b, a.z*b, a.w*b);\n"
"}\n"
"\n"
"inline __device__ double2 operator*(double a, double2 b) {\n"
"    return make_double2(a*b.x, a*b.y);\n"
"}\n"
"\n"
"inline __device__ double3 operator*(double a, double3 b) {\n"
"    return make_double3(a*b.x, a*b.y, a*b.z);\n"
"}\n"
"\n"
"inline __device__ double4 operator*(double a, double4 b) {\n"
"    return make_double4(a*b.x, a*b.y, a*b.z, a*b.w);\n"
"}\n"
"\n"
"// Divide a vector by a constant.\n"
"\n"
"inline __device__ int2 operator/(int2 a, int b) {\n"
"    return make_int2(a.x/b, a.y/b);\n"
"}\n"
"\n"
"inline __device__ int3 operator/(int3 a, int b) {\n"
"    return make_int3(a.x/b, a.y/b, a.z/b);\n"
"}\n"
"\n"
"inline __device__ int4 operator/(int4 a, int b) {\n"
"    return make_int4(a.x/b, a.y/b, a.z/b, a.w/b);\n"
"}\n"
"\n"
"inline __device__ float2 operator/(float2 a, float b) {\n"
"    float scale = 1.0f/b;\n"
"    return a*scale;\n"
"}\n"
"\n"
"inline __device__ float3 operator/(float3 a, float b) {\n"
"    float scale = 1.0f/b;\n"
"    return a*scale;\n"
"}\n"
"\n"
"inline __device__ float4 operator/(float4 a, float b) {\n"
"    float scale = 1.0f/b;\n"
"    return a*scale;\n"
"}\n"
"\n"
"inline __device__ double2 operator/(double2 a, double b) {\n"
"    double scale = 1.0/b;\n"
"    return a*scale;\n"
"}\n"
"\n"
"inline __device__ double3 operator/(double3 a, double b) {\n"
"    double scale = 1.0/b;\n"
"    return a*scale;\n"
"}\n"
"\n"
"inline __device__ double4 operator/(double4 a, double b) {\n"
"    double scale = 1.0/b;\n"
"    return a*scale;\n"
"}\n"
"\n"
"// *= operator (multiply vector by constant)\n"
"\n"
"inline __device__ void operator*=(int2& a, int b) {\n"
"    a.x *= b; a.y *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(int3& a, int b) {\n"
"    a.x *= b; a.y *= b; a.z *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(int4& a, int b) {\n"
"    a.x *= b; a.y *= b; a.z *= b; a.w *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(float2& a, float b) {\n"
"    a.x *= b; a.y *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(float3& a, float b) {\n"
"    a.x *= b; a.y *= b; a.z *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(float4& a, float b) {\n"
"    a.x *= b; a.y *= b; a.z *= b; a.w *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(double2& a, double b) {\n"
"    a.x *= b; a.y *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(double3& a, double b) {\n"
"    a.x *= b; a.y *= b; a.z *= b;\n"
"}\n"
"\n"
"inline __device__ void operator*=(double4& a, double b) {\n"
"    a.x *= b; a.y *= b; a.z *= b; a.w *= b;\n"
"}\n"
"\n"
"// Dot product\n"
"\n"
"inline __device__ float dot(float3 a, float3 b) {\n"
"    return a.x*b.x+a.y*b.y+a.z*b.z;\n"
"}\n"
"\n"
"inline __device__ double dot(double3 a, double3 b) {\n"
"    return a.x*b.x+a.y*b.y+a.z*b.z;\n"
"}\n"
"\n"
"// Cross product\n"
"\n"
"inline __device__ float3 cross(float3 a, float3 b) {\n"
"    return make_float3(a.y*b.z-a.z*b.y, a.z*b.x-a.x*b.z, a.x*b.y-a.y*b.x);\n"
"}\n"
"\n"
"inline __device__ float3 cross(float4 a, float4 b) {\n"
"    return make_float3(a.y*b.z-a.z*b.y, a.z*b.x-a.x*b.z, a.x*b.y-a.y*b.x);\n"
"}\n"
"\n"
"inline __device__ double3 cross(double3 a, double3 b) {\n"
"    return make_double3(a.y*b.z-a.z*b.y, a.z*b.x-a.x*b.z, a.x*b.y-a.y*b.x);\n"
"}\n"
"\n"
"inline __device__ double3 cross(double4 a, double4 b) {\n"
"    return make_double3(a.y*b.z-a.z*b.y, a.z*b.x-a.x*b.z, a.x*b.y-a.y*b.x);\n"
"}\n"
"\n"
"// Normalize a vector\n"
"\n"
"inline __device__ float2 normalize(float2 a) {\n"
"    return a*rsqrtf(a.x*a.x+a.y*a.y);\n"
"}\n"
"\n"
"inline __device__ float3 normalize(float3 a) {\n"
"    return a*rsqrtf(a.x*a.x+a.y*a.y+a.z*a.z);\n"
"}\n"
"\n"
"inline __device__ float4 normalize(float4 a) {\n"
"    return a*rsqrtf(a.x*a.x+a.y*a.y+a.z*a.z+a.w*a.w);\n"
"}\n"
"\n"
"inline __device__ double2 normalize(double2 a) {\n"
"    return a*rsqrt(a.x*a.x+a.y*a.y);\n"
"}\n"
"\n"
"inline __device__ double3 normalize(double3 a) {\n"
"    return a*rsqrt(a.x*a.x+a.y*a.y+a.z*a.z);\n"
"}\n"
"\n"
"inline __device__ double4 normalize(double4 a) {\n"
"    return a*rsqrt(a.x*a.x+a.y*a.y+a.z*a.z+a.w*a.w);\n"
"}\n"
"\n"
"// Strip off the fourth component of a vector.\n"
"\n"
"inline __device__ float3 trimTo3(float4 v) {\n"
"    return make_float3(v.x, v.y, v.z);\n"
"}\n"
"\n"
"inline __device__ double3 trimTo3(double4 v) {\n"
"    return make_double3(v.x, v.y, v.z);\n"
"}\n"
"";
const string CudaKernelSources::verlet = "/**\n"
" * Perform the first step of Verlet integration.\n"
" */\n"
"\n"
"extern \"C\" __global__ void integrateVerletPart1(int numAtoms, int paddedNumAtoms, const mixed2* __restrict__ dt, const real4* __restrict__ posq,\n"
"        const real4* __restrict__ posqCorrection, mixed4* __restrict__ velm, const long long* __restrict__ force, mixed4* __restrict__ posDelta) {\n"
"    const mixed2 stepSize = dt[0];\n"
"    const mixed dtPos = stepSize.y;\n"
"    const mixed dtVel = 0.5f*(stepSize.x+stepSize.y);\n"
"    const mixed scale = dtVel/(mixed) 0x100000000;\n"
"    for (int index = blockIdx.x*blockDim.x+threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed4 velocity = velm[index];\n"
"        if (velocity.w != 0.0) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"            real4 pos1 = posq[index];\n"
"            real4 pos2 = posqCorrection[index];\n"
"            mixed4 pos = make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"            real4 pos = posq[index];\n"
"#endif\n"
"            velocity.x += scale*force[index]*velocity.w;\n"
"            velocity.y += scale*force[index+paddedNumAtoms]*velocity.w;\n"
"            velocity.z += scale*force[index+paddedNumAtoms*2]*velocity.w;\n"
"            pos.x = velocity.x*dtPos;\n"
"            pos.y = velocity.y*dtPos;\n"
"            pos.z = velocity.z*dtPos;\n"
"            posDelta[index] = pos;\n"
"            velm[index] = velocity;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Perform the second step of Verlet integration.\n"
" */\n"
"\n"
"extern \"C\" __global__ void integrateVerletPart2(int numAtoms, mixed2* __restrict__ dt, real4* __restrict__ posq,\n"
"        real4* __restrict__ posqCorrection, mixed4* __restrict__ velm, const mixed4* __restrict__ posDelta) {\n"
"    mixed2 stepSize = dt[0];\n"
"#if __CUDA_ARCH__ >= 130\n"
"    double oneOverDt = 1.0/stepSize.y;\n"
"#else\n"
"    float oneOverDt = 1.0f/stepSize.y;\n"
"    float correction = (1.0f-oneOverDt*stepSize.y)/stepSize.y;\n"
"#endif\n"
"    int index = blockIdx.x*blockDim.x+threadIdx.x;\n"
"    if (index == 0)\n"
"        dt[0].x = stepSize.y;\n"
"    for (; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed4 velocity = velm[index];\n"
"        if (velocity.w != 0.0) {\n"
"#ifdef USE_MIXED_PRECISION\n"
"            real4 pos1 = posq[index];\n"
"            real4 pos2 = posqCorrection[index];\n"
"            mixed4 pos = make_mixed4(pos1.x+(mixed)pos2.x, pos1.y+(mixed)pos2.y, pos1.z+(mixed)pos2.z, pos1.w);\n"
"#else\n"
"            real4 pos = posq[index];\n"
"#endif\n"
"            mixed4 delta = posDelta[index];\n"
"            pos.x += delta.x;\n"
"            pos.y += delta.y;\n"
"            pos.z += delta.z;\n"
"#if __CUDA_ARCH__ >= 130\n"
"            velocity = make_mixed4((mixed) (delta.x*oneOverDt), (mixed) (delta.y*oneOverDt), (mixed) (delta.z*oneOverDt), velocity.w);\n"
"#else\n"
"            velocity = make_mixed4((mixed) (delta.x*oneOverDt+delta.x*correction), (mixed) (delta.y*oneOverDt+delta.y*correction), (mixed) (delta.z*oneOverDt+delta.z*correction), velocity.w);\n"
"#endif\n"
"#ifdef USE_MIXED_PRECISION\n"
"            posq[index] = make_real4((real) pos.x, (real) pos.y, (real) pos.z, (real) pos.w);\n"
"            posqCorrection[index] = make_real4(pos.x-(real) pos.x, pos.y-(real) pos.y, pos.z-(real) pos.z, 0);\n"
"#else\n"
"            posq[index] = pos;\n"
"#endif\n"
"            velm[index] = velocity;\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"/**\n"
" * Select the step size to use for the next step.\n"
" */\n"
"\n"
"extern \"C\" __global__ void selectVerletStepSize(int numAtoms, int paddedNumAtoms, mixed maxStepSize, mixed errorTol, mixed2* __restrict__ dt, const mixed4* __restrict__ velm, const long long* __restrict__ force) {\n"
"    // Calculate the error.\n"
"\n"
"    extern __shared__ mixed error[];\n"
"    mixed err = 0.0f;\n"
"    const mixed scale = RECIP((mixed) 0x100000000);\n"
"    for (int index = threadIdx.x; index < numAtoms; index += blockDim.x*gridDim.x) {\n"
"        mixed3 f = make_mixed3(scale*force[index], scale*force[index+paddedNumAtoms], scale*force[index+paddedNumAtoms*2]);\n"
"        mixed invMass = velm[index].w;\n"
"        err += (f.x*f.x + f.y*f.y + f.z*f.z)*invMass*invMass;\n"
"    }\n"
"    error[threadIdx.x] = err;\n"
"    __syncthreads();\n"
"\n"
"    // Sum the errors from all threads.\n"
"\n"
"    for (unsigned int offset = 1; offset < blockDim.x; offset *= 2) {\n"
"        if (threadIdx.x+offset < blockDim.x && (threadIdx.x&(2*offset-1)) == 0)\n"
"            error[threadIdx.x] += error[threadIdx.x+offset];\n"
"        __syncthreads();\n"
"    }\n"
"    if (threadIdx.x == 0) {\n"
"        mixed totalError = SQRT(error[0]/(numAtoms*3));\n"
"        mixed newStepSize = SQRT(errorTol/totalError);\n"
"        mixed oldStepSize = dt[0].y;\n"
"        if (oldStepSize > 0.0f)\n"
"            newStepSize = min(newStepSize, oldStepSize*2.0f); // For safety, limit how quickly dt can increase.\n"
"        if (newStepSize > oldStepSize && newStepSize < 1.1f*oldStepSize)\n"
"            newStepSize = oldStepSize; // Keeping dt constant between steps improves the behavior of the integrator.\n"
"        if (newStepSize > maxStepSize)\n"
"            newStepSize = maxStepSize;\n"
"        dt[0].y = newStepSize;\n"
"    }\n"
"}\n"
"";
